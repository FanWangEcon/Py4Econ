[["index.html", "Data Structures and Cloud Services with Python Preface", " Data Structures and Cloud Services with Python Fan Wang 2020-12-28 Preface The work-in-progress Py4Econ python examples repository. bookdown site and bookdown pdf. Files are written with RMD. Materials are gathered from various projects in which python code is used for research and paper-administrative tasks. Bullet points show which python packages/functions are used to achieve various objectives. This is not a python package, but a set of example files. The pyfan package repository provides some associated programs. Other repositories: For dynamic savings problems, see MEconoTools; For code examples, see also Matlab Example Code, R Example Code, and Stata Example Code; For intro econ with Matlab, see Intro Mathematics for Economists, and for intro stat with R, see Intro Statistics for Undergraduates. See here for all of Fans public repositories. The site is built using Bookdown (Xie 2020). Please contact FanWangEcon for issues or problems. "],["data-structures.html", "Chapter 1 Data Structures 1.1 Numbers, Strings, Lists and Tuples 1.2 Dictionary 1.3 Numpy Arrays", " Chapter 1 Data Structures 1.1 Numbers, Strings, Lists and Tuples 1.1.1 Numeric Basics Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). import numpy as np 1.1.1.1 Two Digit Numbers Coding Conditional Information We have numbers between 0 and 99, these indicate different estimation specifications, where the digit number is the estimation tolerance level, and the tens number is the minimization algorithm. ls_it_esti_optsalgo = [0, 1, 10, 15, 23, 89, 90, 99, 900, 901, 999, 1000] for it_esti_optsalgo in ls_it_esti_optsalgo: it_esti_optsalgo_tens = int(np.floor(it_esti_optsalgo/10)) it_esti_optsalgo_digits = it_esti_optsalgo%10 print(f&#39;{it_esti_optsalgo_tens=}, {it_esti_optsalgo_digits=}&#39;) ## it_esti_optsalgo_tens=0, it_esti_optsalgo_digits=0 ## it_esti_optsalgo_tens=0, it_esti_optsalgo_digits=1 ## it_esti_optsalgo_tens=1, it_esti_optsalgo_digits=0 ## it_esti_optsalgo_tens=1, it_esti_optsalgo_digits=5 ## it_esti_optsalgo_tens=2, it_esti_optsalgo_digits=3 ## it_esti_optsalgo_tens=8, it_esti_optsalgo_digits=9 ## it_esti_optsalgo_tens=9, it_esti_optsalgo_digits=0 ## it_esti_optsalgo_tens=9, it_esti_optsalgo_digits=9 ## it_esti_optsalgo_tens=90, it_esti_optsalgo_digits=0 ## it_esti_optsalgo_tens=90, it_esti_optsalgo_digits=1 ## it_esti_optsalgo_tens=99, it_esti_optsalgo_digits=9 ## it_esti_optsalgo_tens=100, it_esti_optsalgo_digits=0 1.1.2 Tuple Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). import numpy as np 1.1.2.1 Deal Variables Define a number of variables in one line. st_cta, st_ctb, it_ctc = &#39;e&#39;, &#39;20201025x_esr&#39;, 2 print(f&#39;{st_cta=} and {st_ctb=} and {it_ctc=}&#39;) ## st_cta=&#39;e&#39; and st_ctb=&#39;20201025x_esr&#39; and it_ctc=2 1.1.2.2 Tuple Example A tuple is created with parenthesis on the sides (or no parenthesis), not brackets on the sides. Can access values in a tuple as in list. # Define Tuple, with and without parenthesis tp_abc = (&#39;a&#39;, &#39;b&#39;, &#39;c&#39;) tp_abc_noparent = &#39;a&#39;, &#39;b&#39;, &#39;c&#39; print(f&#39;{tp_abc=}&#39;) ## tp_abc=(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;) print(f&#39;{len(tp_abc)=}&#39;) ## len(tp_abc)=3 print(f&#39;{tp_abc_noparent=}&#39;) ## tp_abc_noparent=(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;) print(f&#39;{(tp_abc==tp_abc_noparent)=}&#39;) # Check Type ## (tp_abc==tp_abc_noparent)=True print(f&#39;{isinstance(tp_abc, list)=}&#39;) ## isinstance(tp_abc, list)=False print(f&#39;{isinstance(tp_abc, tuple)=}&#39;) # select element ## isinstance(tp_abc, tuple)=True print(f&#39;{tp_abc[1]=}&#39;) ## tp_abc[1]=&#39;b&#39; Convert tuple to a list: # convert Tuple to list ls_abc = [i for i in tp_abc] print(f&#39;{ls_abc=}&#39;) ## ls_abc=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;] print(f&#39;{isinstance(ls_abc, list)=}&#39;) ## isinstance(ls_abc, list)=True print(f&#39;{isinstance(ls_abc, tuple)=}&#39;) ## isinstance(ls_abc, tuple)=False Since the tuple is not mutable, we can not change values inside the tuple: # define the tuple tp_abc = (&#39;a&#39;, &#39;b&#39;, &#39;c&#39;) # update tuple value try: tp_abc[0] = &#39;efg&#39; except TypeError as error: print(&#39;Caught this error: &#39; + repr(error)) ## Caught this error: TypeError(&quot;&#39;tuple&#39; object does not support item assignment&quot;) 1.1.2.3 Function Returns Tuple and Unpack When a function returns multiple items in a list, that is a tuple. Each element of the list can be accessed. And the tuple can be unpacked: # Results from some function tp_results = &#39;a&#39;, 123, [1,2,3] # Unpack the results a_st, b_int, c_ls_int = tp_results # Print print(f&#39;{tp_results=}&#39;) ## tp_results=(&#39;a&#39;, 123, [1, 2, 3]) print(f&#39;{a_st=}&#39;) ## a_st=&#39;a&#39; print(f&#39;{b_int=}&#39;) ## b_int=123 print(f&#39;{c_ls_int=}&#39;) ## c_ls_int=[1, 2, 3] Unpack only a subset of the elements in the tuple: # Unpack only one a_st_self_m1, _ , _ = tp_results # Alternative shorter a_st_self_m2, *_ = tp_results # Print print(f&#39;{a_st_self_m1=}&#39;) ## a_st_self_m1=&#39;a&#39; print(f&#39;{a_st_self_m2=}&#39;) ## a_st_self_m2=&#39;a&#39; see unpack the first two elements in list/tuple. 1.1.3 List Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). import numpy as np 1.1.3.1 Loop Through a List get Value and Index There is a list, loop through it, get out both the index and the value of each indexed element together. ls_ob_combo_type = [&quot;e&quot;, &quot;20201025x_esr_list_tKap_mlt_ce1a2&quot;, [&quot;esti_param.kappa_ce9901&quot;, &quot;esti_param.kappa_ce0209&quot;], 1, &quot;C1E31M3S3=1&quot;] for it_idx, ob_val in enumerate(ls_ob_combo_type): print(f&#39;{it_idx=} and {ob_val=}&#39;) ## it_idx=0 and ob_val=&#39;e&#39; ## it_idx=1 and ob_val=&#39;20201025x_esr_list_tKap_mlt_ce1a2&#39; ## it_idx=2 and ob_val=[&#39;esti_param.kappa_ce9901&#39;, &#39;esti_param.kappa_ce0209&#39;] ## it_idx=3 and ob_val=1 ## it_idx=4 and ob_val=&#39;C1E31M3S3=1&#39; 1.1.3.2 Parse Elements of a List A list has multiple elements, deal them out. list_test = [&#39;C1E126M4S3&#39;, 2] [compesti_short_name, esti_top_which] = list_test print(f&#39;{compesti_short_name=} and {esti_top_which=}&#39;) ## compesti_short_name=&#39;C1E126M4S3&#39; and esti_top_which=2 1.1.3.3 Check if Any Element of a List is another List There is a list with two elements, there is another list with say four elements. Check if any of the two element is in the list with four elements. ar_int_list_a1 = [1,2] ar_int_list_a2 = [2,1111] ar_int_list_a3 = [2111,1111] ar_int_list_b = [1,2,3,11,999] ar_int_list_c = [2] check_any_a1_in_b = any(item in ar_int_list_a1 for item in ar_int_list_b) check_any_a2_in_b = any(item in ar_int_list_a2 for item in ar_int_list_b) check_any_a3_in_b = any(item in ar_int_list_a3 for item in ar_int_list_b) check_any_a1_in_c = any(item in ar_int_list_a1 for item in ar_int_list_c) print(f&#39;{check_any_a1_in_b=}&#39;) ## check_any_a1_in_b=True print(f&#39;{check_any_a2_in_b=}&#39;) ## check_any_a2_in_b=True print(f&#39;{check_any_a3_in_b=}&#39;) ## check_any_a3_in_b=False print(f&#39;{check_any_a1_in_c=}&#39;) ## check_any_a1_in_c=True 1.1.3.4 Convert a List to a String List Given a list of string and numeric values, convert to a list of string values. The MAP function is like apply in R. How to concatenate items in a list to a single string? ls_spec_key = [&#39;ng_s_d&#39;, &#39;esti_test_11_simu&#39;, 2, 3] ls_st_spec_key = list(map(str, ls_spec_key)) print(ls_st_spec_key) ## [&#39;ng_s_d&#39;, &#39;esti_test_11_simu&#39;, &#39;2&#39;, &#39;3&#39;] Additionally, append some common element to each element of the string using MAP. ls_spec_key = [&#39;ng_s_d&#39;, &#39;esti_test_11_simu&#39;, 2, 3] ls_st_spec_key = list(map(lambda x: &#39;add++&#39; + str(x), ls_spec_key)) print(ls_st_spec_key) ## [&#39;add++ng_s_d&#39;, &#39;add++esti_test_11_simu&#39;, &#39;add++2&#39;, &#39;add++3&#39;] Equivalently, via list comprehension ls_spec_key = [&#39;ng_s_d&#39;, &#39;esti_test_11_simu&#39;, 2, 3] ls_st_spec_key = [&#39;list_comprehension&#39; + str(spec_key) for spec_key in ls_spec_key] print(ls_st_spec_key) ## [&#39;list_comprehensionng_s_d&#39;, &#39;list_comprehensionesti_test_11_simu&#39;, &#39;list_comprehension2&#39;, &#39;list_comprehension3&#39;] 1.1.3.5 Concatenate a List to a String with Separator Given a list of strings and numeric data types, concatenate list to a string with some separator. Also in reverse, generate a list by breaking a string joined by some separator. ls_spec_key = [&#39;ng_s_d&#39;, &#39;esti_test_11_simu&#39;, 2, 3] st_separator = &#39;=&#39; st_spec_key = st_separator.join(list(map(lambda x : str(x), ls_spec_key))) print(st_spec_key) ## ng_s_d=esti_test_11_simu=2=3 Now break string apart: st_spec_key = &#39;=&#39;.join(list(map(lambda x : &#39;$&#39; + str(x) + &#39;$&#39;, [&#39;ng_s_d&#39;, &#39;esti_test_11_simu&#39;, 2, 3]))) print(st_spec_key.split(&#39;=&#39;)) ## [&#39;$ng_s_d$&#39;, &#39;$esti_test_11_simu$&#39;, &#39;$2$&#39;, &#39;$3$&#39;] 1.1.3.6 Add Nth Element to List when Nth Element Does not Exist There is a list with 2 elements, check if the list has 3 elements, if not, add another element. ls_string_A = [&#39;c&#39;, &#39;20180918&#39;] ls_string_B = [&#39;c&#39;, &#39;20180918&#39;, [&#39;esti_param.alpha_k&#39;]] for ls_string in [ls_string_A, ls_string_B]: if len(ls_string) == 2: ls_string.insert(2, None) print(ls_string) ## [&#39;c&#39;, &#39;20180918&#39;, None] ## [&#39;c&#39;, &#39;20180918&#39;, [&#39;esti_param.alpha_k&#39;]] 1.1.3.7 Check If List Has N Elements of None for Some Elements In the example below, for A, B and C, do something, for D and E do something else. ls_string_A = [&#39;c&#39;, &#39;20180918&#39;] ls_string_B = [&#39;c&#39;, &#39;20180918&#39;, None] ls_string_C = [&#39;c&#39;, &#39;20180918&#39;, None, None] ls_string_D = [&#39;c&#39;, &#39;20180918&#39;, [&#39;esti_param.alpha_k&#39;], None] ls_string_E = [&#39;c&#39;, &#39;20180918&#39;, [&#39;esti_param.alpha_k&#39;], 5] for ls_string in [ls_string_A, ls_string_B, ls_string_C, ls_string_D, ls_string_E]: if len(ls_string) &gt;= 3 and ls_string[2] is not None: print(ls_string) else: print(ls_string[0:2]) ## [&#39;c&#39;, &#39;20180918&#39;] ## [&#39;c&#39;, &#39;20180918&#39;] ## [&#39;c&#39;, &#39;20180918&#39;] ## [&#39;c&#39;, &#39;20180918&#39;, [&#39;esti_param.alpha_k&#39;], None] ## [&#39;c&#39;, &#39;20180918&#39;, [&#39;esti_param.alpha_k&#39;], 5] 1.1.3.8 Add a Default Value to Nth Element of List There is a string list with potential potentially three elements. But sometimes the input only has two elements. Provide default third element value if third element is NONE or if the string list only has two elements. ls_string_A = [&#39;c&#39;, &#39;20180918&#39;] ls_string_B = [&#39;c&#39;, &#39;20180918&#39;, None] ls_string_C = [&#39;c&#39;, &#39;20180918&#39;, [&#39;esti_param.alpha_k&#39;]] for ls_string in [ls_string_A, ls_string_B, ls_string_C]: if len(ls_string) &lt;= 2: # Deals with situation A ls_string.append([&#39;esti_param.alpha_k&#39;]) elif ls_string[2] is None: # Deals with situation B ls_string[2] = [&#39;esti_param.alpha_k&#39;] else: # Situation C pass print(ls_string) ## [&#39;c&#39;, &#39;20180918&#39;, [&#39;esti_param.alpha_k&#39;]] ## [&#39;c&#39;, &#39;20180918&#39;, [&#39;esti_param.alpha_k&#39;]] ## [&#39;c&#39;, &#39;20180918&#39;, [&#39;esti_param.alpha_k&#39;]] Now do the same thing for a numeric list: ls_string_A = [11, 22] ls_string_B = [11, 22, None] ls_string_C = [11, 22, 33] for ls_string in [ls_string_A, ls_string_B, ls_string_C]: if len(ls_string) &lt;= 2: # Deals with situation A ls_string.append(33) elif ls_string[2] is None: # Deals with situation B ls_string[2] = 33 else: # Situation C pass print(ls_string) ## [11, 22, 33] ## [11, 22, 33] ## [11, 22, 33] 1.1.4 Strings Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). import numpy as np import string as string import random as random import pprint 1.1.4.1 List of Array Count Frequency There is a list of strings, with repeating values, count the frequence of the each unique string. ls_st_status = [&quot;success&quot;, &quot;running&quot;, &quot;running&quot;, &quot;running&quot;, &quot;finished&quot;, &quot;pending&quot;, &quot;pending&quot;] ls_freq = [ [f&#39;{ls_st_status.count(st_status)} of {len(ls_st_status)} {st_status}&#39;] for st_status in set(ls_st_status)] pprint.pprint(ls_freq) ## [[&#39;3 of 7 running&#39;], ## [&#39;2 of 7 pending&#39;], ## [&#39;1 of 7 success&#39;], ## [&#39;1 of 7 finished&#39;]] 1.1.4.2 Get Substring Given string, get substring after a word. st_func_stack_code = &#39;dc_ls_combo_type = pyfan_amto_lsdcconvert.ff_ls2dc(ls_combo_type,&#39; st_search_break = &#39;ff_ls2dc(&#39; st_string_after = st_func_stack_code.split(st_search_break)[1] st_search_break = &#39;,&#39; st_string_after = st_func_stack_code.split(st_search_break)[1] print(f&#39;{st_string_after=}&#39;) ## st_string_after=&#39;&#39; 1.1.4.3 Generate Random Strings Generate some random strings: random.seed(123) it_word_length = 5 st_rand_word = &#39;&#39;.join(random.choice(string.ascii_lowercase) for i in range(it_word_length)) st_rand_word = st_rand_word.capitalize() print(f&#39;{st_rand_word=}&#39;) ## st_rand_word=&#39;Bicyn&#39; Generate a block or random text and then convert it to a one list of strings: random.seed(123) it_words_count = 15 it_word_length = 5 st_rand_word_block = &#39;&#39;.join(random.choice(string.ascii_lowercase) for ctr in range(it_word_length*it_words_count)) ls_st_rand_word = [st_rand_word_block[ctr: ctr + it_word_length].capitalize() for ctr in range(0, len(st_rand_word_block), it_word_length)] print(f&#39;{ls_st_rand_word=}&#39;) ## ls_st_rand_word=[&#39;Bicyn&#39;, &#39;Idbmr&#39;, &#39;Rkkbf&#39;, &#39;Ekrkw&#39;, &#39;Hfany&#39;, &#39;Ctmca&#39;, &#39;Kxodb&#39;, &#39;Cveez&#39;, &#39;Ajnsp&#39;, &#39;Ipbyj&#39;, &#39;Kqzpg&#39;, &#39;Tuqsz&#39;, &#39;Kamyu&#39;, &#39;Qnvru&#39;, &#39;Zvtpq&#39;] Reshape the array of words to a matrix: mt_st_rand_word = np.reshape(ls_st_rand_word, [3,5]) print(f&#39;{mt_st_rand_word=}&#39;) ## mt_st_rand_word=array([[&#39;Bicyn&#39;, &#39;Idbmr&#39;, &#39;Rkkbf&#39;, &#39;Ekrkw&#39;, &#39;Hfany&#39;], ## [&#39;Ctmca&#39;, &#39;Kxodb&#39;, &#39;Cveez&#39;, &#39;Ajnsp&#39;, &#39;Ipbyj&#39;], ## [&#39;Kqzpg&#39;, &#39;Tuqsz&#39;, &#39;Kamyu&#39;, &#39;Qnvru&#39;, &#39;Zvtpq&#39;]], dtype=&#39;&lt;U5&#39;) print(f&#39;{mt_st_rand_word.shape=}&#39;) ## mt_st_rand_word.shape=(3, 5) print(f&#39;{type(mt_st_rand_word)=}&#39;) ## type(mt_st_rand_word)=&lt;class &#39;numpy.ndarray&#39;&gt; 1.1.4.4 Add String Suffix to Numeric Array Given an numeric array, add string, for example to generate sequencial column names with suffix c: ar_st_colnames = [ &#39;s&#39; + str(it_col) for it_col in np.array(range(1, 3))] print(ar_st_colnames) ## [&#39;s1&#39;, &#39;s2&#39;] 1.1.4.5 Search if Names Include Strings Given a list of strings, loop but skip if string contains elements string list. # define string ls_st_ignore = [&#39;abc&#39;, &#39;efg&#39;, &#39;xyz&#39;] ls_st_loop = [&#39;ab cefg sdf&#39;, &#39;12345&#39;, &#39;xyz&#39;, &#39;abc xyz&#39;, &#39;good morning&#39;] # zip and loop and replace for st_loop in ls_st_loop: if sum([st_ignore in st_loop for st_ignore in ls_st_ignore]): print(&#39;skip:&#39;, st_loop) else: print(&#39;not skip:&#39;, st_loop) ## skip: ab cefg sdf ## not skip: 12345 ## skip: xyz ## skip: abc xyz ## not skip: good morning 1.1.4.6 Replace a Set of Strings in String Replace terms in string # define string st_full = &quot;&quot;&quot; abc is a great efg, probably xyz. Yes, xyz is great, like efg. eft good, EFG capitalized, efg good again. A B C or abc or ABC. Interesting xyz. &quot;&quot;&quot; # define new and old ls_st_old = [&#39;abc&#39;, &#39;efg&#39;, &#39;xyz&#39;] ls_st_new = [&#39;123&#39;, &#39;456&#39;, &#39;789&#39;] # zip and loop and replace for old, new in zip(ls_st_old, ls_st_new): st_full = st_full.replace(old, new) # print print(st_full) ## ## 123 is a great 456, probably 789. Yes, 789 is great, like 456. ## eft good, EFG capitalized, 456 good again. ## A B C or 123 or ABC. Interesting 789. 1.1.4.7 Wrap String with Fixed Width Given a long string, wrap it into multiple lines with fixed width. import textwrap # A long Path st_path = &quot;&quot;&quot; C:/Users/fan/Documents/Dropbox (UH-ECON)/Project Emily Minority Survey/EthLang/reg_lang_abi_cls_mino/tab3_fm/attain_m_vs_f/tab3_mand_talk_m2c_hfracle02.tex &quot;&quot;&quot; # Wrap text with tight width st_wrapped = textwrap.fill(st_path, width = 20) print(st_wrapped) ## C:/Users/fan/Docume ## nts/Dropbox (UH- ## ECON)/Project Emily ## Minority Survey/EthL ## ang/reg_lang_abi_cls ## _mino/tab3_fm/attain ## _m_vs_f/tab3_mand_ta ## lk_m2c_hfracle02.tex Combine Strings that are wrapped and not Wrapped # Paths st_path_a = &quot;C:/Users/fan/Documents/Dropbox (UH-ECON)/Project Emily Minority Survey/EthLang/reg_lang_abi_cls_mino/tab3_fm/attain_m_vs_f/tab3_mand_talk_m2c_hfracle02.tex&quot; st_path_b = &#39;C:/Users/fan/R4Econ/support/development/fs_packaging.html&#39; # Combine Strings and Wrap str_dc_records = &#39;First Path:&#39;.upper() + &#39;\\n&#39; + \\ textwrap.fill(st_path_a, width=25) + &#39;\\n\\n&#39; + \\ &#39;Second Path:&#39;.upper() + &#39;\\n&#39; + \\ textwrap.fill(st_path_b, width=25) # Print print(str_dc_records) ## FIRST PATH: ## C:/Users/fan/Documents/Dr ## opbox (UH-ECON)/Project ## Emily Minority Survey/Eth ## Lang/reg_lang_abi_cls_min ## o/tab3_fm/attain_m_vs_f/t ## ab3_mand_talk_m2c_hfracle ## 02.tex ## ## SECOND PATH: ## C:/Users/fan/R4Econ/suppo ## rt/development/fs_packagi ## ng.html 1.1.4.8 Change Round for Lists of String Estimates Here we have two strings in a list, with point estimates and corresponding standard errors. Estimates are separated by commas. We want to change the number of decimal points shown and set appropriate roundings. Several steps: (1) split string by comma (2) Loop over (3) extract numerical elements (4) recover it_round_decimal = 1 ls_st_all_estimates = [&quot;84.506***, 91.758***, 107.950***, 115.879***, 133.560***\\n&quot;, &quot;(7.796), (4.848), (4.111), (5.044), (6.961)\\n&quot;, &quot;68.180***, 47.921***, 47.127***, 51.366***, 41.764***\\n&quot;, &quot;(8.986), (5.368), (4.995), (5.099), (8.637)\\n&quot;] for st_all_estimates in ls_st_all_estimates: # delete linebreak at end of line st_all_estimates = st_all_estimates.replace(&quot;\\n&quot;, &quot;&quot;) # split ls_st_estimates = st_all_estimates.split(&quot;,&quot;) # Loop over each value separated by commas for it_esti_ctr, st_esti in enumerate(ls_st_estimates): # Default update is to keep current st_esti_update = st_esti # If estimates, might have stars st_esti_numeric = st_esti.strip() st_esti_numeric = st_esti_numeric.replace(&quot;*&quot;, &quot;&quot;) st_esti_numeric = st_esti_numeric.replace(&quot;(&quot;, &quot;&quot;) st_esti_numeric = st_esti_numeric.replace(&quot;)&quot;, &quot;&quot;) # Decimal Rounding fl_esti_rounded = round(float(st_esti_numeric), it_round_decimal) st_esti_rounded = f&#39;{fl_esti_rounded:.{it_round_decimal}f}&#39; # Replace print(f&#39;{st_esti=} + {st_esti_numeric=} + {st_esti_rounded=}&#39;) st_esti_rounded = st_esti.replace(st_esti_numeric, st_esti_rounded) # Update List ls_st_estimates[it_esti_ctr] = st_esti_rounded # Flatten comman st_text_out = &#39;,&#39;.join(ls_st_estimates) print(f&#39;\\n{st_text_out=}\\n&#39;) print() ## st_esti=&#39;84.506***&#39; + st_esti_numeric=&#39;84.506&#39; + st_esti_rounded=&#39;84.5&#39; ## st_esti=&#39; 91.758***&#39; + st_esti_numeric=&#39;91.758&#39; + st_esti_rounded=&#39;91.8&#39; ## st_esti=&#39; 107.950***&#39; + st_esti_numeric=&#39;107.950&#39; + st_esti_rounded=&#39;108.0&#39; ## st_esti=&#39; 115.879***&#39; + st_esti_numeric=&#39;115.879&#39; + st_esti_rounded=&#39;115.9&#39; ## st_esti=&#39; 133.560***&#39; + st_esti_numeric=&#39;133.560&#39; + st_esti_rounded=&#39;133.6&#39; ## ## st_text_out=&#39;84.5***, 91.8***, 108.0***, 115.9***, 133.6***&#39; ## ## ## st_esti=&#39;(7.796)&#39; + st_esti_numeric=&#39;7.796&#39; + st_esti_rounded=&#39;7.8&#39; ## st_esti=&#39; (4.848)&#39; + st_esti_numeric=&#39;4.848&#39; + st_esti_rounded=&#39;4.8&#39; ## st_esti=&#39; (4.111)&#39; + st_esti_numeric=&#39;4.111&#39; + st_esti_rounded=&#39;4.1&#39; ## st_esti=&#39; (5.044)&#39; + st_esti_numeric=&#39;5.044&#39; + st_esti_rounded=&#39;5.0&#39; ## st_esti=&#39; (6.961)&#39; + st_esti_numeric=&#39;6.961&#39; + st_esti_rounded=&#39;7.0&#39; ## ## st_text_out=&#39;(7.8), (4.8), (4.1), (5.0), (7.0)&#39; ## ## ## st_esti=&#39;68.180***&#39; + st_esti_numeric=&#39;68.180&#39; + st_esti_rounded=&#39;68.2&#39; ## st_esti=&#39; 47.921***&#39; + st_esti_numeric=&#39;47.921&#39; + st_esti_rounded=&#39;47.9&#39; ## st_esti=&#39; 47.127***&#39; + st_esti_numeric=&#39;47.127&#39; + st_esti_rounded=&#39;47.1&#39; ## st_esti=&#39; 51.366***&#39; + st_esti_numeric=&#39;51.366&#39; + st_esti_rounded=&#39;51.4&#39; ## st_esti=&#39; 41.764***&#39; + st_esti_numeric=&#39;41.764&#39; + st_esti_rounded=&#39;41.8&#39; ## ## st_text_out=&#39;68.2***, 47.9***, 47.1***, 51.4***, 41.8***&#39; ## ## ## st_esti=&#39;(8.986)&#39; + st_esti_numeric=&#39;8.986&#39; + st_esti_rounded=&#39;9.0&#39; ## st_esti=&#39; (5.368)&#39; + st_esti_numeric=&#39;5.368&#39; + st_esti_rounded=&#39;5.4&#39; ## st_esti=&#39; (4.995)&#39; + st_esti_numeric=&#39;4.995&#39; + st_esti_rounded=&#39;5.0&#39; ## st_esti=&#39; (5.099)&#39; + st_esti_numeric=&#39;5.099&#39; + st_esti_rounded=&#39;5.1&#39; ## st_esti=&#39; (8.637)&#39; + st_esti_numeric=&#39;8.637&#39; + st_esti_rounded=&#39;8.6&#39; ## ## st_text_out=&#39;(9.0), (5.4), (5.0), (5.1), (8.6)&#39; 1.2 Dictionary 1.2.1 Dictionary Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). import pprint import copy as copy 1.2.1.1 Loop Through a Dictionary Given a dictionary, loop through all of its elements dc_speckey_dict = {0: &#39;mpoly_1&#39;, 1: &#39;ng_s_t&#39;, 2: &#39;ng_s_d&#39;, 3: &#39;ng_p_t&#39;, 4: &#39;ng_p_d&#39;} for speckey_key, speckey_val in dc_speckey_dict.items(): print(&#39;speckey_key:&#39; + str(speckey_key) + &#39;, speckey_val:&#39; + speckey_val) ## speckey_key:0, speckey_val:mpoly_1 ## speckey_key:1, speckey_val:ng_s_t ## speckey_key:2, speckey_val:ng_s_d ## speckey_key:3, speckey_val:ng_p_t ## speckey_key:4, speckey_val:ng_p_d 1.2.1.2 Convert a List to a Dictionary There is a list with different types of elements. Use the name of the list as the key, with value index added in as a part of the key, the value is the value of the dictionary. # List ls_combo_type = [&quot;e&quot;, &quot;20201025x_esr_list_tKap_mlt_ce1a2&quot;, [&quot;esti_param.kappa_ce9901&quot;, &quot;esti_param.kappa_ce0209&quot;], 1, &quot;C1E31M3S3=1&quot;] # List name as string variable st_ls_name = f&#39;{ls_combo_type=}&#39;.split(&#39;=&#39;)[0] # Convert to dict dc_from_list = {st_ls_name + &#39;_i&#39; + str(it_idx) + &#39;o&#39; + str(len(ls_combo_type)) : ob_val for it_idx, ob_val in enumerate(ls_combo_type)} # Print pprint.pprint(dc_from_list, width=1) ## {&#39;ls_combo_type_i0o5&#39;: &#39;e&#39;, ## &#39;ls_combo_type_i1o5&#39;: &#39;20201025x_esr_list_tKap_mlt_ce1a2&#39;, ## &#39;ls_combo_type_i2o5&#39;: [&#39;esti_param.kappa_ce9901&#39;, ## &#39;esti_param.kappa_ce0209&#39;], ## &#39;ls_combo_type_i3o5&#39;: 1, ## &#39;ls_combo_type_i4o5&#39;: &#39;C1E31M3S3=1&#39;} 1.2.1.3 Select One Key-value Pair Given a dictionary, select a single key-value pair, based on either the key or the value. # select by key ls_it_keys = [0, 4] dc_speckey_dict_select_by_key = {it_key: dc_speckey_dict[it_key] for it_key in ls_it_keys} print(f&#39;{dc_speckey_dict_select_by_key=}&#39;) # select by value ## dc_speckey_dict_select_by_key={0: &#39;mpoly_1&#39;, 4: &#39;ng_p_d&#39;} ls_st_keys = [&#39;ng_s_d&#39;, &#39;ng_p_d&#39;] dc_speckey_dict_select_by_val = {it_key: st_val for it_key, st_val in dc_speckey_dict.items() if st_val in ls_st_keys} print(f&#39;{dc_speckey_dict_select_by_val=}&#39;) ## dc_speckey_dict_select_by_val={2: &#39;ng_s_d&#39;, 4: &#39;ng_p_d&#39;} See Get key by value in dictionary. 1.2.1.4 Copying Dictionary and Updating Copied Dictionary First, below, it looks as if the default dictionary has been copied, and that the updates to the dictionary will only impact the dc_invoke_main_args, but that is not the case: # list update dc_invoke_main_args_default = {&#39;speckey&#39;: &#39;ng_s_t&#39;, &#39;ge&#39;: False, &#39;multiprocess&#39;: False, &#39;estimate&#39;: False, &#39;graph_panda_list_name&#39;: &#39;min_graphs&#39;, &#39;save_directory_main&#39;: &#39;simu&#39;, &#39;log_file&#39;: False, &#39;log_file_suffix&#39;: &#39;&#39;} dc_invoke_main_args = dc_invoke_main_args_default dc_invoke_main_args[&#39;speckey&#39;] = &#39;b_ge_s_t_bis&#39; dc_invoke_main_args[&#39;ge&#39;] = True print(f&#39;speckey in dc_invoke_main_args is {dc_invoke_main_args[&quot;speckey&quot;]}.&#39;) ## speckey in dc_invoke_main_args is b_ge_s_t_bis. print(f&#39;speckey in dc_invoke_main_args_default is {dc_invoke_main_args_default[&quot;speckey&quot;]}.&#39;) ## speckey in dc_invoke_main_args_default is b_ge_s_t_bis. Now this has the intended result. After updating the deep-copied dictionary, the key-values in the original dictionary are preserved: # list update dc_invoke_main_args_default = {&#39;speckey&#39;: &#39;ng_s_t&#39;, &#39;ge&#39;: False, &#39;multiprocess&#39;: False, &#39;estimate&#39;: False, &#39;graph_panda_list_name&#39;: &#39;min_graphs&#39;, &#39;save_directory_main&#39;: &#39;simu&#39;, &#39;log_file&#39;: False, &#39;log_file_suffix&#39;: &#39;&#39;} # deep copy and update dc_invoke_main_args = copy.deepcopy(dc_invoke_main_args_default) dc_invoke_main_args[&#39;speckey&#39;] = &#39;b_ge_s_t_bis&#39; dc_invoke_main_args[&#39;ge&#39;] = True print(f&#39;speckey in dc_invoke_main_args_default is {dc_invoke_main_args_default[&quot;speckey&quot;]}.&#39;) ## speckey in dc_invoke_main_args_default is ng_s_t. print(f&#39;speckey in dc_invoke_main_args is {dc_invoke_main_args[&quot;speckey&quot;]}.&#39;) # deep copy and update again ## speckey in dc_invoke_main_args is b_ge_s_t_bis. dc_invoke_main_args = copy.deepcopy(dc_invoke_main_args_default) dc_invoke_main_args[&#39;speckey&#39;] = &#39;b_ge_s_t_bis_new&#39; dc_invoke_main_args[&#39;ge&#39;] = False print(f&#39;speckey in dc_invoke_main_args is {dc_invoke_main_args[&quot;speckey&quot;]}.&#39;) ## speckey in dc_invoke_main_args is b_ge_s_t_bis_new. copy and deepcopy Deep copy of a dict in python 1.2.1.5 Create a List of Dictionaries import datetime import pprint ls_dc_exa = [ {&quot;file&quot;: &quot;mat_matlab&quot;, &quot;title&quot;: &quot;One Variable Graphs and Tables&quot;, &quot;description&quot;: &quot;Frequency table, bar chart and histogram&quot;, &quot;val&quot;: 1, &quot;date&quot;: datetime.date(2020, 5, 2)}, {&quot;file&quot;: &quot;mat_two&quot;, &quot;title&quot;: &quot;Second file&quot;, &quot;description&quot;: &quot;Second file.&quot;, &quot;val&quot;: [1, 2, 3], &quot;date&quot;: datetime.date(2020, 5, 2)}, {&quot;file&quot;: &quot;mat_algebra_rules&quot;, &quot;title&quot;: &quot;Opening a Dataset&quot;, &quot;description&quot;: &quot;Opening a Dataset.&quot;, &quot;val&quot;: 1.1, &quot;date&quot;: datetime.date(2018, 12, 1)} ] pprint.pprint(ls_dc_exa, width=1) ## [{&#39;date&#39;: datetime.date(2020, 5, 2), ## &#39;description&#39;: &#39;Frequency &#39; ## &#39;table, &#39; ## &#39;bar &#39; ## &#39;chart &#39; ## &#39;and &#39; ## &#39;histogram&#39;, ## &#39;file&#39;: &#39;mat_matlab&#39;, ## &#39;title&#39;: &#39;One &#39; ## &#39;Variable &#39; ## &#39;Graphs &#39; ## &#39;and &#39; ## &#39;Tables&#39;, ## &#39;val&#39;: 1}, ## {&#39;date&#39;: datetime.date(2020, 5, 2), ## &#39;description&#39;: &#39;Second &#39; ## &#39;file.&#39;, ## &#39;file&#39;: &#39;mat_two&#39;, ## &#39;title&#39;: &#39;Second &#39; ## &#39;file&#39;, ## &#39;val&#39;: [1, ## 2, ## 3]}, ## {&#39;date&#39;: datetime.date(2018, 12, 1), ## &#39;description&#39;: &#39;Opening &#39; ## &#39;a &#39; ## &#39;Dataset.&#39;, ## &#39;file&#39;: &#39;mat_algebra_rules&#39;, ## &#39;title&#39;: &#39;Opening &#39; ## &#39;a &#39; ## &#39;Dataset&#39;, ## &#39;val&#39;: 1.1}] 1.2.1.6 Iteratively Add to A Dictionary Iteratively add additional Key and Value pairs to a dictionary. ls_snm_tex = [&quot;file1.tex&quot;, &quot;file2.tex&quot;, &quot;file3.tex&quot;] ls_snm_pdf = [&quot;file1.pdf&quot;, &quot;file2.pdf&quot;, &quot;file3.pdf&quot;] dc_tex_pdf = {} for tex, pdf in zip(ls_snm_tex, ls_snm_pdf): dc_tex_pdf[tex] = pdf pprint.pprint(dc_tex_pdf, width=1) ## {&#39;file1.tex&#39;: &#39;file1.pdf&#39;, ## &#39;file2.tex&#39;: &#39;file2.pdf&#39;, ## &#39;file3.tex&#39;: &#39;file3.pdf&#39;} 1.2.1.7 Select by Keys Dictionaries from list of Dictionaries Given a list of dictionary, search if key name is in list: # string to search through ls_str_file_ids = [&#39;mat_matlab&#39;, &#39;mat_algebra_rules&#39;] # select subset ls_dc_selected = [dc_exa for dc_exa in ls_dc_exa if dc_exa[&#39;file&#39;] in ls_str_file_ids] # print pprint.pprint(ls_dc_selected, width=1) ## [{&#39;date&#39;: datetime.date(2020, 5, 2), ## &#39;description&#39;: &#39;Frequency &#39; ## &#39;table, &#39; ## &#39;bar &#39; ## &#39;chart &#39; ## &#39;and &#39; ## &#39;histogram&#39;, ## &#39;file&#39;: &#39;mat_matlab&#39;, ## &#39;title&#39;: &#39;One &#39; ## &#39;Variable &#39; ## &#39;Graphs &#39; ## &#39;and &#39; ## &#39;Tables&#39;, ## &#39;val&#39;: 1}, ## {&#39;date&#39;: datetime.date(2018, 12, 1), ## &#39;description&#39;: &#39;Opening &#39; ## &#39;a &#39; ## &#39;Dataset.&#39;, ## &#39;file&#39;: &#39;mat_algebra_rules&#39;, ## &#39;title&#39;: &#39;Opening &#39; ## &#39;a &#39; ## &#39;Dataset&#39;, ## &#39;val&#39;: 1.1}] Search and Select by Multiple Keys in Dictionary. Using two keys below: # string to search through ls_str_file_ids = [&#39;mat_matlab&#39;, &#39;mat_algebra_rules&#39;] # select subset ls_dc_selected = [dc_exa for dc_exa in ls_dc_exa if ((dc_exa[&#39;file&#39;] in ls_str_file_ids) and (dc_exa[&#39;val&#39;]== 1))] # print pprint.pprint(ls_dc_selected, width=1) ## [{&#39;date&#39;: datetime.date(2020, 5, 2), ## &#39;description&#39;: &#39;Frequency &#39; ## &#39;table, &#39; ## &#39;bar &#39; ## &#39;chart &#39; ## &#39;and &#39; ## &#39;histogram&#39;, ## &#39;file&#39;: &#39;mat_matlab&#39;, ## &#39;title&#39;: &#39;One &#39; ## &#39;Variable &#39; ## &#39;Graphs &#39; ## &#39;and &#39; ## &#39;Tables&#39;, ## &#39;val&#39;: 1}] 1.2.1.8 Drop Element of Dictionary Drop element of a dictionary inside a list: # Dictionary dc_test = [{&quot;file&quot;: &quot;mat_matlab_1&quot;, &quot;title&quot;: &quot;One Variable Graphs and Tables&quot;, &quot;description&quot;: &quot;Frequency table, bar chart and histogram&quot;, &quot;val&quot;: 1, &quot;date&quot;: datetime.date(2020, 5, 2)}, {&quot;file&quot;: &quot;mat_matlab_2&quot;, &quot;val&quot;: &quot;mat_matlab_2&quot;}] # Drop del dc_test[0][&#39;val&#39;] del dc_test[0][&#39;file&#39;] del dc_test[0][&#39;description&#39;] del dc_test[1][&#39;val&#39;] # Print pprint.pprint(dc_test, width=1) ## [{&#39;date&#39;: datetime.date(2020, 5, 2), ## &#39;title&#39;: &#39;One &#39; ## &#39;Variable &#39; ## &#39;Graphs &#39; ## &#39;and &#39; ## &#39;Tables&#39;}, ## {&#39;file&#39;: &#39;mat_matlab_2&#39;}] 1.3 Numpy Arrays 1.3.1 Generate Matrix from Arrays Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). import numpy as np 1.3.1.1 Generate a Random Matrix Generate a matrix with random numbers and arbitrary number of rows and columns. Several types of matrix below: uniform random integer random integer random resorted (shuffled) integer random redrawn (with replacements) Set size: it_rows = 2; it_cols = 3; np.random.seed(123) uniform random: # A random matrix of uniform draws mt_rand_unif = np.random.rand(it_rows, it_cols) print(mt_rand_unif) ## [[0.69646919 0.28613933 0.22685145] ## [0.55131477 0.71946897 0.42310646]] integer random: # A random matrix of integers it_max_int = 10 mt_rand_integer = np.random.randint(it_max_int, size=(it_rows, it_cols)) print(mt_rand_integer) ## [[6 1 0] ## [1 9 0]] integer random resorted (shuffled): # A sequence of numbers, 1 to matrix size, resorted, unique it_mat_size = it_rows*it_cols ar_seq = np.arange(it_mat_size) ar_idx_resort = np.random.choice(np.arange(it_mat_size), it_mat_size, replace = False) ar_seq_rand_sorted = ar_seq[ar_idx_resort] mt_seq_rand_sorted = ar_seq_rand_sorted.reshape((it_rows, it_cols)) print(mt_seq_rand_sorted) # achieve the same objective with a shuffle ## [[5 4 2] ## [3 1 0]] np.random.shuffle(ar_seq) mt_seq_rand_shuffle = ar_seq.reshape((it_rows, it_cols)) print(mt_seq_rand_shuffle) ## [[2 1 3] ## [5 0 4]] integer random redrawn (with replacements): # A sequence of numbers, 1 to matrix size, resorted, nonunique, REPLACE = TRUE it_mat_size = it_rows*it_cols ar_seq = np.arange(it_mat_size) ar_idx_resort_withreplacement = np.random.choice(np.arange(it_mat_size), it_mat_size, replace = True) ar_seq_rand_sorted_withreplacement = ar_seq[ar_idx_resort_withreplacement] mt_seq_rand_sorted_withreplacement = ar_seq_rand_sorted_withreplacement.reshape((it_rows, it_cols)) print(mt_seq_rand_sorted_withreplacement) ## [[3 2 4] ## [2 4 0]] 1.3.1.2 Stack Arrays to Matrix Given various arrays, generate a matrix by stacking equi-length arrays as columns # three arrays ar_a = [1,2,3] ar_b = [3,4,5] ar_c = [11,4,1] # Concatenate to matrix mt_abc = np.column_stack([ar_a, ar_b, ar_c]) print(mt_abc) ## [[ 1 3 11] ## [ 2 4 4] ## [ 3 5 1]] "],["pandas.html", "Chapter 2 Pandas 2.1 Panda Basics", " Chapter 2 Pandas 2.1 Panda Basics 2.1.1 Generate Matrix from Arrays Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). import numpy as np import pandas as pd import random as random import string as string 2.1.1.1 Single Arrays to Matrix Given various arrays, generate a matrix np.random.seed(123) # Concatenate to matrix mt_abc = np.column_stack(np.random.randint(10, size=(5, 3))) # Matrix to data frame with columns and row names df_abc = pd.DataFrame(data=mt_abc, index=[ &#39;r&#39; + str(it_col) for it_col in np.array(range(1, mt_abc.shape[0]+1))], columns=[ &#39;c&#39; + str(it_col) for it_col in np.array(range(1, mt_abc.shape[1]+1))]) # Print print(df_abc) ## c1 c2 c3 c4 c5 ## r1 2 1 6 1 0 ## r2 2 3 1 9 9 ## r3 6 9 0 0 3 2.1.1.2 Generate a Testing Dataframe with String and Numeric Values Generate a test dataframe with string and numeric variables. For testing purposes. # Seed np.random.seed(456) random.seed(456) # Numeric matrix 3 rows 4 columns mt_numeric = np.random.randint(10, size=(3, 4)) # String block 5 letters per word, 3 rows and 3 columns of words st_rand_word_block = &#39;&#39;.join(random.choice(string.ascii_lowercase) for ctr in range(5*3*3)) ls_st_rand_word = [st_rand_word_block[ctr: ctr + 5].capitalize() for ctr in range(0, len(st_rand_word_block), 5)] mt_string = np.reshape(ls_st_rand_word, [3,3]) # Combine string and numeric matrix mt_data = np.column_stack([mt_numeric, mt_string]) # Matrix to dataframe df_data = pd.DataFrame(data=mt_data, index=[ &#39;r&#39; + str(it_col) for it_col in np.array(range(1, mt_data.shape[0]+1))], columns=[ &#39;c&#39; + str(it_col) for it_col in np.array(range(1, mt_data.shape[1]+1))]) # Print table print(df_data) ## c1 c2 c3 c4 c5 c6 c7 ## r1 5 9 4 5 Xoonm Zubtx Zqdkp ## r2 7 1 8 3 Ydcpw Obiee Gfxmq ## r3 5 2 4 2 Tzrwu Srwvp Kcsrb 2.1.2 Select Rows and Columns from Dataframe Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). import numpy as np import pandas as pd import random as random import string as string 2.1.2.1 Generate a Testing Dataframe Generate a testing dataframe for selection and other tests. # Seed np.random.seed(999) random.seed(999) # Numeric matrix 3 rows 4 columns mt_numeric = np.random.randint(10, size=(5, 4)) st_rand_word_block = &#39;&#39;.join(random.choice(string.ascii_lowercase) for ctr in range(5*5*3)) mt_string = np.reshape([st_rand_word_block[ctr: ctr + 5].capitalize() for ctr in range(0, len(st_rand_word_block), 5)], [5,3]) mt_data = np.column_stack([mt_numeric, mt_string]) # Matrix to dataframe df_data = pd.DataFrame(data=mt_data, index=[ &#39;r&#39; + str(it_col) for it_col in np.array(range(1, mt_data.shape[0]+1))], columns=[ &#39;c&#39; + str(it_col) for it_col in np.array(range(1, mt_data.shape[1]+1))]) # Replace values df_data = df_data.replace([&#39;Zvcss&#39;, &#39;Dugei&#39;, &#39;Ciagu&#39;], &#39;Zqovt&#39;) # Print table print(df_data) ## c1 c2 c3 c4 c5 c6 c7 ## r1 0 5 1 8 Zqovt Rppez Ukuzu ## r2 1 9 3 0 Zqovt Sbwyi Mzhum ## r3 5 8 8 0 Zqovt Qgfvk Fcrto ## r4 5 2 5 7 Wxlev Upoax Bhdxu ## r5 4 6 2 7 Hmziq Lbyfo Dntrz 2.1.2.2 Select Rows Based on Column/Variable Values There is a dataframe with many rows, select a subset of rows where a particular column/variables value is equal to some value. # Concatenate to matrix df_data_subset = df_data.loc[df_data[&#39;c5&#39;] == &#39;Zqovt&#39;] # Print print(df_data_subset) ## c1 c2 c3 c4 c5 c6 c7 ## r1 0 5 1 8 Zqovt Rppez Ukuzu ## r2 1 9 3 0 Zqovt Sbwyi Mzhum ## r3 5 8 8 0 Zqovt Qgfvk Fcrto See How to select rows from a DataFrame based on column values. 2.1.3 Pandas Importing and Exporting Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 2.1.3.1 Export a Dataframe to CSV in User Download with Automatic File Name During debugging and testing, a large dataframe is generated, but certain operation produces error. To fully debug, drop into debugger on error in PyCharm, and use console to generate a dataframe of just the matrix at issue. Now export this dataframe to csv in the fastest way possible. Find user home path, generate a download subdirectory if it does not exist. Export the current dataframe to csv in that file, with auto row and column names. The dataframe will be named after the current variable array name, and will have a time suffix added. Replace the mt_abc line below, use a different name that should appear in the saved file name. # Import Pathlib and panddas import pandas as pd import numpy as np from pathlib import Path import time # replace mt_abc line by the matrix currently used mt_abc = np.column_stack(np.random.randint(10, size=(5, 3))) # Save results to C:\\Users\\fan\\Downloads\\PythonDebug, generate if does not exist. srt_pydebug = Path.joinpath(Path.home(), &quot;Downloads&quot;, &quot;PythonDebug&quot;) srt_pydebug.mkdir(parents=True, exist_ok=True) # Matrix to data frame with columns and row names df2export = pd.DataFrame(data=mt_abc, index=[&#39;r&#39; + str(it_col) for it_col in np.array(range(1, mt_abc.shape[0] + 1))], columns=[&#39;c&#39; + str(it_col) for it_col in np.array(range(1, mt_abc.shape[1] + 1))]) # Export File Name spn_csv_path = Path.joinpath(srt_pydebug, f&#39;{mt_abc=}&#39;.split(&#39;=&#39;)[0] + &#39;-&#39; + time.strftime(&quot;%Y%m%d-%H%M%S&quot;) + &#39;.csv&#39;) # export df2export.to_csv(spn_csv_path, sep=&quot;,&quot;) # print print(f&#39;{srt_pydebug=}&#39;) ## srt_pydebug=WindowsPath(&#39;C:/Users/fan/Downloads/PythonDebug&#39;) print(f&#39;{spn_csv_path=}&#39;) ## spn_csv_path=WindowsPath(&#39;C:/Users/fan/Downloads/PythonDebug/mt_abc-20201228-220153.csv&#39;) "],["functions.html", "Chapter 3 Functions 3.1 Function Arguments and Returns 3.2 Exceptions", " Chapter 3 Functions 3.1 Function Arguments and Returns 3.1.1 Data Types Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 3.1.1.1 Check Parameter Type There are parameters of a function, depending on the parameter type, execute the program differently. If integer, behave one way if string behave in another way. # define the function def get_speckey_dict(gn_speckey=None): if isinstance(gn_speckey, str): print(f&#39;{gn_speckey=} is a string&#39;) elif isinstance(gn_speckey, int): print(f&#39;{gn_speckey=} is an integer&#39;) else: raise TypeError(f&#39;{gn_speckey=} was not a string or an integer&#39;) # Call function with integer get_speckey_dict(1) # Call function with string ## gn_speckey=1 is an integer get_speckey_dict(&#39;abc&#39;) # Call function with a list ## gn_speckey=&#39;abc&#39; is a string try: get_speckey_dict([&#39;abc&#39;]) except TypeError as e: print(f&#39;Exception{e=}&#39;) ## Exceptione=TypeError(&quot;gn_speckey=[&#39;abc&#39;] was not a string or an integer&quot;) 3.1.1.2 Check if Parameter is String or Integer In Interval There is a function that takes a string or an integer between certain values. Execute if either of these two conditions are satisfied, do not if neither is satisfied. Below, print if string or an int between 1 and 11. # condition check function def check_condition(gn_invoke_set): bl_is_str = isinstance(gn_invoke_set, str) bl_is_int = isinstance(gn_invoke_set, int) if bl_is_int: bl_between = (gn_invoke_set &gt;= 1 and gn_invoke_set &lt;= 11) else: bl_between = False if bl_between or bl_is_str: print(f&#39;{gn_invoke_set=}&#39;) else: print(f&#39;{gn_invoke_set=} is not string or an integer between 1 and 11&#39;) # call with string or integer check_condition(&#39;string&#39;) ## gn_invoke_set=&#39;string&#39; check_condition(11) ## gn_invoke_set=11 check_condition(1) ## gn_invoke_set=1 check_condition(199) ## gn_invoke_set=199 is not string or an integer between 1 and 11 check_condition([&#39;abc&#39;]) ## gn_invoke_set=[&#39;abc&#39;] is not string or an integer between 1 and 11 3.1.2 Function Arguments Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). import pprint 3.1.2.1 Mutable Argument Default If a parameter is a list, that is mutable, or a dict. Default values for the mutable parameter should be None, with the actual default value provided inside the function. # Mutable dict as parameters def ffi_tab_txt2tex(dc_fmd_sym_sig=None, dc_tex_sig_sym=None): if dc_fmd_sym_sig is None: # defaults dc_fmd_sym_sig = {&#39;***&#39;: 1e-2, &#39;**&#39;: 5e-2, &#39;*&#39;: 1e-1} if dc_tex_sig_sym is None: # defaults dc_tex_sig_sym = {&#39;1e-3&#39;: &#39;\\\\sym{***}&#39;, &#39;1e-2&#39;: &#39;\\\\sym{**}&#39;, &#39;5e-2&#39;: &#39;\\\\sym{*}&#39;, &#39;1e-1&#39;: &#39;\\\\dagger&#39;} # print print(f&#39;{dc_fmd_sym_sig=}&#39;) print(f&#39;{dc_tex_sig_sym=}&#39;) # Call function with default ffi_tab_txt2tex() # Call function update the first dict ## dc_fmd_sym_sig={&#39;***&#39;: 0.01, &#39;**&#39;: 0.05, &#39;*&#39;: 0.1} ## dc_tex_sig_sym={&#39;1e-3&#39;: &#39;\\\\sym{***}&#39;, &#39;1e-2&#39;: &#39;\\\\sym{**}&#39;, &#39;5e-2&#39;: &#39;\\\\sym{*}&#39;, &#39;1e-1&#39;: &#39;\\\\dagger&#39;} ffi_tab_txt2tex(dc_fmd_sym_sig = {&#39;***&#39;: 1e-3, &#39;**&#39;: 1e-2, &#39;*&#39;: 5e-2}) ## dc_fmd_sym_sig={&#39;***&#39;: 0.001, &#39;**&#39;: 0.01, &#39;*&#39;: 0.05} ## dc_tex_sig_sym={&#39;1e-3&#39;: &#39;\\\\sym{***}&#39;, &#39;1e-2&#39;: &#39;\\\\sym{**}&#39;, &#39;5e-2&#39;: &#39;\\\\sym{*}&#39;, &#39;1e-1&#39;: &#39;\\\\dagger&#39;} see Least Astonishment and the Mutable Default Argument. 3.1.2.2 Python Dictionary As Argument via kwargs There is a python function that outputs a dictionary with key and value pairs that specify key aspects of how a model should be solved. For example, one of the parameters could specify the vcpu requirement. This vcpu requirement might change, and so it should be easy to update this key with alternative values. These are accomplished in the following manner. Define the full key-value pair list, with default values for several dictionaries, with model simulation, support, and compute parameters for example. These lists could be updated with some default alternative combinations, or alternatively, it could be updated with externally provided dictionary with both updated values for existing keys, or even additional key value pairs. First, we create a function that processes and outputs default parameters, it has two inputs, it_default_group to specify pre-fixed adjustments from defaults, and kwargs that allows for arbitrarily modifications and additions to parameter dictionary. def gen_compesti_spec(it_default_group=None, **kwargs): # A. Define the default parameter keys and values esti_specs = {&#39;esti_method&#39;: &#39;MomentsSimuStates&#39;, &#39;momsets_type&#39;: [&#39;a&#39;, &#39;20180805a&#39;], &#39;esti_param_vec_count&#39;: 1, &#39;esti_max_func_eval&#39;: 10, &#39;graph_frequncy&#39;: 20} compute_specs = {&#39;cpu&#39;: str(1024 * 1), &#39;memory&#39;: str(517), # only need about 160 mb in reality &#39;workers&#39;: 1, &#39;aws_fargate&#39;: False} # B. For different compesti_specs = {**compute_specs, **esti_specs} # C. Update dictionaries with parameter group values if it_default_group == 1: compesti_specs_updates = {&#39;memory&#39;: str(1024 * 55), &#39;compute_param_vec_count&#39;: 6, &#39;esti_param_vec_count&#39;: 640} compesti_specs.update(compesti_specs_updates) # D. Update with kward, could append new compesti_specs.update(kwargs) return compesti_specs Second, we test the defaults: compesti_specs = gen_compesti_spec() pprint.pprint(compesti_specs, width=1) ## {&#39;aws_fargate&#39;: False, ## &#39;cpu&#39;: &#39;1024&#39;, ## &#39;esti_max_func_eval&#39;: 10, ## &#39;esti_method&#39;: &#39;MomentsSimuStates&#39;, ## &#39;esti_param_vec_count&#39;: 1, ## &#39;graph_frequncy&#39;: 20, ## &#39;memory&#39;: &#39;517&#39;, ## &#39;momsets_type&#39;: [&#39;a&#39;, ## &#39;20180805a&#39;], ## &#39;workers&#39;: 1} Third, we test using default group 1, pre-fixed changes to defaults: compesti_specs = gen_compesti_spec(it_default_group=1) pprint.pprint(compesti_specs, width=1) ## {&#39;aws_fargate&#39;: False, ## &#39;compute_param_vec_count&#39;: 6, ## &#39;cpu&#39;: &#39;1024&#39;, ## &#39;esti_max_func_eval&#39;: 10, ## &#39;esti_method&#39;: &#39;MomentsSimuStates&#39;, ## &#39;esti_param_vec_count&#39;: 640, ## &#39;graph_frequncy&#39;: 20, ## &#39;memory&#39;: &#39;56320&#39;, ## &#39;momsets_type&#39;: [&#39;a&#39;, ## &#39;20180805a&#39;], ## &#39;workers&#39;: 1} Fourth, we use kwargs to feed in arbitrary dictionary to update and append to existing parameter dictionary: compesti_specs_updates = {&#39;esti_method&#39;: &#39;MomentsSimuStateszzz&#39;, &#39;moments_type&#39;: [&#39;a&#39;, &#39;20180805azzz&#39;], &#39;momsets_type&#39;: [&#39;a&#39;, &#39;20180805azzz&#39;], &#39;momsets_type_uuu&#39;: [&#39;a&#39;, &#39;20180805azzz&#39;]} compesti_specs = gen_compesti_spec(it_default_group=None, **compesti_specs_updates) pprint.pprint(compesti_specs, width=1) ## {&#39;aws_fargate&#39;: False, ## &#39;cpu&#39;: &#39;1024&#39;, ## &#39;esti_max_func_eval&#39;: 10, ## &#39;esti_method&#39;: &#39;MomentsSimuStateszzz&#39;, ## &#39;esti_param_vec_count&#39;: 1, ## &#39;graph_frequncy&#39;: 20, ## &#39;memory&#39;: &#39;517&#39;, ## &#39;moments_type&#39;: [&#39;a&#39;, ## &#39;20180805azzz&#39;], ## &#39;momsets_type&#39;: [&#39;a&#39;, ## &#39;20180805azzz&#39;], ## &#39;momsets_type_uuu&#39;: [&#39;a&#39;, ## &#39;20180805azzz&#39;], ## &#39;workers&#39;: 1} 3.1.2.3 Named Argument List and Dictionary Define a function with named and unnamed arguments: def gen_compesti_spec_named(it_default_group, esti_method, memory=123, graph_frequncy=10): # A. Define the default parameter keys and values esti_specs = {&#39;esti_method&#39;: &#39;MomentsSimuStates&#39;, &#39;momsets_type&#39;: [&#39;a&#39;, &#39;20180805a&#39;], &#39;it_default_group&#39;: it_default_group, &#39;esti_param_vec_count&#39;: 1, &#39;esti_max_func_eval&#39;: 10, &#39;graph_frequncy&#39;: graph_frequncy} compute_specs = {&#39;cpu&#39;: str(1024 * 1), &#39;memory&#39;: str(memory), # only need about 160 mb in reality &#39;workers&#39;: 1, &#39;aws_fargate&#39;: False} # B. For different compesti_specs = {**compute_specs, **esti_specs} return compesti_specs Provide inputs for the first two unnamed parameters explicitly. Then provided the two named parameters via a dictionary: dc_inputs = {&#39;memory&#39;:12345, &#39;graph_frequncy&#39;:2} compesti_specs = gen_compesti_spec_named(None, &#39;MomentsSimuStates&#39;, **dc_inputs) pprint.pprint(compesti_specs, width=1) ## {&#39;aws_fargate&#39;: False, ## &#39;cpu&#39;: &#39;1024&#39;, ## &#39;esti_max_func_eval&#39;: 10, ## &#39;esti_method&#39;: &#39;MomentsSimuStates&#39;, ## &#39;esti_param_vec_count&#39;: 1, ## &#39;graph_frequncy&#39;: 2, ## &#39;it_default_group&#39;: None, ## &#39;memory&#39;: &#39;12345&#39;, ## &#39;momsets_type&#39;: [&#39;a&#39;, ## &#39;20180805a&#39;], ## &#39;workers&#39;: 1} 3.1.3 Python Command-line Arguments Parsing Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). import pprint import argparse 3.1.3.1 Positional and Optional Arguments Provide a positional and an optional argument. Position arguments are provided positions when the module is called, without prefixed by which parameter this is. Optional argument requires parameter specification. # Start parser for arguments parser = argparse.ArgumentParser() # Positional argument 1st, will be stored as int parser.add_argument(&#39;esrtype&#39;, type=int, help=&#39;positional argument 1st&#39;) # Positional argument 2nd, will be stored as string ## _StoreAction(option_strings=[], dest=&#39;esrtype&#39;, nargs=None, const=None, default=None, type=&lt;class &#39;int&#39;&gt;, choices=None, help=&#39;positional argument 1st&#39;, metavar=None) parser.add_argument(&#39;speckey&#39;, type=str, help=&#39;positional argument 2nd&#39;) # Optional argument ## _StoreAction(option_strings=[], dest=&#39;speckey&#39;, nargs=None, const=None, default=None, type=&lt;class &#39;str&#39;&gt;, choices=None, help=&#39;positional argument 2nd&#39;, metavar=None) parser.add_argument(&#39;-A&#39;, type=str, default=&#39;opt_arg_A_default_str_val&#39;) # Call with positional argument specified # Note that one is bracketed, will be interpreted as int ## _StoreAction(option_strings=[&#39;-A&#39;], dest=&#39;A&#39;, nargs=None, const=None, default=&#39;opt_arg_A_default_str_val&#39;, type=&lt;class &#39;str&#39;&gt;, choices=None, help=None, metavar=None) print(f&quot;Must specify posi. arg: {parser.parse_args([&#39;1&#39;, &#39;mpoly_1=esti_tinytst_mpoly_13=3=3&#39;])=}&quot;) # Call with two positional arguments and one optional # Note that the first positional argument becomes int, second beomce str ## Must specify posi. arg: parser.parse_args([&#39;1&#39;, &#39;mpoly_1=esti_tinytst_mpoly_13=3=3&#39;])=Namespace(A=&#39;opt_arg_A_default_str_val&#39;, esrtype=1, speckey=&#39;mpoly_1=esti_tinytst_mpoly_13=3=3&#39;) print(f&quot;With opt arg: {parser.parse_args([&#39;1&#39;, &#39;2&#39;, &#39;-A&#39;, &#39;abc&#39;])=}&quot;) ## With opt arg: parser.parse_args([&#39;1&#39;, &#39;2&#39;, &#39;-A&#39;, &#39;abc&#39;])=Namespace(A=&#39;abc&#39;, esrtype=1, speckey=&#39;2&#39;) 3.1.3.2 Short and Long Parameter Name Specifications Test below a boolean parameter that will be true or false. The default value is False. The parameter is called boolparam with short name abc. There is a variety of ways of setting the parameter to true. # Start parser for arguments parser = argparse.ArgumentParser() # short name for the first parameter is a, full name is abc, boolean parameter parser.add_argument(&#39;-abc&#39;, &#39;--boolparam&#39;, action=&quot;store_true&quot;, default=False) # default is false but turn on option so true ## _StoreTrueAction(option_strings=[&#39;-abc&#39;, &#39;--boolparam&#39;], dest=&#39;boolparam&#39;, nargs=0, const=True, default=False, type=None, choices=None, help=None, metavar=None) print(f&quot;default false: {parser.parse_args()=}&quot;) ## default false: parser.parse_args()=Namespace(boolparam=False) print(f&quot;default false, set to true, short all: {parser.parse_args([&#39;-abc&#39;])=}&quot;) ## default false, set to true, short all: parser.parse_args([&#39;-abc&#39;])=Namespace(boolparam=True) print(f&quot;default false, set to true, short part ab for abc: {parser.parse_args([&#39;-ab&#39;])=}&quot;) ## default false, set to true, short part ab for abc: parser.parse_args([&#39;-ab&#39;])=Namespace(boolparam=True) print(f&quot;default false, set to true, short part a for abc: {parser.parse_args([&#39;-a&#39;])=}&quot;) ## default false, set to true, short part a for abc: parser.parse_args([&#39;-a&#39;])=Namespace(boolparam=True) print(f&quot;default false, set to true, full param: {parser.parse_args([&#39;--boolparam&#39;])=}&quot;) ## default false, set to true, full param: parser.parse_args([&#39;--boolparam&#39;])=Namespace(boolparam=True) print(f&quot;default false, set to true, full param: {parser.parse_args([&#39;--boolparam&#39;])=}&quot;) ## default false, set to true, full param: parser.parse_args([&#39;--boolparam&#39;])=Namespace(boolparam=True) 3.1.3.3 A List of Allowed Values There is a parameter, only some specific values are allowed. Also provide help for each allowed option. Note added argparse.RawTextHelpFormatter to parse the next lines in help. # Start parse parser = argparse.ArgumentParser(description=&#39;Run ESR cmd&#39;, formatter_class=argparse.RawTextHelpFormatter) # A required positional argument parameter tht is int and can take eight possible values parser.add_argument(&#39;esrtype&#39;, type=int, choices=[1, 2, 3, 4, 5, 6, 7, 8], help=&#39;1. Simulate at N sets of parameter combinations\\n&#39; &#39;2. Polynomial approximation surface based on (1) &#39; &#39;for each outcome of interest, find best\\n&#39; &#39;3. Estimation at N sets of starting points with (2) as objective function\\n&#39; &#39;4. Gather results frorm (3), find M best.\\n&#39; &#39;5. Simulate (estimate once) at the top M best results from (4) actual model, &#39; &#39;compare objective to approximated from (3)\\n&#39; &#39;6. Gather results from (5), re-rank best of the M best from (4)\\n&#39; &#39;7. Estimate at the top M best results from (4) actual model, &#39; &#39;(4) M best are M best seeds\\n&#39; &#39;8. Gather results from (7), re-rank best of the final results from the M best seeds&#39;) # Print defaults ## _StoreAction(option_strings=[], dest=&#39;esrtype&#39;, nargs=None, const=None, default=None, type=&lt;class &#39;int&#39;&gt;, choices=[1, 2, 3, 4, 5, 6, 7, 8], help=&#39;1. Simulate at N sets of parameter combinations\\n2. Polynomial approximation surface based on (1) for each outcome of interest, find best\\n3. Estimation at N sets of starting points with (2) as objective function\\n4. Gather results frorm (3), find M best.\\n5. Simulate (estimate once) at the top M best results from (4) actual model, compare objective to approximated from (3)\\n6. Gather results from (5), re-rank best of the M best from (4)\\n7. Estimate at the top M best results from (4) actual model, (4) M best are M best seeds\\n8. Gather results from (7), re-rank best of the final results from the M best seeds&#39;, metavar=None) print(f&quot;provide 1 for the value of the positional argument: {parser.parse_args([&#39;1&#39;])=}&quot;) ## provide 1 for the value of the positional argument: parser.parse_args([&#39;1&#39;])=Namespace(esrtype=1) 3.1.3.4 Boolean, Integer, String and list Parameters How to handle parameters of different types, boolean, integer, string and list. For these four types, the same way to specify short and long parameter names. How to set the parameter types, and how to set default values for each type. # Start parser for arguments parser = argparse.ArgumentParser() # Single letter string parameters # Note dest name over-rides full name parser.add_argument(&#39;-cta&#39;, &#39;--cttaaaaa&#39;, dest=&quot;combo_type_a&quot;, default=&#39;e&#39;, type=str) # Multiple letters and integers # Note without dest full name is dest ## _StoreAction(option_strings=[&#39;-cta&#39;, &#39;--cttaaaaa&#39;], dest=&#39;combo_type_a&#39;, nargs=None, const=None, default=&#39;e&#39;, type=&lt;class &#39;str&#39;&gt;, choices=None, help=None, metavar=None) parser.add_argument(&#39;-ctb&#39;, &#39;--combo_type_b&#39;, default=&#39;20201025&#39;, type=str) # Multiple letters and integers # Note without dest and full name short name is parameter name ## _StoreAction(option_strings=[&#39;-ctb&#39;, &#39;--combo_type_b&#39;], dest=&#39;combo_type_b&#39;, nargs=None, const=None, default=&#39;20201025&#39;, type=&lt;class &#39;str&#39;&gt;, choices=None, help=None, metavar=None) parser.add_argument(&#39;-ctc&#39;, default=[&#39;list_tKap_mlt_ce1a2&#39;], nargs=&#39;+&#39;, type=str) # Print defaults ## _StoreAction(option_strings=[&#39;-ctc&#39;], dest=&#39;ctc&#39;, nargs=&#39;+&#39;, const=None, default=[&#39;list_tKap_mlt_ce1a2&#39;], type=&lt;class &#39;str&#39;&gt;, choices=None, help=None, metavar=None) print(f&quot;default false: {parser.parse_args()=}&quot;) # change parameters ## default false: parser.parse_args()=Namespace(combo_type_a=&#39;e&#39;, combo_type_b=&#39;20201025&#39;, ctc=[&#39;list_tKap_mlt_ce1a2&#39;]) print(f&quot;default false: {parser.parse_args([&#39;-ctb&#39;, &#39;20201111&#39;])=}&quot;) ## default false: parser.parse_args([&#39;-ctb&#39;, &#39;20201111&#39;])=Namespace(combo_type_a=&#39;e&#39;, combo_type_b=&#39;20201111&#39;, ctc=[&#39;list_tKap_mlt_ce1a2&#39;]) see variable-argument-lists. 3.1.3.5 Parse multiple parameter types Provide several types of parameters to a function, so that the function can be called easily container call to execute estimation. The types of parameters includes: A list including parameter information A string including estimation/computational controls Additional parameters # Start parser for arguments parser = argparse.ArgumentParser() # First (and only) positional argument for esrtype: parser.add_argument(&#39;esrtype&#39;, type=int, help=&#39;positional argument&#39;) # Optional argument ## _StoreAction(option_strings=[], dest=&#39;esrtype&#39;, nargs=None, const=None, default=None, type=&lt;class &#39;int&#39;&gt;, choices=None, help=&#39;positional argument&#39;, metavar=None) parser.add_argument(&#39;-s&#39;, dest=&#39;speckey&#39;, type=str, default=&#39;ng_s_t=esti_tinytst_thin_1=3=3&#39;, help=&quot;compute and esti keys and omments&quot;) # abc and e of comb_type ## _StoreAction(option_strings=[&#39;-s&#39;], dest=&#39;speckey&#39;, nargs=None, const=None, default=&#39;ng_s_t=esti_tinytst_thin_1=3=3&#39;, type=&lt;class &#39;str&#39;&gt;, choices=None, help=&#39;compute and esti keys and omments&#39;, metavar=None) parser.add_argument(&#39;-cta&#39;, dest=&quot;combo_type_a&quot;, default=&#39;e&#39;, type=str) ## _StoreAction(option_strings=[&#39;-cta&#39;], dest=&#39;combo_type_a&#39;, nargs=None, const=None, default=&#39;e&#39;, type=&lt;class &#39;str&#39;&gt;, choices=None, help=None, metavar=None) parser.add_argument(&#39;-ctb&#39;, dest=&quot;combo_type_b&quot;, default=&#39;20201025&#39;, type=str) ## _StoreAction(option_strings=[&#39;-ctb&#39;], dest=&#39;combo_type_b&#39;, nargs=None, const=None, default=&#39;20201025&#39;, type=&lt;class &#39;str&#39;&gt;, choices=None, help=None, metavar=None) parser.add_argument(&#39;-ctc&#39;, dest=&quot;combo_type_c&quot;, default=[&#39;list_tKap_mlt_ce1a2&#39;], nargs=&#39;+&#39;, type=str) ## _StoreAction(option_strings=[&#39;-ctc&#39;], dest=&#39;combo_type_c&#39;, nargs=&#39;+&#39;, const=None, default=[&#39;list_tKap_mlt_ce1a2&#39;], type=&lt;class &#39;str&#39;&gt;, choices=None, help=None, metavar=None) parser.add_argument(&#39;-cte1&#39;, dest=&quot;combo_type_e1&quot;, default=None, type=str) ## _StoreAction(option_strings=[&#39;-cte1&#39;], dest=&#39;combo_type_e1&#39;, nargs=None, const=None, default=None, type=&lt;class &#39;str&#39;&gt;, choices=None, help=None, metavar=None) parser.add_argument(&#39;-cte2&#39;, dest=&quot;combo_type_e2&quot;, default=&#39;mpoly_1=esti_tinytst_mpoly_13=3=3&#39;, type=str) # other parameters ## _StoreAction(option_strings=[&#39;-cte2&#39;], dest=&#39;combo_type_e2&#39;, nargs=None, const=None, default=&#39;mpoly_1=esti_tinytst_mpoly_13=3=3&#39;, type=&lt;class &#39;str&#39;&gt;, choices=None, help=None, metavar=None) parser.add_argument(&#39;-f&#39;, dest=&quot;save_directory_main&quot;, default=&#39;esti&#39;) # Default, must specify erstype ## _StoreAction(option_strings=[&#39;-f&#39;], dest=&#39;save_directory_main&#39;, nargs=None, const=None, default=&#39;esti&#39;, type=None, choices=None, help=None, metavar=None) print(f&quot;default false: {parser.parse_args([&#39;1&#39;])=}&quot;) # Print with the nargs+ arguments # specified two elements, abc, and efg for nargs ctc, becomes a string list ## default false: parser.parse_args([&#39;1&#39;])=Namespace(combo_type_a=&#39;e&#39;, combo_type_b=&#39;20201025&#39;, combo_type_c=[&#39;list_tKap_mlt_ce1a2&#39;], combo_type_e1=None, combo_type_e2=&#39;mpoly_1=esti_tinytst_mpoly_13=3=3&#39;, esrtype=1, save_directory_main=&#39;esti&#39;, speckey=&#39;ng_s_t=esti_tinytst_thin_1=3=3&#39;) print(f&quot;default false: {parser.parse_args([&#39;1&#39;, &#39;-ctc&#39;, &#39;abc&#39;, &#39;efg&#39;])=}&quot;) # one input for ctc, still generates a list ## default false: parser.parse_args([&#39;1&#39;, &#39;-ctc&#39;, &#39;abc&#39;, &#39;efg&#39;])=Namespace(combo_type_a=&#39;e&#39;, combo_type_b=&#39;20201025&#39;, combo_type_c=[&#39;abc&#39;, &#39;efg&#39;], combo_type_e1=None, combo_type_e2=&#39;mpoly_1=esti_tinytst_mpoly_13=3=3&#39;, esrtype=1, save_directory_main=&#39;esti&#39;, speckey=&#39;ng_s_t=esti_tinytst_thin_1=3=3&#39;) print(f&quot;default false: {parser.parse_args([&#39;1&#39;, &#39;-ctc&#39;, &#39;abc&#39;])=}&quot;) ## default false: parser.parse_args([&#39;1&#39;, &#39;-ctc&#39;, &#39;abc&#39;])=Namespace(combo_type_a=&#39;e&#39;, combo_type_b=&#39;20201025&#39;, combo_type_c=[&#39;abc&#39;], combo_type_e1=None, combo_type_e2=&#39;mpoly_1=esti_tinytst_mpoly_13=3=3&#39;, esrtype=1, save_directory_main=&#39;esti&#39;, speckey=&#39;ng_s_t=esti_tinytst_thin_1=3=3&#39;) 3.1.4 Function Returns Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 3.1.4.1 Function with Multiple Optional Returns There is a function that is already written, that returns some string value. Without interrupting the existing function, now add an additional return for the function. There is some conditional statement that controls whether the function returns one or two value. In the example below, if the path contains Create a testing function: def get_val(spn_path): if &#39;G:&#39; in spn_path: # this returns a tuple of length 2 return spn_path, &#39;G:/repos&#39; else: return spn_path Call the function with one return, in the two calls below, the first call returns a tuple # Return tuple tp_st_return = get_val(&quot;G:/Dropbox (UH-ECON)&quot;) # Unpack tuple return st_path_a, st_path_b = get_val(&quot;G:/Dropbox (UH-ECON)&quot;) # Single element return st_return = get_val(&quot;C:/Dropbox (UH-ECON)&quot;) # Print print(f&#39;{tp_st_return=} and {st_return=}&#39;) ## tp_st_return=(&#39;G:/Dropbox (UH-ECON)&#39;, &#39;G:/repos&#39;) and st_return=&#39;C:/Dropbox (UH-ECON)&#39; print(f&#39;{st_path_a=} and {st_path_b=}&#39;) ## st_path_a=&#39;G:/Dropbox (UH-ECON)&#39; and st_path_b=&#39;G:/repos&#39; print(f&#39;{isinstance(tp_st_return, str)=}&#39;) ## isinstance(tp_st_return, str)=False print(f&#39;{isinstance(tp_st_return, tuple)=}&#39;) ## isinstance(tp_st_return, tuple)=True print(f&#39;{isinstance(st_return, str)=}&#39;) ## isinstance(st_return, str)=True print(f&#39;{isinstance(st_return, tuple)=}&#39;) ## isinstance(st_return, tuple)=False 3.2 Exceptions 3.2.1 Exception Handling Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 3.2.1.1 A function That Raises an Error with Try Statement Catching it Below, we have a function that will raise a TypeError unless we provide an integer input. The function is called with integer input and then called with a string input. The string input is wrapped in a try and except call, where the exception catches the TypeError and prints it. # define the function def ffi_error_test(gn_speckey=None): if isinstance(gn_speckey, int): print(f&#39;{gn_speckey=} is an integer&#39;) else: raise TypeError(f&#39;{gn_speckey=} is not an integer&#39;) # Call function with integer error_test(1) # Call function with string ## gn_speckey=1 is an integer try: ffi_error_test(&#39;abc&#39;) except TypeError as error: print(&#39;Caught this error: &#39; + repr(error)) ## Caught this error: TypeError(&quot;gn_speckey=&#39;abc&#39; is not an integer&quot;) 3.2.1.2 Catch an Exception Noisily Rather than only catching the last element of the exception, show the full trace. Notice in the example below, the second element of the loop does not work as function input. With exception catching, the loop continued despite the second element not working. The traceback shows more details at the end with full trace of the exception from the second element of the list as input for ffi_error_test(). import traceback import numpy as np ls_ob_inputs = [2, [&#39;abc&#39;,&#39;efg&#39;], 1, 123] for ob_input in ls_ob_inputs: print(f&#39;try input {ob_input=} with the error_test function:&#39;) try: ffi_error_test(ob_input) except TypeError as error: traceback.print_exc() print(&#39;Caught this error: &#39; + repr(error)) ## try input ob_input=2 with the error_test function: ## gn_speckey=2 is an integer ## try input ob_input=[&#39;abc&#39;, &#39;efg&#39;] with the error_test function: ## Caught this error: TypeError(&quot;gn_speckey=[&#39;abc&#39;, &#39;efg&#39;] is not an integer&quot;) ## try input ob_input=1 with the error_test function: ## gn_speckey=1 is an integer ## try input ob_input=123 with the error_test function: ## gn_speckey=123 is an integer ## ## Traceback (most recent call last): ## File &quot;&lt;string&gt;&quot;, line 4, in &lt;module&gt; ## File &quot;&lt;string&gt;&quot;, line 5, in ffi_error_test ## TypeError: gn_speckey=[&#39;abc&#39;, &#39;efg&#39;] is not an integer see How to print the stack trace of an exception object in Python? 3.2.1.3 Handle Parameters When Conditions Not Satisfied There is a function, that can estimate or simulate, under both functionalities, there is a common string parameter, that requires specifying estimation or simulation conditions. The common string parameter should be a simple string without special separators in the case of simulation, and should be four strings concatenated together with equal sign for estimation. Generate an exception if the function is called for estimation but the string parameter does not have the required structure. Python 3 TypeError Manually raising (throwing) an exception in Python # ls_st_spec_key_dict = [&#39;NG_S_D&#39;, &#39;NG_S_D=KAP_M0_NLD_M_SIMU=2=3&#39;] # st_connector = &#39;=&#39; # ls_st_esti_simu = [&#39;esti&#39;, &#39;simu&#39;] # for st_spec_key_dict in ls_st_spec_key_dict: # for st_esti_simu in ls_st_esti_simu: # if st_esti_simu == &#39;simu&#39;: # if len(st_spec_key_dict.split(st_connector)) and # print(&#39;simulate with &#39; + st_spec_key_dict) if estimate and not isinstance(spec_key_dict, str): pass elif (estimate is False and isinstance(spec_key_dict, str)) or (estimate is False and isinstance(spec_key_dict, dict)): pass else: st_error = &#39;speckey=&#39; + speckey + &#39; and estimate=&#39; + str(estimate) raise ValueError(st_error) 3.2.1.4 Proceed Despite Error Sometimes, code should proceed despite error, to finish a loop for example: # estimate at each initial random points for it_esti_ctr in range(esti_param_vec_count): # Update the 3rd element of combo_type, which determines which draw index to use combo_type[3] = it_esti_ctr try: invoke_run_main.invoke_main(combo_type, **dc_invoke_main_args) except Exception: logging.critical(f&#39;Finished this {it_esti_ctr=} of {range(esti_param_vec_count)=}&#39;) "],["statistics.html", "Chapter 4 Statistics 4.1 Markov Process", " Chapter 4 Statistics 4.1 Markov Process 4.1.1 Close Value Comparison Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). import sys as sys import numpy as np import pprint 4.1.1.1 Generate a Markov Transition Matrix With numerical probability approximations, discrete random variables often are not exact, given an AR(1) transition matrix, how to check whether the conditional probabilities conditional on each current state (row) sums up to one? First define the AR(1) transition matrix, which is from a model of asset transitions. This is a 50 by 50 matrix. mt_ar1_trans = np.array([[0.4334, 0.5183, 0.0454, 0.0027, 0.0002, 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0.2624, 0.5967, 0.1245, 0.0145, 0.0016, 0.0002, 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0.1673, 0.5918, 0.2005, 0.0343, 0.0052, 0.0008, 0.0001, 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0.0312, 0.6497, 0.2774, 0.0371, 0.0041, 0.0005, 0.0001, 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0.0681, 0.6569, 0.2379, 0.0327, 0.0038, 0.0005, 0.0001, 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0.2201, 0.581 , 0.168 , 0.0264, 0.0038, 0.0006, 0.0001, 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0.0044, 0.4312, 0.4356, 0.1069, 0.0183, 0.003 , 0.0005, 0.0001,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.1408, 0.5552, 0.2403, 0.052 , 0.0095, 0.0017, 0.0003,0.0001, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0.1666, 0.5902, 0.2019, 0.0349, 0.0053, 0.0008, 0.0001,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0.2065, 0.5668, 0.1869, 0.0335, 0.0053, 0.0009,0.0001, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0.2414, 0.5453, 0.1748, 0.0321, 0.0053,0.0009, 0.0002, 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0.0172, 0.4156, 0.4019, 0.1281, 0.0293, 0.0062,0.0013, 0.0003, 0.0001, 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0.0033, 0.3222, 0.4594, 0.1655, 0.0391,0.0083, 0.0017, 0.0004, 0.0001, 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0.0111, 0.3744, 0.4215, 0.1471,0.0357, 0.0079, 0.0017, 0.0004, 0.0001, 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0.1555, 0.504 , 0.2526,0.0682, 0.0154, 0.0034, 0.0008, 0.0002, 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0.1987, 0.5249, 0.215 ,0.0493, 0.0097, 0.0019, 0.0004, 0.0001, 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0.0041, 0.3513, 0.4533,0.1499, 0.0331, 0.0066, 0.0013, 0.0003, 0.0001, 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.0247, 0.441 ,0.3835, 0.1174, 0.0264, 0.0055, 0.0012, 0.0003, 0.0001, 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.1049,0.502 , 0.2887, 0.0809, 0.0183, 0.004 , 0.0009, 0.0002, 0.0001, 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.0003,0.1962, 0.4888, 0.2319, 0.0636, 0.0148, 0.0034, 0.0008, 0.0002, 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.0087, 0.3362, 0.4294, 0.1674, 0.0444, 0.0105, 0.0025, 0.0006, 0.0001, 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.0001, 0.154 , 0.4801, 0.2617, 0.0785, 0.0195, 0.0046, 0.0011, 0.0003, 0.0001, 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.0001, 0.1467, 0.48 , 0.2664, 0.0804, 0.02 , 0.0048, 0.0012, 0.0003, 0.0001, 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0.0149, 0.3543, 0.4103, 0.1614, 0.0444, 0.011 , 0.0027, 0.0007, 0.0002, 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0.0438, 0.4122, 0.3611, 0.1334, 0.0369, 0.0094, 0.0024, 0.0006, 0.0002,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0.1159, 0.452 , 0.2939, 0.1007, 0.0278, 0.0072, 0.0019, 0.0005,0.0001, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0.0012, 0.198 , 0.4463, 0.2436, 0.0804, 0.0224, 0.0059, 0.0016,0.0004, 0.0001, 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0.0087, 0.2821, 0.4181, 0.2011, 0.0649, 0.0183, 0.005 ,0.0014, 0.0004, 0.0001, 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.0842, 0.4174, 0.3217, 0.1244, 0.0376, 0.0105,0.0029, 0.0008, 0.0002, 0.0001, 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.0828, 0.4166, 0.3229, 0.1251, 0.0379, 0.0106,0.0029, 0.0008, 0.0002, 0.0001, 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.0119, 0.2907, 0.4075, 0.1979, 0.0656, 0.019 ,0.0053, 0.0015, 0.0004, 0.0001, 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0.0424, 0.3654, 0.3618, 0.1581, 0.0513,0.015 , 0.0043, 0.0012, 0.0004, 0.0001, 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0.0001, 0.1078, 0.4112, 0.3043, 0.1217,0.0388, 0.0114, 0.0033, 0.001 , 0.0003, 0.0001, 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0.0015, 0.1714, 0.4155, 0.264 ,0.1015, 0.0323, 0.0097, 0.0029, 0.0009, 0.0003, 0.0001, 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0.0093, 0.2496, 0.4001,0.2214, 0.082 , 0.0261, 0.0079, 0.0024, 0.0007, 0.0002, 0.0001, 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0.041 , 0.3374,0.3591, 0.1729, 0.0615, 0.0195, 0.006 , 0.0018, 0.0006, 0.0002, 0.0001, 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0.0295, 0.315 ,0.3712, 0.186 , 0.0673, 0.0215, 0.0066, 0.002 , 0.0006, 0.0002, 0.0001, 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0.0295, 0.315 ,0.3712, 0.186 , 0.0673, 0.0215, 0.0066, 0.002 , 0.0006, 0.0002, 0.0001, 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0.0036, 0.1927,0.4021, 0.2527, 0.1004, 0.0334, 0.0104, 0.0032, 0.001 , 0.0003, 0.0001, 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.018 ,0.2749, 0.3813, 0.2082, 0.0792, 0.0262, 0.0083, 0.0026, 0.0008, 0.0003, 0.0001, 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.0539, 0.3414, 0.344 , 0.1684, 0.0621, 0.0205, 0.0065, 0.0021, 0.0007, 0.0002, 0.0001,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0.0005, 0.1155, 0.3788, 0.2986, 0.1345, 0.0485, 0.016 , 0.0052, 0.0017, 0.0006, 0.0002,0.0001, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0.0042, 0.1819, 0.385 , 0.259 , 0.1109, 0.0395, 0.0132, 0.0043, 0.0014, 0.0005,0.0002, 0.0001, 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0.0183, 0.2571, 0.3709, 0.2174, 0.089 , 0.0314, 0.0105, 0.0035, 0.0012,0.0004, 0.0001, 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0.0041, 0.1763, 0.3796, 0.2619, 0.1149, 0.0419, 0.0142, 0.0047, 0.0016,0.0005, 0.0002, 0.0001, 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0.0028, 0.1598, 0.3781, 0.2712, 0.1209, 0.0444, 0.0151, 0.005 , 0.0017,0.0006, 0.0002, 0.0001, 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0.0414, 0.3051, 0.3488, 0.1888, 0.0756, 0.0267, 0.009 , 0.003 ,0.001 , 0.0004, 0.0001, 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0.0002, 0.0784, 0.3412, 0.3202, 0.1621, 0.0637, 0.0225, 0.0077,0.0026, 0.0009, 0.0003, 0.0001, 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0.0018, 0.1352, 0.3634, 0.2843, 0.135 , 0.0521, 0.0184,0.0063, 0.0022, 0.0008, 0.0003, 0.0001, 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.0111, 0.2115, 0.365 , 0.2415, 0.1079, 0.0409,0.0145, 0.005 , 0.0017, 0.0006, 0.0002, 0.0001, 0., 0., 0., 0., 0.,0., 0., 0., 0., 0., 0.]]) # print print(f&#39;{mt_ar1_trans.shape=}&#39;) ## mt_ar1_trans.shape=(50, 50) What are the row sums, and how close is each to 1: # Sum for each row across columns ar_row_sums_ar1 = np.sum(mt_ar1_trans, axis=1) fl_sum_to_match = 1 # print print(f&#39;{ar_row_sums_ar1=}&#39;) ## ar_row_sums_ar1=array([1. , 0.9999, 1. , 1.0001, 1. , 1. , 1. , 0.9999, ## 0.9998, 1. , 1. , 1. , 1. , 0.9999, 1.0001, 1. , ## 1. , 1.0001, 1. , 1. , 0.9998, 1. , 1. , 0.9999, ## 1. , 1. , 0.9999, 1.0001, 0.9998, 0.9999, 0.9999, 1. , ## 1. , 1.0001, 0.9998, 1.0001, 1. , 1. , 0.9999, 0.9999, ## 0.9999, 1.0002, 1.0002, 0.9998, 1. , 0.9999, 0.9999, 0.9999, ## 0.9999, 1. ]) print(f&#39;Total Avg Diff = {np.mean(abs(ar_row_sums_ar1-fl_sum_to_match))=}&#39;) ## Total Avg Diff = np.mean(abs(ar_row_sums_ar1-fl_sum_to_match))=6.800000000001916e-05 4.1.1.2 Check Row by Row Tolerance Check for tolerance, rtol is the absolute base gap allowed, atol is multipled by fl_sum_to_match, below, we can check row by row, and see if any rows does not meet the approximately equality condition. If there is any one row that does not match this, then set condition for overall matrix checking to false. fl_atol = 1e-08 print(f&#39;with {fl_atol=}, many rows do not approximately equal to 1&#39;) ## with fl_atol=1e-08, many rows do not approximately equal to 1 print(f&#39;{[np.allclose(fl_row_sum, fl_sum_to_match, rtol=0, atol=fl_atol) for fl_row_sum in ar_row_sums_ar1]=}&#39;) ## [np.allclose(fl_row_sum, fl_sum_to_match, rtol=0, atol=fl_atol) for fl_row_sum in ar_row_sums_ar1]=[True, False, True, False, True, True, True, False, False, True, True, True, True, False, False, True, True, False, True, True, False, True, True, False, True, True, False, False, False, False, False, True, True, False, False, False, True, True, False, False, False, False, False, False, True, False, False, False, False, True] print(f&#39;{np.allclose(ar_row_sums_ar1, fl_sum_to_match, rtol=0, atol=fl_atol)=}&#39;) ## np.allclose(ar_row_sums_ar1, fl_sum_to_match, rtol=0, atol=fl_atol)=False fl_atol = 1e-03 print(f&#39;With {fl_atol=}, all rows approximately equal to 1&#39;) ## With fl_atol=0.001, all rows approximately equal to 1 print(f&#39;{[np.allclose(fl_row_sum, fl_sum_to_match, rtol=0, atol=fl_atol) for fl_row_sum in ar_row_sums_ar1]=}&#39;) ## [np.allclose(fl_row_sum, fl_sum_to_match, rtol=0, atol=fl_atol) for fl_row_sum in ar_row_sums_ar1]=[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True] print(f&#39;{np.allclose(ar_row_sums_ar1, fl_sum_to_match, rtol=0, atol=fl_atol)=}&#39;) ## np.allclose(ar_row_sums_ar1, fl_sum_to_match, rtol=0, atol=fl_atol)=True 4.1.1.3 Check Joint Tolerance For practical usages, we set joint condition. The difference between the sum of any row and 1 should be less than a threshold, additionally, the total average gap between row sums and 1 should be less than a threshold. Do this so that can have a more relaxed per-row tolerance requirement, and more stringent average requirement. Setting only a stringent per row requirement might be too restive, and reject transition matrixes that do not have problems. # criteria fl_atol_per_row = 1e-03 fl_atol_avg_row = 1e-04 # per-row check bl_per_row_pass = np.allclose(ar_row_sums_ar1, fl_sum_to_match, rtol=0, atol=fl_atol_per_row) # all-rows check fl_row_gap_mean = np.mean(abs(ar_row_sums_ar1-fl_sum_to_match)) bl_avg_row_pass = np.allclose(fl_row_gap_mean+fl_sum_to_match, fl_sum_to_match, rtol=0, atol=fl_atol_avg_row) # Joint bl_ar1_sum_pass = bl_per_row_pass and bl_avg_row_pass # Print print(f&#39;{bl_per_row_pass=}&#39;) ## bl_per_row_pass=True print(f&#39;{bl_avg_row_pass=} and {fl_row_gap_mean=}&#39;) ## bl_avg_row_pass=True and fl_row_gap_mean=6.800000000001916e-05 print(f&#39;{bl_ar1_sum_pass=}&#39;) ## bl_ar1_sum_pass=True 4.1.1.4 Normalize Transition Matrix Row Sum Having pass the checks, would like to have conditional probability sum up to 1, so normalize. Division by broadcast, reshape the sum for each row as column, divide all columns for the same row by the same sum value. New sum of normalized ar(1) for each row is now equal to 1. # current row sums ar_row_sums_ar1 = np.sum(mt_ar1_trans, axis=1) ar_row_sums_ar1 = np.reshape(ar_row_sums_ar1, [-1, 1]) # Update row values mt_ar1_trans_norm = mt_ar1_trans/np.reshape(ar_row_sums_ar1, [-1, 1]) ar_row_sums_ar1_norm = np.sum(mt_ar1_trans_norm, axis=1) ar_row_sums_ar1_norm = np.reshape(ar_row_sums_ar1_norm, [-1, 1]) # check sum print(f&#39;{np.column_stack([ar_row_sums_ar1, ar_row_sums_ar1_norm])=}&#39;) ## np.column_stack([ar_row_sums_ar1, ar_row_sums_ar1_norm])=array([[1. , 1. ], ## [0.9999, 1. ], ## [1. , 1. ], ## [1.0001, 1. ], ## [1. , 1. ], ## [1. , 1. ], ## [1. , 1. ], ## [0.9999, 1. ], ## [0.9998, 1. ], ## [1. , 1. ], ## [1. , 1. ], ## [1. , 1. ], ## [1. , 1. ], ## [0.9999, 1. ], ## [1.0001, 1. ], ## [1. , 1. ], ## [1. , 1. ], ## [1.0001, 1. ], ## [1. , 1. ], ## [1. , 1. ], ## [0.9998, 1. ], ## [1. , 1. ], ## [1. , 1. ], ## [0.9999, 1. ], ## [1. , 1. ], ## [1. , 1. ], ## [0.9999, 1. ], ## [1.0001, 1. ], ## [0.9998, 1. ], ## [0.9999, 1. ], ## [0.9999, 1. ], ## [1. , 1. ], ## [1. , 1. ], ## [1.0001, 1. ], ## [0.9998, 1. ], ## [1.0001, 1. ], ## [1. , 1. ], ## [1. , 1. ], ## [0.9999, 1. ], ## [0.9999, 1. ], ## [0.9999, 1. ], ## [1.0002, 1. ], ## [1.0002, 1. ], ## [0.9998, 1. ], ## [1. , 1. ], ## [0.9999, 1. ], ## [0.9999, 1. ], ## [0.9999, 1. ], ## [0.9999, 1. ], ## [1. , 1. ]]) "],["tables-and-graphs.html", "Chapter 5 Tables and Graphs 5.1 Matplotlib Base Plots", " Chapter 5 Tables and Graphs 5.1 Matplotlib Base Plots 5.1.1 Line and Scatter Plots Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 5.1.1.1 Plot Random Walk and White Noise Jointly Given x and y coordinates, plot out two lines. see matplotlib.pyplot.plot. Here we will plot out the extremes of AR(1), white noise (no persistence), and random walk (fully persistent shocks). # Import Packages import numpy as np import matplotlib.pyplot as plt # Generate X and Y np.random.seed(123) ar_fl_y1_rand = np.random.normal(0, 2, 100) ar_fl_y2_rand = np.cumsum(np.random.normal(0, 1, 100)) ar_it_x_grid = np.arange(1,len(ar_fl_y1_rand)+1) # Start Figure fig, ax = plt.subplots() # Graph ax.plot(ar_it_x_grid, ar_fl_y1_rand, color=&#39;blue&#39;, linestyle=&#39;dashed&#39;, label=&#39;sd=2, 0 persistence&#39;) ## [&lt;matplotlib.lines.Line2D object at 0x000001716B9A56A0&gt;] ax.plot(ar_it_x_grid, ar_fl_y2_rand, color=&#39;red&#39;, linestyle=&#39;solid&#39;, label=&#39;sd=1, random walk&#39;) # Labeling ## [&lt;matplotlib.lines.Line2D object at 0x000001716E16BA30&gt;] ax.legend(loc=&#39;upper left&#39;) ## &lt;matplotlib.legend.Legend object at 0x000001716E171D90&gt; plt.ylabel(&#39;Random Standard Normal Draws&#39;) ## Text(0, 0.5, &#39;Random Standard Normal Draws&#39;) plt.xlabel(&#39;Time Periods&#39;) ## Text(0.5, 0, &#39;Time Periods&#39;) plt.title(&#39;White Noise&#39;) ## Text(0.5, 1.0, &#39;White Noise&#39;) plt.grid() plt.show() 5.1.2 Text Plot Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 5.1.2.1 Plot Text Plot Text as Image. Create text with different alignment and rotation. # Import Packages import matplotlib.pyplot as plt import textwrap import json # Dict of String to String dc_path = {&#39;C:\\\\Users\\\\fan\\\\Documents\\\\Dropbox (UH-ECON)\\\\repos\\\\Tex4Econ\\\\&#39; &#39;_other\\\\equation\\\\cases.tex&#39;: &#39;C:/Users/fan/Documents/cases.pdf&#39;, &#39;C:\\\\Users\\\\fan\\\\Documents\\\\Dropbox (UH-ECON)\\\\repos\\\\Tex4Econ\\\\&#39; &#39;_other\\\\symbols\\\\fs_symbols.tex&#39;: &#39;C:/Users/fan/Documents/fs_symbols.pdf&#39;} st_dc_path = textwrap.fill(json.dumps(dc_path), width = 70) # Start Plot fig, ax = plt.subplots() # Text Plot ax.text(0.5, 0.5, st_dc_path, horizontalalignment=&#39;center&#39;, verticalalignment=&#39;center&#39;, fontsize=14, color=&#39;black&#39;, transform=ax.transAxes) # Labeling ## Text(0.5, 0.5, &#39;{&quot;C:\\\\\\\\Users\\\\\\\\fan\\\\\\\\Documents\\\\\\\\Dropbox (UH-\\nECON)\\\\\\\\repos\\\\\\\\Tex4Econ\\\\\\\\_other\\\\\\\\equation\\\\\\\\cases.tex&quot;:\\n&quot;C:/Users/fan/Documents/cases.pdf&quot;,\\n&quot;C:\\\\\\\\Users\\\\\\\\fan\\\\\\\\Documents\\\\\\\\Dropbox (UH-\\nECON)\\\\\\\\repos\\\\\\\\Tex4Econ\\\\\\\\_other\\\\\\\\symbols\\\\\\\\fs_symbols.tex&quot;:\\n&quot;C:/Users/fan/Documents/fs_symbols.pdf&quot;}&#39;) ax.set_axis_off() plt.show() "],["amazon-web-services.html", "Chapter 6 Amazon Web Services 6.1 AWS Setup 6.2 S3 6.3 Batch", " Chapter 6 Amazon Web Services 6.1 AWS Setup 6.1.1 AWS Setup Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 6.1.1.1 Installation on Local Machine First install anaconda, git, and associated programs. Putty access to .pem key conda aws environment below 6.1.1.2 Conda AWS Environment Can Start and Stop instances from Conda Prompt after this. conda deactivate conda list env conda env remove -n wk_aws conda create -n wk_aws -y conda activate wk_aws # Install External Tools conda install -c anaconda pip -y # Command line interface conda install -c conda-forge awscli -y # Programmatically send JSON instructions with boto3 conda install -c anaconda boto3 -y 6.1.1.3 AWS Account set-up Sign-up for AWS web services account (can be the same as your Amazon shopping account) Register for AWS Educate to get student or faculty voucher. The University of Houston is a part of AWS Educate, choose educator or student, should hear back within 24 hours with coupon code. UH students can get $100, faculty can get $200. 6.1.1.4 Start a AWS Instance and Link Local to Remote Amazon has a lot of tutorials. Here is an outline. Generate keypair on AWS, aws guide this gives you a .pem file which you download and Amazon also remembers local computers with the right .pem file can talk to your AWS instances You might need to invoke the chmod command below to set permission: chmod 400 &quot;C:/Users/fan/Documents/Dropbox (UH-ECON)/Programming/AWS/fan_wang-key-pair-us_east_nv.pem&quot; Launching Instance: Go to your console, choose EC2, choose launch instance, select Amazon Linux Instance (review and launch) Instance security: select VPC security group: I have for example: fan_wang_SG_us_east_nv_VPC (edit security group and submit) Security group can allow any IP address to access your instance or just specific ones. AWS has a tool here that just allows your current IP to access the EC2 instance Instance access key: Select right keypair (your .pem key), fan_wang-key-pair-us_east_nv (prompted after submitting) For SSH in, you can use Putty. aws guide tell Putty your AWS instance DNS address and where your pem key is Can use a Putty client to enter an EC2 instance For SSH, can also do the process below: open git bash (install putty before) ssh-agent -s eval $(ssh-agent -s) Tell SSH where pem key is: ssh-add &quot;C:/Users/fan/Documents/Dropbox (UH-ECON)/Programming/AWS/fan_wang-key-pair-us_east_nv.pem&quot; You will find a public DNS address for your aws instance on the AWS user interface page # ssh git bash command line # for ubuntu machine ssh ubuntu@ec2-54-197-6-153.compute-1.amazonaws.com # for aws linux ssh ec2-user@ec2-52-23-218-117.compute-1.amazonaws.com # quit aws instance # ctrl + D if get: Permission denied (publickey), see: Trying to connect with the wrong key. Are you sure this instance is using this keypair? Trying to connect with the wrong username. ubuntu is the username for the ubuntu based AWS distribution, but on some others its ec2-user (or admin on some Debians, according to Bogdan Kulbidas answer)(can also be root, fedora, see below) Trying to connect the wrong host. Is that the right host you are trying to log in to? You can log in generally like this, note the instance gets new public DNS IP address every time you restart it: LOCALPEM=&quot;C:/Users/fan/Documents/Dropbox (UH-ECON)/Programming/AWS/fan_wang-key-pair-us_east_nv.pem&quot; IPADD=34.207.250.160 REMOTEIP=ec2-user@$IPADD ssh-keygen -R $IPADD ssh -i &quot;$LOCALPEM&quot; $REMOTEIP 6.1.1.5 Use AWSCLI to Start and Stop an Instance Install AWS CLI Create individual IAM users Follow instructions to Configure your awscli, and profit access key id and secrete access key when prompted. do not copy and paste the Key ID and Access Key. They are example, type these in as answers given config prompt: # aws configure AWS Access Key ID [None]: XXXXIOSFODNN7EXAMPLE AWS Secret Access Key [None]: wXalrXXtnXXXX/X7XXXXX/bXxXfiCXXXXXXXXXXX Default region name [None]: us-west-1 Default output format [None]: json this creates under a folder like this: C:/Users/fan/.aws, inside the folder these info will be stored in a configuration file. # the credentials file [default] aws_access_key_id = XXXXIOSFODNN7EXAMPLE aws_secret_access_key = wXalrXXtnXXXXX7XXXXXbXxXfiCXXXXXXXXXXX then when you use aws cli, you will automatically be authenticated Start an instance in console first (or directly in command line). Stop it. do not terminate. Now this instance will have a fixed instance ID. Its DNS IP address will change every time you restart it, but its instance ID is fixed. Instance ID is found easily in the EC2 Console. Launch an instance aws ec2 run-instances --image-id ami-xxxxxxxx --count 1 --instance-type t2.micro --key-name MyKeyPair --security-group-ids sg-xxxxxxxx --subnet-id subnet-xxxxxxxx Start an instance aws ec2 start-instances --instance-ids i-XXXXXXXX aws ec2 start-instances --instance-ids i-040c856530b2619bc Stop an instance aws ec2 stop-instances --instance-ids i-XXXXXXXX aws ec2 stop-instances --instance-ids i-040c856530b2619bc 6.1.1.6 Set-up SSM on EC2 Instance To execute commandlines etc remote on EC2, need to set up SSM: AWS Systems Manager Agent (SSM Agent) SSM-agent is already installed in Amazon Linux. Error Message regarding InvalidInstanceId. The following scenarios can result in this error message: Instance id is invalid (in the comments you have verified it isnt) Instance is in a different region (in the comments you have verified it isnt) Instance is not currently in the Running state Instance does not have the AWS SSM agent installed and running. You have to create and attach the policy AmazonSSMFullAccess to the machine (thats maybe more broad than you need) but that was why it wasnt working for me You do that by clicking on (when selected on the ec2 instance) Action &gt; Instance Settings &gt; Attach/Replace IAM Role then create a role for ec2 that has that permission then attach, should take like 5-10 mins to pop up in SYSTEMS MANAGER SHARED RESOURCES - Managed Instances as mark mentions.  Glen Thompson Sep 20 18 at 16:31 # Start SSM Agent with sudo systemctl start amazon-ssm-agent 6.1.2 AWS Boto3 Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 6.1.2.1 Basics Create local .aws folder under user for example that has credential information, this will be useful for AWS command line operations. # IN C:\\Users\\fan\\.aws # config file [default] region = us-east-1 output = json # credentials file [default] aws_access_key_id = XKIXXXGSXXXBZXX43XXX aws_secret_access_key = xxTgp9r0f4XXXXXXX1XXlG1vTy07wydxXXXXXX11 Additionally, or alternatively, for boto3 operations, store in for example a yml file, so that appropriate value could be obtained. - main_aws_id: 710673677961, aws_access_key_id: XKIXXXGSXXXBZXX43XXX aws_secret_access_key: xxTgp9r0f4XXXXXXX1XXlG1vTy07wydxXXXXXX11 region: us-east-1 main_ec2_instance_id: i-YYYxYYYYYYx2619xx main_ec2_linux_ami: ami-0xYYYYYxx95x71x9 main_ec2_public_subnet: subnet-d9xxxxYY fargate_vpc_name: FanCluster fargate_vpc_id: vpc-xxx5xYYY fargate_public_subnet: subnet-e3dYYYxx fargate_security_group: sg-17xxxxYx fargate_task_executionRoleArn: ecsTaskExecutionRole batch_task_executionRoleArn: ecsExecutionRole fargate_route_table: rtb-5xxxYx25 date_start: 20180701 6.1.2.2 Start Client Service For the various AWS services, could use Boto3 to access and use programmatically. To use any particular service, first start the client for that service: boto3 client. We load AWS access key and secret acess key etc in from a yaml file to start boto3 client. We then start the client for AWS Batch. And then describe a compute environment. import boto3 import yaml import pprint # Load YAML file son_aws_yml = &quot;C:/Users/fan/fanwangecon.github.io/_data/aws.yml&quot; fl_yaml = open(son_aws_yml) ls_dict_yml = yaml.load(fl_yaml, Loader=yaml.BaseLoader) # Get the first element of the yml list of dicts aws_yml_dict_yml = ls_dict_yml[0] # Use AWS Personal Access Keys etc to start boto3 client aws_batch = boto3.client(&#39;batch&#39;, aws_access_key_id=aws_yml_dict_yml[&#39;aws_access_key_id&#39;], aws_secret_access_key=aws_yml_dict_yml[&#39;aws_secret_access_key&#39;], region_name=aws_yml_dict_yml[&#39;region&#39;]) # Show a compute environment Delete some Personal Information ob_response = aws_batch.describe_compute_environments(computeEnvironments=[&quot;SpotEnv2560&quot;]) ob_response[&#39;ResponseMetadata&#39;] = &#39;&#39; ob_response[&#39;computeEnvironments&#39;][0][&#39;ecsClusterArn&#39;] = &#39;&#39; ob_response[&#39;computeEnvironments&#39;][0][&#39;serviceRole&#39;] = &#39;&#39; ob_response[&#39;computeEnvironments&#39;][0][&#39;computeResources&#39;][&#39;instanceRole&#39;] = &#39;&#39; pprint.pprint(ob_response, width=1) ## {&#39;ResponseMetadata&#39;: &#39;&#39;, ## &#39;computeEnvironments&#39;: [{&#39;computeEnvironmentArn&#39;: &#39;arn:aws:batch:us-east-1:710673677961:compute-environment/SpotEnv2560&#39;, ## &#39;computeEnvironmentName&#39;: &#39;SpotEnv2560&#39;, ## &#39;computeResources&#39;: {&#39;desiredvCpus&#39;: 4, ## &#39;ec2KeyPair&#39;: &#39;fan_wang-key-pair-us_east_nv&#39;, ## &#39;instanceRole&#39;: &#39;&#39;, ## &#39;instanceTypes&#39;: [&#39;optimal&#39;], ## &#39;maxvCpus&#39;: 2560, ## &#39;minvCpus&#39;: 0, ## &#39;securityGroupIds&#39;: [&#39;sg-e6642399&#39;], ## &#39;spotIamFleetRole&#39;: &#39;arn:aws:iam::710673677961:role/AmazonEC2SpotFleetRole&#39;, ## &#39;subnets&#39;: [&#39;subnet-d9abbe82&#39;], ## &#39;tags&#39;: {}, ## &#39;type&#39;: &#39;SPOT&#39;}, ## &#39;ecsClusterArn&#39;: &#39;&#39;, ## &#39;serviceRole&#39;: &#39;&#39;, ## &#39;state&#39;: &#39;ENABLED&#39;, ## &#39;status&#39;: &#39;VALID&#39;, ## &#39;statusReason&#39;: &#39;ComputeEnvironment &#39; ## &#39;Healthy&#39;, ## &#39;tags&#39;: {}, ## &#39;type&#39;: &#39;MANAGED&#39;}]} 6.2 S3 6.2.1 S3 Usages Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 6.2.1.1 Upload Local File to S3 A program runs either locally or on a remote EC2 machine inside a docker container. Upon exit, data does not persist in the docker container and needs to be exported to be saved. The idea is to export program images, csv files, json files, etc to S3 when these are generated, if the program detects that it is been executed on an EC2 machine (in a container). First, inside the program, detect platform status. For Docker Container on EC2, AWS Linux 2 has platform.release of something like 4.14.193-194.317.amzn2.x86_64. import platform as platform print(platform.release()) # This assums using an EC2 instance where amzn is in platform name ## 10 if &#39;amzn&#39; in platform.release(): s3_status = True else: s3_status = False print(s3_status) ## False Second, on s3, create a bucket, fans3testbucket for example (no underscore in name allowed). Before doing this, set up AWS Access Key ID and AWS Secrete Acccess KEy in /Users/fan/.aws folder so that boto3 can access s3 from computer. Upon successful completion of the push, the file can be accessed at https://fans3testbucket.s3.amazonaws.com/_data/iris_s3.dta. import boto3 s3 = boto3.client(&#39;s3&#39;) spn_local_path_file_name = &quot;C:/Users/fan/Py4Econ/aws/setup/_data/iris_s3.dta&quot; str_bucket_name = &quot;fans3testbucket&quot; spn_remote_path_file_name = &quot;_data/iris_s3.dta&quot; s3.upload_file(spn_local_path_file_name, str_bucket_name, spn_remote_path_file_name) 6.2.1.2 Download File from S3 to Local Machine On a local computer, download a particular file from S3. Download back the file we just uploaded onto S3. import boto3 s3 = boto3.client(&#39;s3&#39;) spn_local_path_file_name = &quot;C:/Users/fan/Py4Econ/aws/setup/_data/iris_s3_downloaded.dta&quot; str_bucket_name = &quot;fans3testbucket&quot; spn_remote_path_file_name = &quot;_data/iris_s3.dta&quot; s3.download_file(str_bucket_name, spn_remote_path_file_name, spn_local_path_file_name) 6.2.1.3 Download File from S3 to EC2 Machine On a EC2 machine, Amazon Linux 2 AMI, for example. Install pip, and install boto3, then download file to the /data/ folder. # ssh into EC2 linux 2 AMI ssh -i &quot;G:/repos/ThaiJMP/boto3aws/aws_ec2/pem/fan_wang-key-pair-us_east_nv.pem&quot; ec2-user@3.81.101.142 # generate data folder mkdir data # install boto3 sudo yum install python-pip python3-wheel &amp;&amp; Pip install boto3 --user # try download file using boto3 # go into python python Now inside python, download the iris_s3.dta to the data folder under root in the EC2 Machine. import boto3 s3 = boto3.client(&#39;s3&#39;) spn_ec2_path_file_name = &quot;/home/ec2-user/data/iris_s3_downloaded.dta&quot; str_bucket_name = &quot;fans3testbucket&quot; spn_s3_path_file_name = &quot;_data/iris_s3.dta&quot; s3.download_file(str_bucket_name, spn_s3_path_file_name, spn_ec2_path_file_name) 6.2.1.4 Download File from S3 to Active Docker Container Working inside an active docker container. First activate and enter into a docker container: # inside EC2 AMI Linux 2, start dockers sudo service docker start sudo service docker status # see docker images docker images # run docker container and enter inside docker run -t -i fanconda /bin/bash # make a data directory and a esti subdirectory mkdir data cd data mkdir esti # enter python python Inside docker, which has boto3 installed already. The Path is different than on EC2, the path root structure is shorter, but otherwise the same. import boto3 s3 = boto3.client(&#39;s3&#39;) spn_container_path_file_name = &quot;/data/esti/iris_s3_downloaded.dta&quot; str_bucket_name = &quot;fans3testbucket&quot; spn_s3_path_file_name = &quot;_data/iris_s3.dta&quot; s3.download_file(str_bucket_name, spn_s3_path_file_name, spn_container_path_file_name) 6.2.1.5 Forward and Backward Slashes Following up on the uploading example above, suppose that rather than using forward slash, backward slash is used, then AWS gets confused about folder. This will not appear under the _data folder, but will appear as a file with file name: *_data/iris_s3.dta* under the bucket. Note that the folder for S3 is a GUI trick, but still, we want to use forward slash properly, so that all double backslash that might be generated by default path tools need to be converted to forward slashes import os # This generates a file directly under bucket _data\\iris_s3: spn_remote_path_file_name_backslash = &quot;_data\\\\iris_s3_slashbackforward.dta&quot; s3.upload_file(spn_local_path_file_name, str_bucket_name, spn_remote_path_file_name_backslash) # This allows the folder structure to be clickable: spn_remote_path_file_name_forwardslash = spn_remote_path_file_name_backslash.replace(os.sep, &#39;/&#39;) s3.upload_file(spn_local_path_file_name, str_bucket_name, spn_remote_path_file_name_forwardslash) # Print slashs print(f&#39;{spn_remote_path_file_name_backslash=}&#39;) ## spn_remote_path_file_name_backslash=&#39;_data\\\\iris_s3_slashbackforward.dta&#39; print(f&#39;{spn_remote_path_file_name_forwardslash=}&#39;) ## spn_remote_path_file_name_forwardslash=&#39;_data/iris_s3_slashbackforward.dta&#39; 6.2.1.6 Sync Local Drive with S3 of a Particular File Type Boto3 does not offer directory upload/download for s3. Needs to rely on aws command line. To sync local folder with all files from a particular AWS folder, exclude image files: # CD into a directory cd /d &quot;G:\\S3\\fanconda202010\\esti&quot; # Make a new directory making S3 Directory Name mkdir e_20201025x_esr_medtst_list_tKap_mlt_ce1a2 # cd into the directory just made cd /d &quot;G:\\S3\\thaijmp202010\\esti\\e_20201025x_esr_medtst_list_tKap_mlt_ce1a2&quot; # copy all results from the s3 folder&#39;s subfolders including subfolders, excluding images aws s3 cp ^ s3://fanconda202010/esti/e_20201025x_esr_medtst_list_tKap_mlt_ce1a2/ . ^ --recursive --exclude &quot;*.png&quot; 6.3 Batch 6.3.1 AWS Batch Run Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 6.3.1.1 Preparing a Docker Image and a Python Function for Batch Array Job We want to set-up a function that can be used jointly with AWS Batch Array. With Batch Array, can run many simulations concurrently. All simulations might only differ in random seed for drawing shocks. This requires setting up the proper dockerfile as well as modifying the python function that we want to invoke slightly. First, create and push a docker image, see this dockerfile. Following the AWS ECR instructions, this registers a docker image in AWS ECR with a URI: XXXX7367XXXX.dkr.ecr.us-east-1.amazonaws.com/fanconda The dockerfile has for CMD: CMD [python, /pyfan/pyfan/graph/exa/scatterline3.py]. This runs the function scatterline3. Second, the scatterline3 function checks if AWS_BATCH_JOB_ARRAY_INDEX is in the os.environ. AWS_BATCH_JOB_ARRAY_INDEX, if exists, is used as a random seed to generate data for the graph. When the function is run in a docker container via batch, the function saves the graph output to a bucket in AWS s3. The pushing the s3 is achieved by pyfan.aws.general.path.py. In the batch job, when arrayProperties = {size: 10}, this will generate AWS_BATCH_JOB_ARRAY_INDEX from 1 through 10 in 10 sub-tasks of a single batch task. These AWS_BATCH_JOB_ARRAY_INDEX could be used as different random seeds, and could be used as folder suffixes. Here, the scatterline3 function generates a graph, that will be stored for testing purpose in pyfan_gph_scatter_line_rand folder of fans3testbucket bucket, the images saved has seed_0.png, seed_1.png, , seed_10.png as names when arrayProperties = {size: 10}. 6.3.1.2 Register A Batch Job Definition Given the docker image we created: XXXX7367XXXX.dkr.ecr.us-east-1.amazonaws.com/fanconda, we can use this to register a batch job. computing requirements: memory and cpu: vCpus = 1 and Memory=7168 for example which container to pull from (ECR): List the image name: XXXX7367XXXX.dkr.ecr.us-east-1.amazonaws.com/fanconda for example job role ARN: arn:aws:iam::XXXX7367XXXX:role/ecsExecutionRole to allow for proper in and out from and to the container. These can be registered programmatically by using boto3: Boto3 Batch Documentation In the example below, will register a new job definition, this will add pyfan-scatterline3-test-rmd to job definition as an additional job definition. Everytime, when the code below is re-run, a new batch revision number is generated. AWS allows per batch job to have potential hundreds of thousands of revisions. import boto3 import yaml import pprint # Load YAML file with security info srn_aws_yml = &quot;C:/Users/fan/fanwangecon.github.io/_data/aws.yml&quot; fl_yaml = open(srn_aws_yml) ls_dict_yml = yaml.load(fl_yaml, Loader=yaml.BaseLoader) aws_yml_dict_yml = ls_dict_yml[0] # Dictionary storing job definition related information job_dict = {&quot;jobDefinitionName&quot;: &#39;pyfan-scatterline3-test-rmd&#39;, &quot;type&quot;: &quot;container&quot;, &quot;containerProperties&quot;: { &quot;image&quot;: aws_yml_dict_yml[&#39;main_aws_id&#39;] + &quot;.dkr.ecr.&quot; + aws_yml_dict_yml[&#39;region&#39;] + &quot;.amazonaws.com/fanconda&quot;, &quot;vcpus&quot;: int(1), &quot;memory&quot;: int(1024), &quot;command&quot;: [&quot;python&quot;, &quot;/pyfan/pyfan/graph/exa/scatterline3.py&quot;, &quot;-A&quot;, &quot;fans3testbucket&quot;, &quot;-B&quot;, &quot;111&quot;], &quot;jobRoleArn&quot;: &quot;arn:aws:iam::&quot; + aws_yml_dict_yml[&#39;main_aws_id&#39;] + &quot;:role/&quot; + aws_yml_dict_yml[&#39;batch_task_executionRoleArn&#39;] }, &quot;retryStrategy&quot;: { &quot;attempts&quot;: 1 }} # Use AWS Personal Access Keys etc to start boto3 client aws_batch = boto3.client(&#39;batch&#39;, aws_access_key_id=aws_yml_dict_yml[&#39;aws_access_key_id&#39;], aws_secret_access_key=aws_yml_dict_yml[&#39;aws_secret_access_key&#39;], region_name=aws_yml_dict_yml[&#39;region&#39;]) # Register a job definition response = aws_batch.register_job_definition( jobDefinitionName = job_dict[&#39;jobDefinitionName&#39;], type = job_dict[&#39;type&#39;], containerProperties = job_dict[&#39;containerProperties&#39;], retryStrategy = job_dict[&#39;retryStrategy&#39;]) # Print response pprint.pprint(response, width=1) ## {&#39;ResponseMetadata&#39;: {&#39;HTTPHeaders&#39;: {&#39;connection&#39;: &#39;keep-alive&#39;, ## &#39;content-length&#39;: &#39;169&#39;, ## &#39;content-type&#39;: &#39;application/json&#39;, ## &#39;date&#39;: &#39;Tue, &#39; ## &#39;29 &#39; ## &#39;Dec &#39; ## &#39;2020 &#39; ## &#39;04:02:05 &#39; ## &#39;GMT&#39;, ## &#39;x-amz-apigw-id&#39;: &#39;YS-JkEZroAMF20g=&#39;, ## &#39;x-amzn-requestid&#39;: &#39;f6129b5e-609f-4561-919c-1552c12fbf48&#39;, ## &#39;x-amzn-trace-id&#39;: &#39;Root=1-5feaaa3d-24bf3db471454a1f31c9bc12&#39;}, ## &#39;HTTPStatusCode&#39;: 200, ## &#39;RequestId&#39;: &#39;f6129b5e-609f-4561-919c-1552c12fbf48&#39;, ## &#39;RetryAttempts&#39;: 0}, ## &#39;jobDefinitionArn&#39;: &#39;arn:aws:batch:us-east-1:710673677961:job-definition/pyfan-scatterline3-test-rmd:90&#39;, ## &#39;jobDefinitionName&#39;: &#39;pyfan-scatterline3-test-rmd&#39;, ## &#39;revision&#39;: 90} 6.3.1.3 Submit a Batch Array Given the batch job definition that has been created. Create also Job Queues and related compute environments. Then we can run Batch Array. Upon submitting the batch array, you can monitor AWS EC2 instances, should notice potentially many instances of EC2 starting up. AWS is starting EC2 instances to complete the batch array jobs. create a batch compute environment that uses spot price instances, which will be much cheaper than on demand costs. Will need to set proper AMI roles, arn:aws:iam::XXXX7367XXXX:role/AmazonEC2SpotFleetRole for Spot fleet role, and also proper securities. When the array_size parameter is equal to 100, that starts 100 child processes, with 1 through 100 for AWS_BATCH_JOB_ARRAY_INDEX, which, could be used directly by the python function by taking in the parameter from the os environment as shown earlier. For demonstration purposes, will only set array_size=3 in the example below. Outputs from the scatterline3 has a timestamp, so each time the code below is run, will generate several new images, with the same set of random seeds, but different date prefix. The output s3 folder is public. import boto3 import yaml import pprint import datetime as datetime # Using the &quot;jobDefinitionName&quot;: &#39;pyfan-scatterline3-test-rmd&#39; from registering jobDefinitionName = &#39;pyfan-scatterline3-test-rmd&#39; # How many child batch processes to start # child process differ in: AWS_BATCH_JOB_ARRAY_INDEX array_size = 3 # job name timestr = &quot;{:%Y%m%d%H%M%S%f}&quot;.format(datetime.datetime.now()) timesufx = &#39;_&#39; + timestr st_jobName = jobDefinitionName + timesufx # job queue (needs to design own queue in batch) st_jobQueue = &#39;Spot&#39; # start batch service # Load YAML file with security info srn_aws_yml = &quot;C:/Users/fan/fanwangecon.github.io/_data/aws.yml&quot; fl_yaml = open(srn_aws_yml) ls_dict_yml = yaml.load(fl_yaml, Loader=yaml.BaseLoader) aws_yml_dict_yml = ls_dict_yml[0] # Use AWS Personal Access Keys etc to start boto3 client aws_batch = boto3.client(&#39;batch&#39;, aws_access_key_id=aws_yml_dict_yml[&#39;aws_access_key_id&#39;], aws_secret_access_key=aws_yml_dict_yml[&#39;aws_secret_access_key&#39;], region_name=aws_yml_dict_yml[&#39;region&#39;]) # aws batch submit job dc_json_batch_response = aws_batch.submit_job( jobName=st_jobName, jobQueue=st_jobQueue, arrayProperties={&#39;size&#39;: array_size}, jobDefinition=jobDefinitionName) # Print response pprint.pprint(dc_json_batch_response, width=1) ## {&#39;ResponseMetadata&#39;: {&#39;HTTPHeaders&#39;: {&#39;connection&#39;: &#39;keep-alive&#39;, ## &#39;content-length&#39;: &#39;198&#39;, ## &#39;content-type&#39;: &#39;application/json&#39;, ## &#39;date&#39;: &#39;Tue, &#39; ## &#39;29 &#39; ## &#39;Dec &#39; ## &#39;2020 &#39; ## &#39;04:02:05 &#39; ## &#39;GMT&#39;, ## &#39;x-amz-apigw-id&#39;: &#39;YS-JoFnDIAMFV6Q=&#39;, ## &#39;x-amzn-requestid&#39;: &#39;7c96cbb3-585f-4118-bca8-0eac23a4e3f7&#39;, ## &#39;x-amzn-trace-id&#39;: &#39;Root=1-5feaaa3d-6ded2cfd5219094502659cc2&#39;}, ## &#39;HTTPStatusCode&#39;: 200, ## &#39;RequestId&#39;: &#39;7c96cbb3-585f-4118-bca8-0eac23a4e3f7&#39;, ## &#39;RetryAttempts&#39;: 0}, ## &#39;jobArn&#39;: &#39;arn:aws:batch:us-east-1:710673677961:job/b7a12a78-f187-423c-ae75-5088e7c2efd4&#39;, ## &#39;jobId&#39;: &#39;b7a12a78-f187-423c-ae75-5088e7c2efd4&#39;, ## &#39;jobName&#39;: &#39;pyfan-scatterline3-test-rmd_20201228220157556998&#39;} 6.3.1.4 Track the Status of a Submitted Batch Array Until it Finished To automate certain processes, often need to check and wait for job to complete. Can do this on web interface. Easier to do this via boto3 operations: describe_job and list_jobs Given the batch array job we just generated above, first, parse out the job ID from the response from the batch array submission above. Then use list_jobs to check the length of JobSummaryList, and then use describe_jobs to check overall job completion status. import time # Get Job ID st_batch_jobID = dc_json_batch_response[&#39;jobId&#39;] # Print Job ID print(f&#39;{st_batch_jobID=}&#39;) # While loop to check status ## st_batch_jobID=&#39;b7a12a78-f187-423c-ae75-5088e7c2efd4&#39; bl_job_in_progress = True it_wait_seconds = 0 while bl_job_in_progress and it_wait_seconds &lt;= 600: # describe job dc_json_batch_describe_job_response = aws_batch.describe_jobs(jobs=[st_batch_jobID]) # pprint.pprint(dc_json_batch_describe_job_response, width=1) it_array_size = dc_json_batch_describe_job_response[&#39;jobs&#39;][0][&#39;arrayProperties&#39;][&#39;size&#39;] dc_status_summary = dc_json_batch_describe_job_response[&#39;jobs&#39;][0][&#39;arrayProperties&#39;][&#39;statusSummary&#39;] if dc_status_summary: # check status it_completed = dc_status_summary[&#39;SUCCEEDED&#39;] + dc_status_summary[&#39;FAILED&#39;] if it_completed &lt; it_array_size: bl_job_in_progress = True # sleep three seconds time.sleep(10) it_wait_seconds = it_wait_seconds + 10 else: bl_job_in_progress = False print(f&#39;{it_wait_seconds=}, ArrayN={it_array_size},&#39; \\ f&#39;SUCCEEDED={dc_status_summary[&quot;SUCCEEDED&quot;]}, FAILED={dc_status_summary[&quot;FAILED&quot;]}, &#39; \\ f&#39;RUNNING={dc_status_summary[&quot;RUNNING&quot;]}, PENDING={dc_status_summary[&quot;PENDING&quot;]}, &#39; \\ f&#39;RUNNABLE={dc_status_summary[&quot;RUNNABLE&quot;]}&#39;) else: #empty statussummary bl_job_in_progress = True time.sleep(10) it_wait_seconds = it_wait_seconds + 10 print(f&#39;{it_wait_seconds=}, ArrayN={it_array_size}&#39;) ## it_wait_seconds=10, ArrayN=3 ## it_wait_seconds=20, ArrayN=3,SUCCEEDED=0, FAILED=0, RUNNING=0, PENDING=0, RUNNABLE=3 ## it_wait_seconds=20, ArrayN=3,SUCCEEDED=3, FAILED=0, RUNNING=0, PENDING=0, RUNNABLE=0 "],["docker-container.html", "Chapter 7 Docker Container 7.1 Docker Setup", " Chapter 7 Docker Container 7.1 Docker Setup 7.1.1 Docker Setup Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 7.1.1.1 Install Docker on AWS Installation Instructions Putty access to .pem key conda aws environment below For Amazon Linux 2: # SSH into EC2 Instance ssh ec2-user@ec2-52-23-218-117.compute-1.amazonaws.com # Update sudo yum update -y # install sudo amazon-linux-extras install docker -y # start service sudo service docker start sudo service docker status # execute docker commands without sudo sudo usermod -a -G docker ec2-user # log out and in reboot does not change public address sudo reboot # if docker info does not work, docker start again docker info 7.1.1.2 Create a Dockerfile and build it Create a Dockerfile and build it. Building a dockerfile generates a docker image: # docker folder mkdir ~/docker # cd into docker folder cd ~/docker # create a Dockerfile in the docker folder # copy the Example Dockerfile below to the Dockerfile vim Dockerfile # in the docker directory build the docker file docker build -t hello-world . Example Dockerfile: FROM ubuntu:12.04 # Install dependencies RUN apt-get update -y RUN apt-get install -y apache2 # Install apache and write hello world message RUN echo &quot;Hello World!&quot; &gt; /var/www/index.html # Configure apache RUN a2enmod rewrite RUN chown -R www-data:www-data /var/www ENV APACHE_RUN_USER www-data ENV APACHE_RUN_GROUP www-data ENV APACHE_LOG_DIR /var/log/apache2 EXPOSE 80 CMD [&quot;/usr/sbin/apache2&quot;, &quot;-D&quot;, &quot;FOREGROUND&quot;] 7.1.1.3 Run, Enter and Exit docker build generates a docker image, we start the docker container, run using the image created. # list docker images available to run docker images These could be some images that are shown after running *docker images*: REPOSITORY TAG IMAGE ID CREATED SIZE XXXX7367XXXX.dkr.ecr.us-east-1.amazonaws.com/fanconda latest 5d1a0df0796e 8 days ago 3.52GB XXXX7367XXXX.dkr.ecr.us-east-1.amazonaws.com/fanconda2020 latest 2db5e859d70c 2 weeks ago 3.4GB fanconda2020 latest 2db5e859d70c 2 weeks ago 3.4GB fanconda5 latest fa55672e7753 2 weeks ago 3.4GB fanconda3 latest 2083f1124465 2 weeks ago 2.91GB Run the image and enter into it (use an image name) and run commands with programs, upon exit, container is stopped. Entering back into the container, the data was generated before now is no longer there, it is a new container based on the same image. # will be inside now the conda image (base) docker run -t -i fanconda /bin/bash # can run programs inside here that have been loaded into the image python /fanProg/invoke/run.py -A ng_s_t=kap_m0_nld_m_simu=2=3 -B b -C 20180814_beta -D esti_param.beta -E None -F min_graphs -G simu --no-ge --no-multiprocess --no-esti # review generated outputs inside docker, results are stored by the run.py program and associated file, to a data folder cd /data ls # To exit the currently running docker exit # show docker container exited docker ps -a Root directory in conda docker: &gt; fanProg bin boot data dev etc home lib lib64 media mnt opt proc pyfan root run sbin srv sys tmp usr var Run the image with program without entering into it. docker run fancondajmp python /ThaiJMP/invoke/run.py -A ng_s_t=kap_m0_nld_m_simu=2=3 -B b -C 20180814_beta -D esti_param.beta -E None -F min_graphs -G simu --no-ge --no-multiprocess --no-esti Docker container will automatically stop after docker run -d 7.1.1.4 Status and Cleaning 7.1.1.4.1 Docker file and Git Repo To have docker file access a git repo without exposing git repo password. Generate a private token, and access as below. See stackoverflow-23391839. RUN git clone https://b123451234dfc025a836927PRIVATETOKEND1239@github.com/FanWangEcon/ThaiJMP.git /ThaiJMP/ 7.1.1.4.2 Docker Status, Space and Clean First, start service: # start docker sudo service docker start # see status sudo service docker status Second, list all docker related space usages, containers and images: # check disk usage docker system df Third, clean containers # see docker containers docker container ls -a # Remove all stopped docker containers docker rm $(docker ps -a -q) Fourth, clean images # list all images docker images docker images --all # Clean all images not referenced by a container docker image prune 7.1.2 ECR Setup Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 7.1.2.1 Pull from Elastic Container Registry (ECR) Given docker files already on ECR, in EC2, first, get password, then pull. # log in # copy the output from the line below and paste aws ecr get-login --no-include-email # this is copied from output of the command above docker login -u AWS -p PASSWORDPASSWORDPASSWORDPASSWORD https://XXXX7367XXXX.dkr.ecr.us-east-1.amazonaws.com # pull from docker docker pull XXXX7367XXXX.dkr.ecr.us-east-1.amazonaws.com/fancondaXX 7.1.2.2 Update Elastic Container Registry (ECR) There is a local conda file, perhaps some project repo have been updated, need to update docker file on ECR (or create new ones). Controlling EC2 can be done manually, or via SSM. Start a EC2 Instance Create a docker folder on EC2 instance (on remote) scp update dockerfile in EC2 docker folder (local to remote) build on remote server docker container (on remote) push from EC2 updated docker to ECR (on remote) First, after creating/starting a EC2 instance, create a docker file and scp update: # Then a sequences of SSM calls: # on local machine: ssh -i &quot;C:/Users/fan/CondaPrj/boto3aws/aws_ec2/pem/fan_wang-key-pair-us_east_nv.pem&quot; ec2-user@54.161.29.209 # if new instance, create a docker folder under main # on remote machine mkdir /home/ec2-user/docker # ssm call to remove current dockerfile # on remote machine rm /home/ec2-user/docker/Dockerfile # run local scp command to copy lateste Dockerfile to EC2, local scp generated by ec2managee # on local machine scp -o StrictHostKeyChecking=accept-new -i C:/Users/fan/CondaPrj/boto3aws/aws_ec2/pem/fan_wang-key-pair-us_east_nv.pem C:/Users/fan/CondaPrj/boto3aws/aws_ecr/container/DockerfileInstall ec2-user@54.161.29.209:~/docker/Dockerfile Second, start container service remotely, and build new container: # start docker service on ec2 # on remote machine sudo service docker start # On remote machine cd /home/ec2-user/docker docker build -t fanconda6 --build-arg CACHE_DATE=2020-09-21-22-43-52 . Third, push new container to ECR (tag, get token, login, push): # Start Container Service sudo service docker start # CD into folder on remote cd /home/ec2-user/docker # tag docker docker tag fancondaxxx XXXX7367XXXX.dkr.ecr.us-east-1.amazonaws.com/fancondaxxx # ECR Docker Log in # ssm.get_authorization_token(registryIds=[boto3aws.aws_keys()[&#39;main_aws_id&#39;]]) # Decode authorization token docker login -u AWS -p TOKENX6XXXxXXg1XXg3OX0= https://XXXX7367XXXX.dkr.ecr.us-east-1.amazonaws.com # ECR Docker Push to ECR docker push XXXX7367XXXX.dkr.ecr.us-east-1.amazonaws.com/fancondaxxx 7.1.2.3 PyFan Procedures Start EC2 instance Push to ECR Get SSH link to EC2, SSH into EC2 sudo service docker start and docker images (or see pull earlier) start docker image and enter to access via command line: docker run -t -i fanconda /bin/bash 7.1.2.4 More Example ECR Code and Outputs 7.1.2.4.1 Example Docker File for AWS Note that that private git repos are pulled in. Note also that AWS keys are set up to allow for various access to AWS services. FROM continuumio/anaconda3 VOLUME /data # Conda update RUN conda update conda # https://github.com/ContinuumIO/docker-images/issues/49#issuecomment-311556456 RUN apt-get update &amp;&amp; \\ apt-get install libgl1-mesa-glx -y # Install Conda additional packages that i use RUN conda install -c conda-forge interpolation RUN conda install -c conda-forge boto3 # see https://github.com/moby/moby/issues/22832, this allows for code below to run without --no-cache ARG CACHE_DATE=2000-01-01 # Clone our private GitHub Repository: PyFan RUN git clone https://b123451234dfc025a836927PRIVATETOKEND1239@github.com/FanWangEcon/pyfan.git /pyfan/ # Make port 80 available to the world outside this container EXPOSE 80 # Install software ENV PYTHONPATH /pyfan/ ENV AWS_BUCKET_NAME=BucketName ENV AWS_ACCESS_KEY_ID=XKIXXXGSXXXBZXX43XXX ENV AWS_SECRET_ACCESS_KEY=xxTgp9r0f4XXXXXXX1XXlG1vTy07wydxXXXXXX11 # Run CMD [&quot;python&quot;, &quot;/pyfan/pyfan/graph/exa/scatterline3.py&quot;] 7.1.2.4.2 Example SSM communication # aws_keys stores keys aws_keys_dict = aws_keys() ssm = boto3.client(&#39;ssm&#39;, aws_access_key_id=aws_keys_dict[&#39;aws_access_key_id&#39;], aws_secret_access_key=aws_keys_dict[&#39;aws_secret_access_key&#39;], region_name=aws_keys_dict[&#39;region&#39;]) commands = &#39;rm /home/ec2-user/docker/Dockerfile&#39; resp = client.send_command( DocumentName=&quot;AWS-RunShellScript&quot;, # One of AWS&#39; preconfigured documents Parameters={&#39;commands&#39;: commands}, InstanceIds=[instance_id]) 7.1.2.4.3 Outputs from Docker Build outputs from docker build json.py - jdump - 47 - 2020-09-22 16:04:32,459 - INFO list_command_invocation-cur_output :[ &quot;Sending build context to Docker daemon 3.072kB\\r\\r&quot;, &quot;Step 1/16 : FROM continuumio/anaconda3&quot;, &quot; ---&gt; 472a925c4385&quot;, &quot;Step 2/16 : VOLUME /data&quot;, &quot; ---&gt; Using cache&quot;, &quot; ---&gt; cf4e6a503f00&quot;, &quot;Step 3/16 : RUN conda update conda&quot;, &quot; ---&gt; Using cache&quot;, &quot; ---&gt; 542901f01365&quot;, &quot;Step 4/16 : RUN apt-get update &amp;&amp; apt-get install libgl1-mesa-glx -y&quot;, &quot; ---&gt; Using cache&quot;, &quot; ---&gt; 6672960aa00c&quot;, &quot;Step 5/16 : RUN conda install -c conda-forge interpolation&quot;, &quot; ---&gt; Using cache&quot;, &quot; ---&gt; efd86a4259a4&quot;, &quot;Step 6/16 : RUN conda install -c conda-forge boto3&quot;, &quot; ---&gt; Using cache&quot;, &quot; ---&gt; bd0146dac9b3&quot;, &quot;Step 7/16 : ARG CACHE_DATE=2000-01-01&quot;, &quot; ---&gt; Using cache&quot;, &quot; ---&gt; dc40688e3720&quot;, &quot;Step 8/16 : RUN git clone https://XXXX@github.com/FanWangEcon/pyfan.git /pyfan/&quot;, &quot; ---&gt; Running in 9c0c2a444540&quot;, &quot;\\u001b[91mCloning into &#39;/pyfan&#39;...&quot;, &quot;\\u001b[0mRemoving intermediate container 9c0c2a444540&quot;, &quot; ---&gt; c80480cc51a1&quot;, &quot;Step 9/16 : RUN git clone https://XXXX@github.com/FanWangEcon/CondaProg.git /CondaProg/&quot;, &quot; ---&gt; Running in 07d9f665b760&quot;, &quot;\\u001b[91mCloning into &#39;/CondaProg&#39;...&quot;, &quot;\\u001b[0mRemoving intermediate container 07d9f665b760&quot;, &quot; ---&gt; a5ac6c6e1458&quot;, &quot;Step 10/16 : EXPOSE 80&quot;, &quot; ---&gt; Running in 1a8ef516e236&quot;, &quot;Removing intermediate container 1a8ef516e236&quot;, &quot; ---&gt; 13ab2965e892&quot;, &quot;Step 11/16 : ENV PYTHONPATH /pyfan/&quot;, &quot; ---&gt; Running in 2d9e4b68164b&quot;, &quot;Removing intermediate container 2d9e4b68164b&quot;, &quot; ---&gt; 0a74e69ce1c8&quot;, &quot;Step 12/16 : ENV PYTHONPATH $PYTHONPATH:/CondaProg/&quot;, &quot; ---&gt; Running in ba59f1273f51&quot;, &quot;Removing intermediate container ba59f1273f51&quot;, &quot; ---&gt; 11fd9d732e2e&quot;, &quot;Step 13/16 : ENV AWS_BUCKET_NAME=BucketName&quot;, &quot; ---&gt; Running in e7a052d3eacf&quot;, &quot;Removing intermediate container e7a052d3eacf&quot;, &quot; ---&gt; 5e294f562838&quot;, &quot;Step 14/16 : ENV AWS_ACCESS_KEY_ID=XXXXX5GSDZSXXXX43XXX&quot;, &quot; ---&gt; Running in 60d810a8514f&quot;, &quot;Removing intermediate container 60d810a8514f&quot;, &quot; ---&gt; 2fa1ac4e7d3b&quot;, &quot;Step 15/16 : ENV AWS_SECRET_ACCESS_KEY=XXXXXXXXXXXXX&quot;, &quot; ---&gt; Running in 8b34126cee5d&quot;, &quot;Removing intermediate container 8b34126cee5d&quot;, &quot; ---&gt; 93bd8b521d61&quot;, &quot;Step 16/16 : CMD [\\&quot;python\\&quot;, \\&quot;/CondaPrj/invoke/invoke.py\\&quot;]&quot;, &quot; ---&gt; Running in dd3ed44dcca7&quot;, &quot;Removing intermediate container dd3ed44dcca7&quot;, &quot; ---&gt; 506f92a794cd&quot;, &quot;Successfully built 506f92a794cd&quot;, &quot;Successfully tagged fanconda:latest&quot;, &quot;Total reclaimed space: 0B&quot;, &quot;&quot; ] 7.1.2.4.4 Output from Docker Push json.py - jdump - 47 - 2020-09-22 16:05:32,986 - INFO list_command_invocation-cur_output :[ &quot;The push refers to repository [XXXX7367XXXX.dkr.ecr.us-east-1.amazonaws.com/fanconda]&quot;, &quot;63cc929545c3: Preparing&quot;, &quot;d849f5d67bbb: Preparing&quot;, &quot;f9c77b2e4c5f: Preparing&quot;, &quot;7ffd6385ae0e: Preparing&quot;, &quot;2fc88e09d363: Preparing&quot;, &quot;50e089036495: Preparing&quot;, &quot;6637031dbcc2: Preparing&quot;, &quot;68d0bdfd0715: Preparing&quot;, &quot;d0f104dc0a1f: Preparing&quot;, &quot;50e089036495: Waiting&quot;, &quot;6637031dbcc2: Waiting&quot;, &quot;68d0bdfd0715: Waiting&quot;, &quot;d0f104dc0a1f: Waiting&quot;, &quot;2fc88e09d363: Layer already exists&quot;, &quot;7ffd6385ae0e: Layer already exists&quot;, &quot;50e089036495: Layer already exists&quot;, &quot;6637031dbcc2: Layer already exists&quot;, &quot;68d0bdfd0715: Layer already exists&quot;, &quot;d0f104dc0a1f: Layer already exists&quot;, &quot;d849f5d67bbb: Pushed&quot;, &quot;f9c77b2e4c5f: Pushed&quot;, &quot;63cc929545c3: Pushed&quot;, &quot;latest: digest: sha256:XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX size: 2226&quot;, &quot;&quot; ] 7.1.2.4.5 AWS ECR Instructions Under repositories listed under ECR, click on View push command, which shows: # Retrieve an authentication token and authenticate your Docker client to your registry. # Use the AWS CLI: aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin XXXX7367XXXX.dkr.ecr.us-east-1.amazonaws.com # Note: If you receive an error using the AWS CLI, make sure that you have the latest version of the AWS CLI and Docker installed. # Build your Docker image using the following command. For information on building a Docker file from scratch see the instructions here . You can skip this step if your image is already built: docker build -t fanconda . # After the build completes, tag your image so you can push the image to this repository: docker tag fanconda:latest XXXX7367XXXX.dkr.ecr.us-east-1.amazonaws.com/fanconda:latest 7.1.2.5 Command Line Sequence Gathered Gathered sequence of command line operations: ssh -i &quot;G:/repos/CondaPrj/boto3aws/aws_ec2/pem/fan_wang-key-pair-us_east_nv.pem&quot; ec2-user@34.229.39.138 docker run -t -i fanconda /bin/bash scp -o StrictHostKeyChecking=accept-new -i G:/repos/CondaPrj/boto3aws/aws_ec2/pem/fan_wang-key-pair-us_east_nv.pem G:/repos/CondaPrj/boto3aws/aws_ecr/container/DockerfileConda ec2-user@34.229.39.138:~/docker/Dockerfile sudo service docker start cd /home/ec2-user/docker docker build -t fanconda --build-arg CACHE_DATE=2020-12-22-10-58-57 . docker system prune --force cd /home/ec2-user/docker docker tag fanconda 710673677961.dkr.ecr.us-east-1.amazonaws.com/fanconda aws ecr get-login --no-include-email docker login -u AWS -p XXXXX= https://710673677961.dkr.ecr.us-east-1.amazonaws.com docker push 710673677961.dkr.ecr.us-east-1.amazonaws.com/fanconda "],["get-data.html", "Chapter 8 Get Data 8.1 Environmental Data", " Chapter 8 Get Data 8.1 Environmental Data 8.1.1 ECMWF ERA5 Data Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 8.1.1.1 Basic Conda Setup Download Anaconda for Python 3. For more involved conda instructions see here Open up anaconda prompt with admin rights (right click choose as admin). # Inside anaconda prompt where python where anaconda # C:/ProgramData/Anaconda3/Scripts/anaconda.exe # C:/ProgramData/Anaconda3/python.exe Add to Path Install cdsapi and eccodes conda config --add channels conda-forge conda install -c anaconda pandas conda install -c conda-forge eccodes -y conda install -c conda-forge cfgrib -y conda install -c anaconda xarray 8.1.1.2 Account Registration Register for an account Agree to Licence Go to your CDS user page copy the url and key: Get url and key this has UID, 4XXXX, and API KEY, 4XXXfXXX-XXXf-4XXX-9XXX-7XXXebXXfdXX together they should look like: 4XXXX:4XXXfXXX-XXXf-4XXX-9XXX-7XXXebXXfdXX Open up an editor (notepad++ for example), create an empty file, paste the url and your UID:APIKEY into the file as below. Save file as: C:/Users/fan/.cdsapirc. Under user root, as .cdsapirc file. Note .cdsapirc is the file name, you are saving that under the directory C:/Users/fan/. url: https://cds.climate.copernicus.eu/api/v2 key: 4XXXX:4XXXfXXX-XXXf-4XXX-9XXX-7XXXebXXfdXX 8.1.1.3 Run API Request via Jupyter Notebook open up Jupyter Notebook (this opens up a browser page) cd C:/Users/fan/Downloads jupyter notebook create a new python3 file somewhere you like name the file cdstest (saved as ipynb file) paste the code below inside the ipynb file you opened (modify spt_root): import cdsapi import urllib.request # download folder spt_root = &quot;C:/Users/fan/downloads/_data/&quot; spn_dl_test_grib = spt_root + &quot;test_china_temp.grib&quot; # request c = cdsapi.Client() res = c.retrieve(&quot;reanalysis-era5-pressure-levels&quot;, { &#39;product_type&#39;: &#39;reanalysis&#39;, &#39;variable&#39;: &#39;temperature&#39;, &#39;pressure_level&#39;: &#39;1000&#39;, &#39;year&#39;: &#39;2008&#39;, &#39;month&#39;: &#39;01&#39;, &#39;day&#39;: &#39;01&#39;, &#39;time&#39;: &#39;12:00&#39;, &#39;format&#39;: &#39;netcdf&#39;, &#39;area&#39; : [53.31, 73, 4.15, 135], &#39;grid&#39; : [1.0, 1.0], &quot;format&quot;: &quot;grib&quot; }, spn_dl_test_grib ) # show results print(&#39;print results&#39;) print(res) print(type(res)) click run 8.1.1.4 Run API request via Ipython In Anaconda Prompt: ipython Open a file in notepad++ or elsewhere, copy the code above over and edit the spt_root to reflect your directories Select the entire code in the notepad++ page, and copy all lines Now inside ipython, type percentage and paste: %paste This should run the file above and save the grib file in the folder you specified with the name you specified. 8.1.1.5 Convert CRIB data to CSV inside conda prompt cd into the folder where you downloaded the grib file grib_ls shows what is in the grib file grib_get_data translates grib to csv cd &quot;C:/Users/fan/downloads/_data/&quot; grib_ls test_china_temp.grib grib_get_data test_china_temp.grib &gt; test_china_temp_raw.csv 8.1.1.6 More Advanced Download Setup and Instructions 8.1.1.6.1 Conda Enviornment and Installation In conda, set up a conda environment for downloading ECMWF data using the ECMWF API. (Conda Set-up) # Set up conda deactivate conda list env conda env remove -n wk_ecmwf conda create -n wk_ecmwf -y conda activate wk_ecmwf # Add conda-forge to channel in env conda config --env --add channels conda-forge conda config --get channels conda config --get channels --env # Install conda install cdsapi -y conda install -c anaconda pandas conda install -c conda-forge eccodes -y conda install -c conda-forge cfgrib -y conda install -c anaconda xarray This creates the conda env that we are using here for python. 8.1.1.6.2 Config File .cdsapirc Open up the cdsapirc, create new if does note exist. Below, open up the file and save the text. See Python Reading and Writing to File Examples. First, get the text for the config file: stf_cds_cdsapirc = &quot;&quot;&quot;\\ url: https://cds.climate.copernicus.eu/api/v2 key: 4XXXX:4XXXfXXX-XXXf-4XXX-9XXX-7XXXebXXfdXX\\ &quot;&quot;&quot; print(stf_cds_cdsapirc) Second save text to file: # Relative file name spt_file_cds = &quot;C:/Users/fan/&quot; snm_file_cds = &quot;.cdsapirc&quot; spn_file_cds = spt_file_cds + snm_file_cds # Open new file fl_cdsapirc_contents = open(spn_file_cds, &#39;w&#39;) # Write to File fl_cdsapirc_contents.write(stf_cds_cdsapirc) # Close fl_cdsapirc_contents.close() # Open the config file to check code &quot;C:/Users/fan/.cdsapirc&quot; 8.1.1.7 Generate API Requests Go to the sites below, choose download data, pick what is needed, and then select Show API request at the bottom of page: ERA5 pressure levels from 1979 to present ERA5 hourly pressure ERA5 monthly pressure ERA5 single levels from 1979 to present ERA5 hourly pressure ERA5 monthly pressure 8.1.1.7.1 API Request China Temp Test API function is here. Select based on Chinas area, some testing data and download grib file. The data is from 2008, Jan 1st, at 12 noon? Open up Jupyter notebook: jupyter notebook # import module in conda env wk_ecmwf import cdsapi import urllib.request # download folder spt_root = &quot;C:/Users/fan/py4econ/vig/getdata/envir/&quot; spn_dl_test_grib = spt_root + &quot;_data/test/test_china_temp.grib&quot; # request c = cdsapi.Client() res = c.retrieve(&quot;reanalysis-era5-pressure-levels&quot;, { &#39;product_type&#39;: &#39;reanalysis&#39;, &#39;variable&#39;: &#39;temperature&#39;, &#39;pressure_level&#39;: &#39;1000&#39;, &#39;year&#39;: &#39;2008&#39;, &#39;month&#39;: &#39;01&#39;, &#39;day&#39;: &#39;01&#39;, &#39;time&#39;: &#39;12:00&#39;, &#39;format&#39;: &#39;netcdf&#39;, &#39;area&#39; : [53.31, 73, 4.15, 135], &#39;grid&#39; : [1.0, 1.0], &quot;format&quot;: &quot;grib&quot; }, spn_dl_test_grib ) # show results print(&#39;print results&#39;) print(res) print(type(res)) # download # response = urllib.request.urlopen(&#39;http://www.example.com/&#39;) # html = response.read() 2020-06-17 23:51:35,107 INFO Welcome to the CDS 2020-06-17 23:51:35,107 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-pressure-levels 2020-06-17 23:51:36,441 INFO Request is queued 2020-06-17 23:51:39,183 INFO Request is running 2020-06-17 23:51:45,059 INFO Request is completed 2020-06-17 23:51:45,060 INFO Downloading &gt; http://136.156.133.25/cache-compute-0008/cache/data2/adaptor.mars.internal-1592455900.8655114-11162-11-68e1ea23-8985-4926-95e6-9f181cc7792&gt; 7.grib to C:/Users/fan/pyfan/vig/getdata/envir/_data/test/test_china_temp.grib (6.3K) 2020-06-17 23:51:45,441 INFO Download rate 16.6K/s print results Result(content_length=6480,content_type=application/x-grib,location=http://136.156.133.25/cache-compute-0008/cache/data2/adaptor.mars.inte&gt; rnal-1592455900.8655114-11162-11-68e1ea23-8985-4926-95e6-9f181cc77927.grib) &lt;class cdsapi.api.Result&gt; Convert grib to raw csv, open up command line: cd &quot;C:/Users/fan/pyfan/vig/getdata/envir/_data/test/&quot; grib_ls test_china_temp.grib grib_get_data test_china_temp.grib &gt; test_china_temp_raw.csv Format the CSV file (is not comma separated) spt_root = &quot;C:/Users/fan/pyfan/vig/getdata/envir/_data/test/&quot; spn_csv_raw = spt_root + &quot;test_china_temp_raw.csv&quot; spn_csv_edi = spt_root + &quot;test_china_temp.csv&quot; with open(spn_csv_raw, &#39;r&#39;) as f_in, open(spn_csv_edi, &#39;w&#39;) as f_out: f_out.write(next(f_in)) [f_out.write(&#39;,&#39;.join(line.split()) + &#39;\\n&#39;) for line in f_in] Show CSV results: # Path and Read spt_root = &quot;C:/Users/fan/pyfan/vig/getdata/envir/&quot; spn_dl_test_csv = paste0(spt_root, &quot;_data/test/test_china_temp.csv&quot;) china_weather_data &lt;- read.csv(spn_dl_test_csv) # Top 50 rows kable(head(china_weather_data, 50), caption=&quot;Chinese Long and Lat, Temperature Pressure, 2008 Jan 1st at 12 noon?&quot;) %&gt;% kable_styling_fc() Table 8.1: Chinese Long and Lat, Temperature Pressure, 2008 Jan 1st at 12 noon? time latitude longitude u10 v10 d2m t2m msl sp 2008-01-01 02:00:00 23.25 113 -2.6031342 -4.829605 265.4314 284.8363 102918.8 102616.0 2008-01-01 02:00:00 23.25 114 -2.7173920 -3.808121 262.7693 284.2719 102862.1 101628.0 2008-01-01 02:00:00 22.25 113 -2.6246185 -6.311050 266.9294 284.2602 102796.6 102059.0 2008-01-01 02:00:00 22.25 114 -2.6285248 -6.152847 267.4978 285.3168 102710.1 102201.0 2008-01-01 12:00:00 23.25 113 -1.1495056 -2.728592 265.8091 286.1729 102588.9 102290.7 2008-01-01 12:00:00 23.25 114 -1.4454040 -2.477615 265.3033 285.0987 102591.6 101374.7 2008-01-01 12:00:00 22.25 113 -0.6924744 -4.270584 268.0396 286.5753 102482.9 101757.7 2008-01-01 12:00:00 22.25 114 -1.9668884 -4.906326 266.7486 288.0030 102440.1 101940.7 ERA5 is a comprehensive reanalysis, from 1979 (soon to be backdated to 1950) to near real time, which assimilates as many observations as possible in the upper air and near surface. The ERA5 atmospheric model is coupled with a land surface model and a wave model. Register for an account Agree to Licence 8.1.1.8 Learning 8.1.1.8.1 Terminologies Links: status of the CDS queue. Terminologies: single level parameters 8.1.1.8.2 Single Level Parameters ERA5 Variables? Table 1: surface and single level parameters: invariants Table 9: pressure level parameters: instantaneous Temperature ER5 Data Download Instructions. 8.1.1.9 UTCI, NC Format Data, Download, Unzip, Convert to combined CSV The data downloaded from CDS climate could become very large in size. We want to process parts of the data one part at a time, summarize and aggregate over each part, and generate a file output file with aggregate statistics over the entire time period of interest. This code below accompalishes the following tasks: download data from derived-utci-historical as ZIP: API request by itself unzip convert nc files to csv files individual csv files are half year groups Parameter Control for the code below: spt_root: root folder where everything will be at spth_conda_env: the conda virtual environment python path, eccodes and cdsapi packages are installed in the conda virtual environment. In the example below, the first env is: wk_ecmwf st_nc_prefix: the downloaded individual nc files have dates and prefix before and after the date string in the nc file names. This is the string before that. st_nc_suffix: see (3), this is the suffix ar_years: array of years to download and aggregate over ar_months_g1: months to download in first half year ar_months_g2: months to download in second half year ################################################# # ------------ Parameters ################################################# # Where to store everything spt_root &lt;- &quot;C:/Users/fan/Downloads/_data/&quot; spth_conda_env &lt;- &quot;C:/ProgramData/Anaconda3/envs/wk_ecmwf/python.exe&quot; # nc name prefix st_nc_prefix &lt;- &quot;ECMWF_utci_&quot; st_nc_suffix &lt;- &quot;_v1.0_con.nc&quot; # Years list # ar_years &lt;- 2001:2019 ar_years &lt;- c(2005, 2015) # ar_months_g1 &lt;- c(&#39;01&#39;,&#39;02&#39;,&#39;03&#39;,&#39;04&#39;,&#39;05&#39;,&#39;06&#39;) ar_months_g1 &lt;- c(&#39;01&#39;, &#39;03&#39;) # ar_months_g2 &lt;- c(&#39;07&#39;,&#39;08&#39;,&#39;09&#39;,&#39;10&#39;,&#39;11&#39;,&#39;12&#39;) ar_months_g2 &lt;- c(&#39;07&#39;, &#39;09&#39;) # folder to download any nc zips to nczippath &lt;- spt_root # we are changing the python api file with different requests stirngs and storing it here pyapipath &lt;- spt_root # output directory for AGGREGATE CSV with all DATES from this search csvpath &lt;- spt_root ################################################# # ------------ Packages ################################################# library(&quot;ncdf4&quot;) library(&quot;chron&quot;) library(&quot;lattice&quot;) library(&quot;RColorBrewer&quot;) library(&quot;stringr&quot;) library(&quot;tibble&quot;) library(&quot;dplyr&quot;) Sys.setenv(RETICULATE_PYTHON = spth_conda_env) library(&quot;reticulate&quot;) ################################################# # ------------ Define Loops ################################################# for (it_yr in ar_years) { for (it_mth_group in c(1,2)) { if(it_mth_group == 1) { ar_months = ar_months_g1 } if(it_mth_group == 2) { ar_months = ar_months_g2 } ################################################# # ------------ Define Python API Call ################################################# # name of zip file nczipname &lt;- &quot;derived_utci_2010_2.zip&quot; unzipfolder &lt;- &quot;derived_utci_2010_2&quot; st_file &lt;- paste0(&quot;import cdsapi import urllib.request # download folder spt_root = &#39;&quot;, nczippath, &quot;&#39; spn_dl_test_grib = spt_root + &#39;&quot;, nczipname, &quot;&#39; # request c = cdsapi.Client() res = c.retrieve( &#39;derived-utci-historical&#39;, { &#39;format&#39;: &#39;zip&#39;, &#39;variable&#39;: &#39;Universal thermal climate index&#39;, &#39;product_type&#39;: &#39;Consolidated dataset&#39;, &#39;year&#39;: &#39;&quot;,it_yr, &quot;&#39;, &#39;month&#39;: [ &quot;, paste(&quot;&#39;&quot;, ar_months, &quot;&#39;&quot;, sep = &quot;&quot;, collapse = &quot;, &quot;), &quot; ], &#39;day&#39;: [ &#39;01&#39;,&#39;03&#39; ], &#39;area&#39; : [53.31, 73, 4.15, 135], &#39;grid&#39; : [0.25, 0.25], }, spn_dl_test_grib) # show results print(&#39;print results&#39;) print(res) print(type(res))&quot;) # st_file = &quot;print(1+1)&quot; # Store Python Api File fl_test_tex &lt;- paste0(pyapipath, &quot;api.py&quot;) fileConn &lt;- file(fl_test_tex) writeLines(st_file, fileConn) close(fileConn) ################################################# # ------------ Run Python File ################################################# # Set Path setwd(pyapipath) # Run py file, api.py name just defined use_python(spth_conda_env) source_python(&#39;api.py&#39;) ################################################# # ------------ uNZIP ################################################# spn_zip &lt;- paste0(nczippath, nczipname) spn_unzip_folder &lt;- paste0(nczippath, unzipfolder) unzip(spn_zip, exdir=spn_unzip_folder) ################################################# # ------------ Find All files ################################################# # Get all files with nc suffix in folder ncpath &lt;- paste0(nczippath, unzipfolder) ls_sfls &lt;- list.files(path=ncpath, recursive=TRUE, pattern=&quot;.nc&quot;, full.names=T) ################################################# # ------------ Combine individual NC files to JOINT Dataframe ################################################# # List to gather dataframes ls_df &lt;- vector(mode = &quot;list&quot;, length = length(ls_sfls)) # Loop over files and convert nc to csv it_df_ctr &lt;- 0 for (spt_file in ls_sfls) { it_df_ctr &lt;- it_df_ctr + 1 # Get file name without Path snm_file_date &lt;- sub(paste0(&#39;\\\\&#39;,st_nc_suffix,&#39;$&#39;), &#39;&#39;, basename(spt_file)) snm_file_date &lt;- sub(st_nc_prefix, &#39;&#39;, basename(snm_file_date)) # Dates Start and End: list.files is auto sorted in ascending order if (it_df_ctr == 1) { snm_start_date &lt;- snm_file_date } else { # this will give the final date snm_end_date &lt;- snm_file_date } # Given this structure: ECMWF_utci_20100702_v1.0_con, sub out prefix and suffix print(spt_file) ncin &lt;- nc_open(spt_file) nchist &lt;- ncatt_get(ncin, 0, &quot;history&quot;) # not using this missing value flag at the moment missingval &lt;- str_match(nchist$value, &quot;setmisstoc,\\\\s*(.*?)\\\\s* &quot;)[,2] missingval &lt;- as.numeric(missingval) lon &lt;- ncvar_get(ncin, &quot;lon&quot;) lat &lt;- ncvar_get(ncin, &quot;lat&quot;) tim &lt;- ncvar_get(ncin, &quot;time&quot;) tunits &lt;- ncatt_get(ncin, &quot;time&quot;, &quot;units&quot;) nlon &lt;- dim(lon) nlat &lt;- dim(lat) ntim &lt;- dim(tim) # convert time -- split the time units string into fields # tustr &lt;- strsplit(tunits$value, &quot; &quot;) # tdstr &lt;- strsplit(unlist(tustr)[3], &quot;-&quot;) # tmonth &lt;- as.integer(unlist(tdstr)[2]) # tday &lt;- as.integer(unlist(tdstr)[3]) # tyear &lt;- as.integer(unlist(tdstr)[1]) # mytim &lt;- chron(tim, origin = c(tmonth, tday, tyear)) tmp_array &lt;- ncvar_get(ncin, &quot;utci&quot;) tmp_array &lt;- tmp_array - 273.15 lonlat &lt;- as.matrix(expand.grid(lon = lon, lat = lat, hours = tim)) temperature &lt;- as.vector(tmp_array) tmp_df &lt;- data.frame(cbind(lonlat, temperature)) # extract a rectangle eps &lt;- 1e-8 minlat &lt;- 22.25 - eps maxlat &lt;- 23.50 + eps minlon &lt;- 113.00 - eps maxlon &lt;- 114.50 + eps # subset data subset_df &lt;- tmp_df[tmp_df$lat &gt;= minlat &amp; tmp_df$lat &lt;= maxlat &amp; tmp_df$lon &gt;= minlon &amp; tmp_df$lon &lt;= maxlon, ] # add Date subset_df_date &lt;- as_tibble(subset_df) %&gt;% mutate(date = snm_file_date) # Add to list ls_df[[it_df_ctr]] &lt;- subset_df_date # Close NC nc_close(ncin) } # List of DF to one DF df_all_nc &lt;- do.call(rbind, ls_df) # Save File fname &lt;- paste0(paste0(st_nc_prefix, snm_start_date, &quot;_to_&quot;, snm_end_date, &quot;.csv&quot;)) csvfile &lt;- paste0(csvpath, fname) write.table(na.omit(df_all_nc), csvfile, row.names = FALSE, sep = &quot;,&quot;) # Delete folders unlink(spn_zip, recursive=TRUE, force=TRUE) unlink(spn_unzip_folder, recursive=TRUE, force=TRUE) # end loop months groups } # end loop year } "],["system-and-support.html", "Chapter 9 System and Support 9.1 Command Line 9.2 File In and Out 9.3 Install Python 9.4 Documentation", " Chapter 9 System and Support 9.1 Command Line 9.1.1 Python Command Line Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 9.1.1.1 Run Command Line from Inside Python Use subprocess, where is python: import subprocess cmd_popen = subprocess.Popen([&quot;where&quot;, &quot;python&quot;], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE) output, err = cmd_popen.communicate() print(output.decode(&#39;utf-8&#39;)) ## G:\\ProgramData\\Anaconda3\\envs\\wk_pyfan\\python.exe ## G:\\ProgramData\\Anaconda3\\python.exe ## C:\\Users\\fan\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe Command line file redirection symbol, # The &gt; command line sends current console output to file.txt # cd &quot;C:\\users\\fan&quot; # ls &gt; ls_files.txt # rm ls_files.txt import os import subprocess # ls in current location cmd_ls = subprocess.Popen([&quot;ls&quot;], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True); stf_out_cmd_ls, err = cmd_ls.communicate() stf_out_cmd_ls = stf_out_cmd_ls.decode(&#39;utf-8&#39;) print(stf_out_cmd_ls) srt_file_tex = &quot;_file/&quot; sna_file_tex = &quot;test_ls_pyfanvig_stdout&quot; srn_file_tex = srt_file_tex + sna_file_tex + &quot;.txt&quot; fl_tex_contents = open(srn_file_tex, &#39;w&#39;) fl_tex_contents.write(stf_out_cmd_ls) ## 0 fl_tex_contents.close() 9.1.1.2 Execute Command Line Python Functions run python from command line run python function with parameters from command line Here run python from command line inside python itself. # Run: from py.fan.util.rmd.mattexmd import fp_mlxtex2md fp_mlxtex2md(spt_root=&#39;C:/Users/fan/Math4Econ/matrix_application/&#39;, ls_srt_subfolders=None, st_rglob_tex=&#39;twogoods.tex&#39;, verbose=True) # Run: python -c &quot;from pyfan.util.rmd.mattexmd import fp_mlxtex2md; fp_mlxtex2md(spt_root=&#39;C:/Users/fan/Math4Econ/matrix_application/&#39;, ls_srt_subfolders=None, st_rglob_tex=&#39;twogoods.tex&#39;, verbose=True)&quot; 9.1.2 Run Matlab Functions Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 9.1.2.1 Generate A template Matlab Script Generate an example matlab script file with parameter x. # Example Matlab Function stf_m_contents = &quot;&quot;&quot;\\ a = x + 1 b = 10*x\\ &quot;&quot;&quot; # Print print(stf_m_contents) # Open new file ## a = x + 1 ## b = 10*x fl_m_contents = open(&quot;_m/fs_test.m&quot;, &#39;w&#39;) # Write to File fl_m_contents.write(stf_m_contents) # print ## 18 fl_m_contents.close() 9.1.2.2 Run the Matlab Function from Commandline run matlab function from command line Retrieving the output of subprocess.call https://www.mathworks.com/help/matlab/ref/matlabwindows.html First, check where matlab is installed: import subprocess cmd_popen = subprocess.Popen([&quot;where&quot;, &quot;matlab&quot;], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE) output, err = cmd_popen.communicate() print(output.decode(&#39;utf-8&#39;)) ## G:\\ProgramData\\MATLAB\\R2020b\\bin\\matlab.exe Second, run the matlab file, first definet he parameter x: import os # print and set directory print(os.getcwd()) ## G:\\repos\\Py4Econ os.chdir(&#39;_m&#39;) print(os.getcwd()) # run matlab script saved prior # running command line: matlab -batch &quot;fs_test; exit&quot; ## G:\\repos\\Py4Econ\\_m cmd_popen = subprocess.Popen([&quot;matlab&quot;, &quot;-batch&quot;, &quot;\\&quot;x=1; fs_test; exit\\&quot;&quot;], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE) output, err = cmd_popen.communicate() print(output.decode(&#39;utf-8&#39;)) ## ## a = ## ## 2 ## ## ## b = ## ## 10 ## Third, run the function again, but with x=3: os.chdir(&#39;_m&#39;) print(os.getcwd()) ## G:\\repos\\Py4Econ\\_m print(subprocess.Popen([&quot;matlab&quot;, &quot;-batch&quot;, &quot;\\&quot;x=5; fs_test; exit\\&quot;&quot;], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()[0].decode(&#39;utf-8&#39;)) ## ## a = ## ## 6 ## ## ## b = ## ## 50 ## 9.2 File In and Out 9.2.1 Check, Read, Write and Convert Files Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 9.2.1.1 Check if where a Program is. Suppose we want to generate a commandline call from within python and want to start it in bash. Calling something like C:/Program Files/Git/git-bash.exe -c COMMANDS. However, depending on the computer that is been used, the git-bash command might be in different spots. How do we find the right path to the git-bash file. Accomplish this by using shutil.which, which can find the path to different commands, including the git command. Given the path that we found, the git-bash.exe file is stored in the Git folder, two levels up. So we will use pathlib to get to the correct path location. To be safe, go up one level, and then two levels to search for git-bash.exe. First, find the path to the git exe command: # Imports import os import shutil # cmd st_cmd = &#39;git&#39; # Using shutil.which() method to find local path to the *git* command spn_path_to_git = shutil.which(st_cmd) # Print result print(f&#39;{spn_path_to_git=}&#39;) ## spn_path_to_git=&#39;G:\\\\ProgramData\\\\Git\\\\cmd\\\\git.EXE&#39; Second, find the parent and grandparent folders: from pathlib import Path # Get the parent folder 2 levels up srt_path_git_parent_folder = Path(spn_path_to_git).parents[0] srt_path_git_grandparent_folder = Path(spn_path_to_git).parents[1] # Print print(f&#39;{srt_path_git_parent_folder=}&#39;) ## srt_path_git_parent_folder=WindowsPath(&#39;G:/ProgramData/Git/cmd&#39;) print(f&#39;{srt_path_git_grandparent_folder=}&#39;) # Search for for the git-bash.exe file in parent and then in the grandparent folder. ## srt_path_git_grandparent_folder=WindowsPath(&#39;G:/ProgramData/Git&#39;) Third, search inside parent folder first, and then grand until find the path to git-bash.exe. Will put all three steps code together: # required packages import shutil from pathlib import Path # find path to git st_cmd = &#39;git&#39; spn_path_to_git = shutil.which(st_cmd) # find path to git-bash.exe spn_path_to_gitbash = &#39;&#39; for it_up_iter in [0,1]: # up-tier folder srt_path_git_up_folder = Path(spn_path_to_git).parents[it_up_iter] # search # get file names in folders (not recursively) ls_spn_found_git_bash = [spn_file for spt_srh in [srt_path_git_up_folder] for spn_file in Path(spt_srh).glob(&#39;git-bash.exe&#39;)] # if found, length of ls of founds files must be 1 if len(ls_spn_found_git_bash) == 1: spn_path_to_gitbash = ls_spn_found_git_bash[0] break if spn_path_to_gitbash == &#39;&#39;: raise NameError(f&#39;failed to find git-bash, {spn_path_to_git=}&#39;) else: print(f&#39;Found git-bash: {spn_path_to_gitbash} by searching around {spn_path_to_git=}&#39;) ## Found git-bash: G:\\ProgramData\\Git\\git-bash.exe by searching around spn_path_to_git=&#39;G:\\\\ProgramData\\\\Git\\\\cmd\\\\git.EXE&#39; 9.2.1.2 Generate a tex file Will a bare-bone tex file with some texts inside, save inside the *_file* subfolder. First, create the text text string, note the the linebreaks utomatically generate linebreaks, note that slash need double slash: # Create the Tex Text # Note that trible quotes begin first and end last lines stf_tex_contents = &quot;&quot;&quot;\\\\documentclass[12pt,english]{article} \\\\usepackage[bottom]{footmisc} \\\\usepackage[urlcolor=blue]{hyperref} \\\\begin{document} \\\\title{A Latex Testing File} \\\\author{\\\\href{http://fanwangecon.github.io/}{Fan Wang} \\\\thanks{See information \\\\href{https://fanwangecon.github.io/Tex4Econ/}{Tex4Econ} for more.}} \\\\maketitle Ipsum information dolor sit amet, consectetur adipiscing elit. Integer Latex placerat nunc orci. \\\\paragraph{\\\\href{https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3140132}{Data}} Village closure information is taken from a village head survey.\\\\footnote{Generally students went to schools.} \\\\end{document}&quot;&quot;&quot; # Print print(stf_tex_contents) ## \\documentclass[12pt,english]{article} ## \\usepackage[bottom]{footmisc} ## \\usepackage[urlcolor=blue]{hyperref} ## \\begin{document} ## \\title{A Latex Testing File} ## \\author{\\href{http://fanwangecon.github.io/}{Fan Wang} \\thanks{See information \\href{https://fanwangecon.github.io/Tex4Econ/}{Tex4Econ} for more.}} ## \\maketitle ## Ipsum information dolor sit amet, consectetur adipiscing elit. Integer Latex placerat nunc orci. ## \\paragraph{\\href{https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3140132}{Data}} ## Village closure information is taken from a village head survey.\\footnote{Generally students went to schools.} ## \\end{document} Second, write the contents of the file to a new tex file stored inside the *_file* subfolder of the directory: # Relative file name srt_file_tex = &quot;_file/&quot; sna_file_tex = &quot;test_fan&quot; srn_file_tex = srt_file_tex + sna_file_tex + &quot;.tex&quot; # Open new file fl_tex_contents = open(srn_file_tex, &#39;w&#39;) # Write to File fl_tex_contents.write(stf_tex_contents) # print ## 617 fl_tex_contents.close() 9.2.1.3 Replace Strings in a tex file Replace a set of strings in the file just generated by a set of alternative strings. # Open file Get text fl_tex_contents = open(srn_file_tex) stf_tex_contents = fl_tex_contents.read() print(srn_file_tex) # define new and old ## _file/test_fan.tex ls_st_old = [&#39;information&#39;, &#39;Latex&#39;] ls_st_new = [&#39;INFOREPLACE&#39;, &#39;LATEX&#39;] # zip and loop and replace for old, new in zip(ls_st_old, ls_st_new): stf_tex_contents = stf_tex_contents.replace(old, new) print(stf_tex_contents) # write to file with replacements ## \\documentclass[12pt,english]{article} ## \\usepackage[bottom]{footmisc} ## \\usepackage[urlcolor=blue]{hyperref} ## \\begin{document} ## \\title{A LATEX Testing File} ## \\author{\\href{http://fanwangecon.github.io/}{Fan Wang} \\thanks{See INFOREPLACE \\href{https://fanwangecon.github.io/Tex4Econ/}{Tex4Econ} for more.}} ## \\maketitle ## Ipsum INFOREPLACE dolor sit amet, consectetur adipiscing elit. Integer LATEX placerat nunc orci. ## \\paragraph{\\href{https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3140132}{Data}} ## Village closure INFOREPLACE is taken from a village head survey.\\footnote{Generally students went to schools.} ## \\end{document} sna_file_edited_tex = &quot;test_fan_edited&quot; srn_file_edited_tex = srt_file_tex + sna_file_edited_tex + &quot;.tex&quot; fl_tex_ed_contents = open(srn_file_edited_tex, &#39;w&#39;) fl_tex_ed_contents.write(stf_tex_contents) ## 617 fl_tex_ed_contents.close() 9.2.1.4 Convert Tex File to Pandoc and Compile Latex Compile tex file to pdf and clean up the extraneous pdf outputs. See ff_pdf_gen_clean. import subprocess import os # Change to local directory so path in tex respected. os.chdir(&quot;C:/Users/fan/py4econ/support/inout&quot;) # Convert tex to pdf subprocess.call([&#39;C:/texlive/2020/bin/win32/xelatex.exe&#39;, &#39;-output-directory&#39;, srt_file_tex, srn_file_edited_tex], shell=False) # Clean pdf extraneous output ## 0 ls_st_remove_suffix = [&#39;aux&#39;,&#39;log&#39;,&#39;out&#39;,&#39;bbl&#39;,&#39;blg&#39;] for st_suffix in ls_st_remove_suffix: srn_cur_file = srt_file_tex + sna_file_edited_tex + &quot;.&quot; + st_suffix if (os.path.isfile(srn_cur_file)): os.remove(srt_file_tex + sna_file_edited_tex + &quot;.&quot; + st_suffix) Use pandoc to convert tex file import subprocess # md file name srn_file_md = srt_file_tex + &quot;test_fan_edited.md&quot; # Convert tex to md subprocess.call([&#39;pandoc&#39;, &#39;-s&#39;, srn_file_tex, &#39;-o&#39;, srn_file_md]) # Open md file ## 0 fl_md_contents = open(srn_file_md) print(fl_md_contents.read()) ## --- ## author: ## - &quot;[Fan Wang](http://fanwangecon.github.io/) [^1]&quot; ## title: A Latex Testing File ## --- ## ## Ipsum information dolor sit amet, consectetur adipiscing elit. Integer ## Latex placerat nunc orci. ## ## #### [Data](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3140132) ## ## Village closure information is taken from a village head survey.[^2] ## ## [^1]: See information ## [Tex4Econ](https://fanwangecon.github.io/Tex4Econ/) for more. ## ## [^2]: Generally students went to schools. 9.2.1.5 Search for Files with Suffix in Several Folders python search all files in folders with suffix Search for files in several directories that have a particular suffix. Then decompose directory into sub-components. Search file inside several folders (not recursively in subfolders): from pathlib import Path # directories to search in ls_spt_srh = [&quot;C:/Users/fan/R4Econ/amto/&quot;, &quot;C:/Users/fan/R4Econ/function/&quot;] # get file names in folders (not recursively) ls_spn_found = [spn_file for spt_srh in ls_spt_srh for spn_file in Path(spt_srh).glob(&#39;*.Rmd&#39;)] for spn_found in ls_spn_found: print(spn_found) ## C:\\Users\\fan\\R4Econ\\amto\\main.Rmd ## C:\\Users\\fan\\R4Econ\\function\\main.Rmd Search file recursivesly in all subfolders of folders: from pathlib import Path # directories to search in ls_spt_srh = [&quot;C:/Users/fan/R4Econ/amto/array/&quot;, &quot;C:/Users/fan/R4Econ/amto/list&quot;] # get file names recursively in all subfolders ls_spn_found = [spn_file for spt_srh in ls_spt_srh for spn_file in Path(spt_srh).rglob(&#39;*.R&#39;)] for spn_found in ls_spn_found: drive, path_and_file = os.path.splitdrive(spn_found) path_no_suffix = os.path.splitext(spn_found)[0] path_no_file, file = os.path.split(spn_found) file_no_suffix = Path(spn_found).stem print(&#39;file:&#39;, file, &#39;\\ndrive:&#39;, drive, &#39;\\nfile no suffix:&#39;, file_no_suffix, &#39;\\nfull path:&#39;, spn_found, &#39;\\npt no fle:&#39;, path_no_file, &#39;\\npt no suf:&#39;, path_no_suffix, &#39;\\n&#39;) ## file: fs_ary_basics.R ## drive: C: ## file no suffix: fs_ary_basics ## full path: C:\\Users\\fan\\R4Econ\\amto\\array\\htmlpdfr\\fs_ary_basics.R ## pt no fle: C:\\Users\\fan\\R4Econ\\amto\\array\\htmlpdfr ## pt no suf: C:\\Users\\fan\\R4Econ\\amto\\array\\htmlpdfr\\fs_ary_basics ## ## file: fs_ary_generate.R ## drive: C: ## file no suffix: fs_ary_generate ## full path: C:\\Users\\fan\\R4Econ\\amto\\array\\htmlpdfr\\fs_ary_generate.R ## pt no fle: C:\\Users\\fan\\R4Econ\\amto\\array\\htmlpdfr ## pt no suf: C:\\Users\\fan\\R4Econ\\amto\\array\\htmlpdfr\\fs_ary_generate ## ## file: fs_ary_mesh.R ## drive: C: ## file no suffix: fs_ary_mesh ## full path: C:\\Users\\fan\\R4Econ\\amto\\array\\htmlpdfr\\fs_ary_mesh.R ## pt no fle: C:\\Users\\fan\\R4Econ\\amto\\array\\htmlpdfr ## pt no suf: C:\\Users\\fan\\R4Econ\\amto\\array\\htmlpdfr\\fs_ary_mesh ## ## file: fs_ary_string.R ## drive: C: ## file no suffix: fs_ary_string ## full path: C:\\Users\\fan\\R4Econ\\amto\\array\\htmlpdfr\\fs_ary_string.R ## pt no fle: C:\\Users\\fan\\R4Econ\\amto\\array\\htmlpdfr ## pt no suf: C:\\Users\\fan\\R4Econ\\amto\\array\\htmlpdfr\\fs_ary_string ## ## file: fs_listr.R ## drive: C: ## file no suffix: fs_listr ## full path: C:\\Users\\fan\\R4Econ\\amto\\list\\htmlpdfr\\fs_listr.R ## pt no fle: C:\\Users\\fan\\R4Econ\\amto\\list\\htmlpdfr ## pt no suf: C:\\Users\\fan\\R4Econ\\amto\\list\\htmlpdfr\\fs_listr ## ## file: fs_lst_basics.R ## drive: C: ## file no suffix: fs_lst_basics ## full path: C:\\Users\\fan\\R4Econ\\amto\\list\\htmlpdfr\\fs_lst_basics.R ## pt no fle: C:\\Users\\fan\\R4Econ\\amto\\list\\htmlpdfr ## pt no suf: C:\\Users\\fan\\R4Econ\\amto\\list\\htmlpdfr\\fs_lst_basics 9.2.2 Folder Operations Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). 9.2.2.1 Create an Absolute Folder with Path join Create a platform free full absolute path to a particular folder import os import pathlib # suffix st_suffix = &quot;_mlt_region_ne&quot; srt_folder = &quot;testfolder&quot; + st_suffix + &#39;_other_stuff&#39; # path join with os.sep srt_path = os.path.join(os.sep, &quot;users&quot;, &quot;fan&quot;, &quot;pyfan&quot;, &quot;vig&quot;, &quot;support&quot;, &quot;inout&quot;, &quot;_folder&quot;, &quot;testfolder&quot; + st_suffix, &#39;subfolder&#39;) # Path Name spn_path = os.path.abspath(srt_path) # Create the folder pathlib.Path(spn_path).mkdir(parents=True, exist_ok=True) # Print print(f&#39;{srt_folder=}&#39;) ## srt_folder=&#39;testfolder_mlt_region_ne_other_stuff&#39; print(f&#39;{srt_path=}&#39;) ## srt_path=&#39;\\\\users\\\\fan\\\\pyfan\\\\vig\\\\support\\\\inout\\\\_folder\\\\testfolder_mlt_region_ne\\\\subfolder&#39; print(f&#39;{spn_path=}&#39;) ## spn_path=&#39;G:\\\\users\\\\fan\\\\pyfan\\\\vig\\\\support\\\\inout\\\\_folder\\\\testfolder_mlt_region_ne\\\\subfolder&#39; Slash converion, convert the system slash to forward-slash all: srt_folder_slashconverted = spn_path.replace(os.sep, &#39;/&#39;) print(f&#39;{srt_folder_slashconverted=}&#39;) ## srt_folder_slashconverted=&#39;G:/users/fan/pyfan/vig/support/inout/_folder/testfolder_mlt_region_ne/subfolder&#39; see: constructing absolute path with os.path.join(). 9.2.2.2 Get the Last Directory in a Path without Some Suffix Suppose there is a directory with abc_suffix_other/subfolder as the name, generate a new folder that has abc as the folder name without _suffix. Generate this folder in the same root folder that the abc_suffix folder resides in. # Absolute path just created: print(f&#39;{spn_path=}&#39;) # the suffix used ## spn_path=&#39;G:\\\\users\\\\fan\\\\pyfan\\\\vig\\\\support\\\\inout\\\\_folder\\\\testfolder_mlt_region_ne\\\\subfolder&#39; print(f&#39;{st_suffix=}&#39;) # get path without what comes after suffix ## st_suffix=&#39;_mlt_region_ne&#39; spn_path_no_suffix = spn_path[:spn_path.index(st_suffix)] # Create the folder pathlib.Path(spn_path_no_suffix).mkdir(parents=True, exist_ok=True) # Get the new folder name create spt_root_main, srt_new_subfolder = os.path.split(spn_path_no_suffix) # Add Slash to new subfolder spn_path_no_suffix = spn_path_no_suffix + os.sep # Print print(f&#39;{spn_path_no_suffix=}&#39;) ## spn_path_no_suffix=&#39;G:\\\\users\\\\fan\\\\pyfan\\\\vig\\\\support\\\\inout\\\\_folder\\\\testfolder\\\\&#39; print(f&#39;{spt_root_main=}&#39;) ## spt_root_main=&#39;G:\\\\users\\\\fan\\\\pyfan\\\\vig\\\\support\\\\inout\\\\_folder&#39; print(f&#39;{srt_new_subfolder=}&#39;) ## srt_new_subfolder=&#39;testfolder&#39; 9.2.2.3 New Folder and Files create a folder and subfolder create two files in the new folder import pathlib # folder root srt_folder = &quot;_folder/&quot; # new folder srt_subfolder = srt_folder + &quot;fa/&quot; # new subfolder srt_subfolder = srt_subfolder + &quot;faa/&quot; # generate folders recursively pathlib.Path(srt_subfolder).mkdir(parents=True, exist_ok=True) # Open new file fl_tex_contents_aa = open(srt_subfolder + &quot;file_a.txt&quot;, &#39;w&#39;) # Write to File fl_tex_contents_aa.write(&#39;contents of file a&#39;) ## 18 fl_tex_contents_aa.close() # Open another new file and save fl_tex_contents_ab = open(srt_subfolder + &quot;file_b.txt&quot;, &#39;w&#39;) # Write to File fl_tex_contents_ab.write(&#39;contents of file b&#39;) ## 18 fl_tex_contents_ab.close() Generate more folders without files: # generate folders recursively pathlib.Path(&quot;_folder/fb/fba/&quot;).mkdir(parents=True, exist_ok=True) # generate folders recursively pathlib.Path(&quot;_folder/fc/&quot;).mkdir(parents=True, exist_ok=True) # generate folders recursively pathlib.Path(&quot;_folder/fd/&quot;).mkdir(parents=True, exist_ok=True) 9.2.2.4 Copy a File from One Folder to Another Move the two files from *_folder/fa/faa* to *_folder/faa* as well as to *_folder/fb/faa. Use shutil.copy2* so that more metadata is copied over. But copyfile is faster. How do I copy a file in Python? Moving one file: import shutil # Faster method shutil.copyfile(&#39;_folder/fa/faa/file_a.txt&#39;, &#39;_folder/fb/file_a.txt&#39;) # More metadat copied, and don&#39;t need to specify name ## &#39;_folder/fb/file_a.txt&#39; shutil.copy2(&#39;_folder/fa/faa/file_a.txt&#39;, &#39;_folder/fb/fba&#39;) ## &#39;_folder/fb/fba\\\\file_a.txt&#39; 9.2.2.5 Copy Folder to Multiple Destimations Move Entire Folder, How do I copy an entire directory of files into an existing directory using Python?: from distutils.dir_util import copy_tree # Move contents from fa/faa/ to fc/faa srt_curroot = &#39;_folder/fa/&#39; srt_folder = &#39;faa/&#39; srt_newroot = &#39;_folder/fc/&#39; # Full source and destination srt_sourc = srt_curroot + srt_folder srt_desct = srt_newroot + srt_folder # Check/Create new Directory pathlib.Path(srt_desct).mkdir(parents=True, exist_ok=True) # Move copy_tree(srt_sourc, srt_desct) ## [&#39;_folder/fc/faa/file_a.txt&#39;, &#39;_folder/fc/faa/file_b.txt&#39;] Move contents to multiple destinations: from distutils.dir_util import copy_tree # Check/Create new Directory pathlib.Path(&#39;_folder/fd/faa/fa_images&#39;).mkdir(parents=True, exist_ok=True) pathlib.Path(&#39;_folder/fd/faa/fb_images&#39;).mkdir(parents=True, exist_ok=True) pathlib.Path(&#39;_folder/fd/faa/fc_images&#39;).mkdir(parents=True, exist_ok=True) pathlib.Path(&#39;_folder/fd/faa/fz_img&#39;).mkdir(parents=True, exist_ok=True) pathlib.Path(&#39;_folder/fd/faa/fz_other&#39;).mkdir(parents=True, exist_ok=True) # Move copy_tree(&#39;_folder/fa/faa/&#39;, &#39;_folder/fd/faa/fa_images&#39;) ## [&#39;_folder/fd/faa/fa_images\\\\file_a.txt&#39;, &#39;_folder/fd/faa/fa_images\\\\file_b.txt&#39;] copy_tree(&#39;_folder/fa/faa/&#39;, &#39;_folder/fd/faa/fb_images&#39;) ## [&#39;_folder/fd/faa/fb_images\\\\file_a.txt&#39;, &#39;_folder/fd/faa/fb_images\\\\file_b.txt&#39;] copy_tree(&#39;_folder/fa/faa/&#39;, &#39;_folder/fd/faa/fc_images&#39;) ## [&#39;_folder/fd/faa/fc_images\\\\file_a.txt&#39;, &#39;_folder/fd/faa/fc_images\\\\file_b.txt&#39;] copy_tree(&#39;_folder/fa/faa/&#39;, &#39;_folder/fd/faa/fz_img&#39;) ## [&#39;_folder/fd/faa/fz_img\\\\file_a.txt&#39;, &#39;_folder/fd/faa/fz_img\\\\file_b.txt&#39;] copy_tree(&#39;_folder/fa/faa/&#39;, &#39;_folder/fd/faa/fz_other&#39;) # Empty Folder ## [&#39;_folder/fd/faa/fz_other\\\\file_a.txt&#39;, &#39;_folder/fd/faa/fz_other\\\\file_b.txt&#39;] pathlib.Path(&#39;_folder/fd/faa/fd_images&#39;).mkdir(parents=True, exist_ok=True) pathlib.Path(&#39;_folder/fd/faa/fe_images&#39;).mkdir(parents=True, exist_ok=True) 9.2.2.6 Search for Files in Folder Find the total number of files in a folder. from pathlib import Path # the number of files in folder found with search critiera st_fle_search = &#39;*.txt&#39; ls_spn = [Path(spn).stem for spn in Path(&#39;_folder/fd/faa/fa_images&#39;).rglob(st_fle_search)] print(ls_spn) # count files in a non-empty folder ## [&#39;file_a&#39;, &#39;file_b&#39;] srn = &#39;_folder/fd/faa/fa_images&#39; [spn for spn in Path(srn).rglob(st_fle_search)] ## [WindowsPath(&#39;_folder/fd/faa/fa_images/file_a.txt&#39;), WindowsPath(&#39;_folder/fd/faa/fa_images/file_b.txt&#39;)] bl_folder_is_empty = len([spn for spn in Path(srn).rglob(st_fle_search)])&gt;0 print(bl_folder_is_empty) # count files in an empty folder ## True srn = &#39;_folder/fd/faa/fd_images&#39; [spn for spn in Path(srn).rglob(st_fle_search)] ## [] bl_folder_is_empty = len([spn for spn in Path(srn).rglob(st_fle_search)])&gt;0 print(bl_folder_is_empty) ## False 9.2.2.7 Search for Folder Names python search for folders containing strings Search for folders with certain search word in folder name, and only keep if folder actually has files. import os # get all folder names in folder ls_spt = os.listdir(&#39;_folder/fd/faa/&#39;) print(ls_spt) # Select only subfolder names containing _images ## [&#39;fa_images&#39;, &#39;fb_images&#39;, &#39;fc_images&#39;, &#39;fd_images&#39;, &#39;fe_images&#39;, &#39;fz_img&#39;, &#39;fz_other&#39;, &#39;_img&#39;] srt = &#39;_folder/fd/faa/&#39; st_search = &#39;_images&#39; ls_srt_found = [srt + spt for spt in os.listdir(srt) if st_search in spt] print(ls_srt_found) ## [&#39;_folder/fd/faa/fa_images&#39;, &#39;_folder/fd/faa/fb_images&#39;, &#39;_folder/fd/faa/fc_images&#39;, &#39;_folder/fd/faa/fd_images&#39;, &#39;_folder/fd/faa/fe_images&#39;] 9.2.2.8 Find Non-empty Folders by Name Search: Get subfolders in folder with string in name Only collect if there are files in the subfolder import pathlib # Select only subfolder names containing _images srt = &#39;_folder/fd/faa/&#39; # the folder names must contain _images st_srt_srh = &#39;_images&#39; # there must be files in the folder with this string st_fle_srh = &#39;*.txt&#39; # All folders that have String ls_srt_found = [srt + spt for spt in os.listdir(srt) if st_srt_srh in spt] print(ls_srt_found) # All folders that have String and that are nonempty ## [&#39;_folder/fd/faa/fa_images&#39;, &#39;_folder/fd/faa/fb_images&#39;, &#39;_folder/fd/faa/fc_images&#39;, &#39;_folder/fd/faa/fd_images&#39;, &#39;_folder/fd/faa/fe_images&#39;] ls_srt_found = [srt + spt for spt in os.listdir(srt) if ((st_srt_srh in spt) and (len([spn for spn in Path(srt + spt).rglob(st_fle_srh)])&gt;0)) ] print(ls_srt_found) ## [&#39;_folder/fd/faa/fa_images&#39;, &#39;_folder/fd/faa/fb_images&#39;, &#39;_folder/fd/faa/fc_images&#39;] 9.2.2.9 Found Folders to new Folder Search for subfolders by folder name string in a folder Select nonempty subfolders Move nonsempty subfolders to one new folder Move this single combination folder The results here are implemented as function in the pyfan package: fp_agg_move_subfiles. import pathlib import os import shutil from distutils.dir_util import copy_tree # 1 Define Parameters # Select only subfolder names containing _images srt = &#39;_folder/fd/faa/&#39; # the folder names must contain _images st_srt_srh = &#39;_images&#39; # there must be files in the folder with this string st_fle_srh = &#39;*.txt&#39; # new aggregating folder name srt_agg = &#39;_img&#39; # folders to move aggregation files towards ls_srt_dest = [&#39;_folder/fd/faa/&#39;, &#39;_folder/&#39;] # delete source bl_delete_source = False # 2 Gather Folders ls_ls_srt_found = [[srt + spt, spt] for spt in os.listdir(srt) if ((st_srt_srh in spt) and (len([spn for spn in Path(srt + spt).rglob(st_fle_srh)])&gt;0)) ] print(ls_ls_srt_found) # 3 Loop over destination folders, loop over source folders ## [[&#39;_folder/fd/faa/fa_images&#39;, &#39;fa_images&#39;], [&#39;_folder/fd/faa/fb_images&#39;, &#39;fb_images&#39;], [&#39;_folder/fd/faa/fc_images&#39;, &#39;fc_images&#39;]] for srt in ls_srt_dest: # Move each folder over for ls_srt_found in ls_ls_srt_found: # Paths srt_source = ls_srt_found[0] srt_dest = os.path.join(srt, srt_agg, ls_srt_found[1]) # dest folders pathlib.Path(srt_dest).mkdir(parents=True, exist_ok=True) # move copy_tree(ls_srt_found[0], srt_dest) # 4. Delete Sources ## [&#39;_folder/fd/faa/_img\\\\fa_images\\\\file_a.txt&#39;, &#39;_folder/fd/faa/_img\\\\fa_images\\\\file_b.txt&#39;] ## [&#39;_folder/fd/faa/_img\\\\fb_images\\\\file_a.txt&#39;, &#39;_folder/fd/faa/_img\\\\fb_images\\\\file_b.txt&#39;] ## [&#39;_folder/fd/faa/_img\\\\fc_images\\\\file_a.txt&#39;, &#39;_folder/fd/faa/_img\\\\fc_images\\\\file_b.txt&#39;] ## [&#39;_folder/_img\\\\fa_images\\\\file_a.txt&#39;, &#39;_folder/_img\\\\fa_images\\\\file_b.txt&#39;] ## [&#39;_folder/_img\\\\fb_images\\\\file_a.txt&#39;, &#39;_folder/_img\\\\fb_images\\\\file_b.txt&#39;] ## [&#39;_folder/_img\\\\fc_images\\\\file_a.txt&#39;, &#39;_folder/_img\\\\fc_images\\\\file_b.txt&#39;] if bl_delete_source: for ls_srt_found in ls_ls_srt_found: shutil.rmtree(ls_srt_found[0]) 9.2.3 Parse Yaml Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). Use the PyYAML to parse yaml. 9.2.3.1 Write and Create a Simple YAML file First, Yaml as a string variable: # Create the Tex Text # Note that trible quotes begin first and end last lines stf_tex_contents = &quot;&quot;&quot;\\ - file: matrix_matlab title: &quot;One Variable Graphs and Tables&quot; description: | Frequency table, bar chart and histogram. R function and lapply to generate graphs/tables for different variables. core: - package: r code: | c(&#39;word1&#39;,&#39;word2&#39;) function() for (ctr in c(1,2)) {} - package: dplyr code: | group_by() date: 2020-05-02 output: pdf_document: pandoc_args: &#39;../_output_kniti_pdf.yaml&#39; includes: in_header: &#39;../preamble.tex&#39; urlcolor: blue - file: matrix_algebra_rules title: &quot;Opening a Dataset&quot; titleshort: &quot;Opening a Dataset&quot; description: | Opening a Dataset. core: - package: r code: | setwd() - package: readr code: | write_csv() date: 2020-05-02 date_start: 2018-12-01 - file: matrix_two title: &quot;Third file&quot; titleshort: &quot;Third file&quot; description: | Third file description.&quot;&quot;&quot; # Print print(stf_tex_contents) ## - file: matrix_matlab ## title: &quot;One Variable Graphs and Tables&quot; ## description: | ## Frequency table, bar chart and histogram. ## R function and lapply to generate graphs/tables for different variables. ## core: ## - package: r ## code: | ## c(&#39;word1&#39;,&#39;word2&#39;) ## function() ## for (ctr in c(1,2)) {} ## - package: dplyr ## code: | ## group_by() ## date: 2020-05-02 ## output: ## pdf_document: ## pandoc_args: &#39;../_output_kniti_pdf.yaml&#39; ## includes: ## in_header: &#39;../preamble.tex&#39; ## urlcolor: blue ## - file: matrix_algebra_rules ## title: &quot;Opening a Dataset&quot; ## titleshort: &quot;Opening a Dataset&quot; ## description: | ## Opening a Dataset. ## core: ## - package: r ## code: | ## setwd() ## - package: readr ## code: | ## write_csv() ## date: 2020-05-02 ## date_start: 2018-12-01 ## - file: matrix_two ## title: &quot;Third file&quot; ## titleshort: &quot;Third file&quot; ## description: | ## Third file description. Second, write the contents of the file to a new tex file stored inside the *_file* subfolder of the directory: # Relative file name srt_file_tex = &quot;_file/&quot; sna_file_tex = &quot;test_yml_fan&quot; srn_file_tex = srt_file_tex + sna_file_tex + &quot;.yml&quot; # Open new file fl_tex_contents = open(srn_file_tex, &#39;w&#39;) # Write to File fl_tex_contents.write(stf_tex_contents) # print ## 908 fl_tex_contents.close() 9.2.3.2 Select Subset of Values by Key Load Yaml file created prior, the output is a list of dictionaries: import yaml import pprint # Open yaml file fl_yaml = open(srn_file_tex) # load yaml ls_dict_yml = yaml.load(fl_yaml, Loader=yaml.BaseLoader) # type type(ls_dict_yml) ## &lt;class &#39;list&#39;&gt; type(ls_dict_yml[0]) # display ## &lt;class &#39;dict&#39;&gt; pprint.pprint(ls_dict_yml, width=1) ## [{&#39;core&#39;: [{&#39;code&#39;: &quot;c(&#39;word1&#39;,&#39;word2&#39;)\\n&quot; ## &#39;function()\\n&#39; ## &#39;for &#39; ## &#39;(ctr &#39; ## &#39;in &#39; ## &#39;c(1,2)) &#39; ## &#39;{}\\n&#39;, ## &#39;package&#39;: &#39;r&#39;}, ## {&#39;code&#39;: &#39;group_by()\\n&#39;, ## &#39;package&#39;: &#39;dplyr&#39;}], ## &#39;date&#39;: &#39;2020-05-02&#39;, ## &#39;description&#39;: &#39;Frequency &#39; ## &#39;table, &#39; ## &#39;bar &#39; ## &#39;chart &#39; ## &#39;and &#39; ## &#39;histogram.\\n&#39; ## &#39;R &#39; ## &#39;function &#39; ## &#39;and &#39; ## &#39;lapply &#39; ## &#39;to &#39; ## &#39;generate &#39; ## &#39;graphs/tables &#39; ## &#39;for &#39; ## &#39;different &#39; ## &#39;variables.\\n&#39;, ## &#39;file&#39;: &#39;matrix_matlab&#39;, ## &#39;output&#39;: {&#39;pdf_document&#39;: {&#39;includes&#39;: {&#39;in_header&#39;: &#39;../preamble.tex&#39;}, ## &#39;pandoc_args&#39;: &#39;../_output_kniti_pdf.yaml&#39;}}, ## &#39;title&#39;: &#39;One &#39; ## &#39;Variable &#39; ## &#39;Graphs &#39; ## &#39;and &#39; ## &#39;Tables&#39;, ## &#39;urlcolor&#39;: &#39;blue&#39;}, ## {&#39;core&#39;: [{&#39;code&#39;: &#39;setwd()\\n&#39;, ## &#39;package&#39;: &#39;r&#39;}, ## {&#39;code&#39;: &#39;write_csv()\\n&#39;, ## &#39;package&#39;: &#39;readr&#39;}], ## &#39;date&#39;: &#39;2020-05-02&#39;, ## &#39;date_start&#39;: &#39;2018-12-01&#39;, ## &#39;description&#39;: &#39;Opening &#39; ## &#39;a &#39; ## &#39;Dataset.\\n&#39;, ## &#39;file&#39;: &#39;matrix_algebra_rules&#39;, ## &#39;title&#39;: &#39;Opening &#39; ## &#39;a &#39; ## &#39;Dataset&#39;, ## &#39;titleshort&#39;: &#39;Opening &#39; ## &#39;a &#39; ## &#39;Dataset&#39;}, ## {&#39;description&#39;: &#39;Third &#39; ## &#39;file &#39; ## &#39;description.&#39;, ## &#39;file&#39;: &#39;matrix_two&#39;, ## &#39;title&#39;: &#39;Third &#39; ## &#39;file&#39;, ## &#39;titleshort&#39;: &#39;Third &#39; ## &#39;file&#39;}] Select yaml information by file name which is a key shared by components of the list: ls_str_file_ids = [&#39;matrix_two&#39;] ls_dict_selected = [dict_yml for dict_yml in ls_dict_yml if dict_yml[&#39;file&#39;] in ls_str_file_ids] pprint.pprint(ls_dc_selected, width=1) ## [{&#39;date&#39;: datetime.date(2020, 5, 2), ## &#39;description&#39;: &#39;Frequency &#39; ## &#39;table, &#39; ## &#39;bar &#39; ## &#39;chart &#39; ## &#39;and &#39; ## &#39;histogram&#39;, ## &#39;file&#39;: &#39;mat_matlab&#39;, ## &#39;title&#39;: &#39;One &#39; ## &#39;Variable &#39; ## &#39;Graphs &#39; ## &#39;and &#39; ## &#39;Tables&#39;, ## &#39;val&#39;: 1}] 9.2.3.3 Dump List of Dictionary as YAML py yaml dump pipe Given a list of dictionaries, dump values to yaml. Note that dumped output does not use pipe for long sentences, but use single quote and space line, which works with the rmdparrse.py function without problem. ls_dict_selected = [dict_yml for dict_yml in ls_dict_yml if dict_yml[&#39;file&#39;] in [&#39;matrix_two&#39;,&#39;matrix_matlab&#39;]] print(yaml.dump(ls_dict_selected)) ## - core: ## - code: &#39;c(&#39;&#39;word1&#39;&#39;,&#39;&#39;word2&#39;&#39;) ## ## function() ## ## for (ctr in c(1,2)) {} ## ## &#39; ## package: r ## - code: &#39;group_by() ## ## &#39; ## package: dplyr ## date: &#39;2020-05-02&#39; ## description: &#39;Frequency table, bar chart and histogram. ## ## R function and lapply to generate graphs/tables for different variables. ## ## &#39; ## file: matrix_matlab ## output: ## pdf_document: ## includes: ## in_header: ../preamble.tex ## pandoc_args: ../_output_kniti_pdf.yaml ## title: One Variable Graphs and Tables ## urlcolor: blue ## - description: Third file description. ## file: matrix_two ## title: Third file ## titleshort: Third file 9.3 Install Python 9.3.1 Core Installations Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). Use the PyYAML to parse yaml. 9.3.1.1 Git Bash Download and install git 9.3.1.2 Conda Install Download Anaconda for Python 3. For more involved conda instructions see here Get where you installed conda: open up anaconda prompt with admin rights (press windows button, and search for anaconda prompt, right click on the resulting terminal icon, choose as admin, a terminal opens up). where python where anaconda # C:/ProgramData/Anaconda3/Scripts/anaconda.exe # C:/ProgramData/Anaconda3/python.exe Add to Path: open up windows Path and copy the paths found above inside. 9.3.1.2.1 Add To Path Details To Add Anaconda to Path, In Windows Search for: Environment Variables Edit Environment Variables Add new to Path (lower half): C:/ProgramData/Anaconda3/Scripts/ C:/ProgramData/Anaconda3/ Now open up regular windows command Prompt, Type in: conda version Close and Open up Git Bash: conda version Alternatively, in windows, directly search for Path, and add the python and anaconda exe paths to paths. 9.4 Documentation 9.4.1 Numpy Doc Documentation Guide Go back to fans Python Code Examples Repository (bookdown site) or the pyfan Package (API). sphinxcontrib-napoleon examples. numpydoc examples. Documenting Python APIs with docstrings Numpy Doc Example Parameters Check types: print(type(111)) print(type(&#39;111&#39;)) import logging print(type(logging.WARNING)) Style 1: Parameters ---------- n : int The upper limit of the range to generate, from 0 to `n` - 1. param1 : int The first parameter. param1 : str Description of `param1`. msg : str Human readable string describing the exception. param1 : int The first parameter. param2 : str The second parameter. param3 : str, optional The second parameter. param5: dict A dictionary param6: bool boolean arr1 : ndarray 2D array containing data with `float` type. arr2 : ndarray 1D mask array(containing data with boolean type). Style 2, this will add a link to the types in python doc: Parameters ---------- param2 : :obj:`str`, optional The second parameter. code : :obj:`int`, optional Numeric error code. param3 : :obj:`int`, optional Description of `param3`. param4 : :obj:`list` of :obj:`str` Description of `param2`. Multiple lines are supported. For args and kwargs: Parameters ---------- *args Variable length argument list. **kwargs Arbitrary keyword arguments. 9.4.1.1 Returns Returns ------- numpy.array of shape (1, it_draws) A vector of sorted or unsorted random grid points, or equi-quantile points. Returns ------- :obj:`tuple` of :obj:`bool` Returns ------- None 9.4.1.2 Function Calls To refer to functions in the same .py file, just need to use: :func:log_format to refer to function name. For function in different .py files, might need its full path **kwargs Arguments for functions that is called, including :func:`log_format` 9.4.1.3 Examples Array outputs. Examples -------- &gt;&gt;&gt; fl_mu = 0 &gt;&gt;&gt; fl_sd = 1 &gt;&gt;&gt; it_draws = 5 &gt;&gt;&gt; it_seed = 123 &gt;&gt;&gt; fl_lower_sd = -1 &gt;&gt;&gt; fl_higher_sd = 0.8 &gt;&gt;&gt; it_draw_type = 0 &gt;&gt;&gt; ar_draw_random_normal(fl_mu, fl_sd, it_draws, ... it_seed, it_draw_type, ... fl_lower_sd, fl_higher_sd) [-1. 0.8 0.2829785 - 1. - 0.57860025] &gt;&gt;&gt; it_draw_type = 1 &gt;&gt;&gt; ar_draw_random_normal(fl_mu, fl_sd, it_draws, ... it_seed, it_draw_type, ... fl_lower_sd, fl_higher_sd) [-1. - 0.47883617 - 0.06672597 0.3338994 0.8] &gt;&gt;&gt; it_draw_type = 2 &gt;&gt;&gt; ar_draw_random_normal(fl_mu, fl_sd, it_draws, ... it_seed, it_draw_type, ... fl_lower_sd, fl_higher_sd) [-1. - 1. - 0.57860025 0.2829785 0.8] String outputs. Examples -------- &gt;&gt;&gt; log_vig_start(spt_root = proj_sys_sup.main_directory(), ... main_folder_name=&#39;logvig&#39;, sub_folder_name=&#39;parameters&#39;, ... subsub_folder_name=&#39;combo_type&#39;, ... file_name=&#39;fs_gen_combo_type&#39;, ... it_time_format=8, log_level=logging.INFO) C:\\\\Users\\\\fan\\\\logvig\\\\parameters\\\\combo_type\\\\fs_gen_combo_type_20201030.log.py "],["index-and-code-links.html", "A Index and Code Links A.1 Data Structures links A.2 Pandas links A.3 Functions links A.4 Statistics links A.5 Tables and Graphs links A.6 Amazon Web Services links A.7 Docker Container links A.8 Get Data links A.9 System and Support links", " A Index and Code Links A.1 Data Structures links A.1.1 Section 1.1 Numbers, Strings, Lists and Tuples links Basic Number Numeric Manipulations: rmd | r | pdf | html Loop over a list of numbers where the first and second digits have different interpretations. py: int(np.floor(it_num/10)) + it_num%10 numpy: floor Define and Unpack Tuple: rmd | r | pdf | html Define/deal multiple variables on the same line Define tuple in python with and without parenthesis, unpack tuple, get subset of elements. Access tuple element and fail to mutate tuple element. py: isinstance(tp_abc, tuple) List Manipulations and Defaults: rmd | r | pdf | html Conditional statements based on list length and element value. Provide default for element of a list when list does not have that element. py: lambda + join + append() + if len(X) &gt;= 3 and X[2] is not None + if elif else Python String Manipulation Examples: rmd | r | pdf | html Count unique elements of a string array, generate frequency list. Search for substring, replace string, wrap string. Display and format numeric string with fstring. Change the decimal rounding given a list of estimates and standard error string arrays. py: zip() + upper() + join() + round() + float() + split() + replace() + ascii_lowercase() + set() textwrap: fill(st, width = 20) fstring: f + f{fl_esti_rounded:.{it_round_decimal}f} random: choice A.1.2 Section 1.2 Dictionary links Python Dictionary Examples and Usages: rmd | r | pdf | html Generate a dictionary, loop through a dictionary. List comprehension with dictionary. py: dc = {key: name, val: 1} copy: deepcopy A.1.3 Section 1.3 Numpy Arrays links Numpy Combine Arrays to Matrix: rmd | r | pdf | html Arrays to matrix. numpy: column_stack() + random.choice() + reshape() A.2 Pandas links A.2.1 Section 2.1 Panda Basics links Pandas Generate Dataframes with Random Numeric and String Data: rmd | r | pdf | html Generate a dataframe from arrays. Generate a dataframe with random integers as well as random string variables. np: random.randint() + reshape() + column_stack() pandas: DataFrame() Python Pandas Conditional Selection of Selectiotn Rows and Columns: rmd | r | pdf | html Select subset of rows or columns based on cell value conditions. pandas: pd.DataFrame() + replace([Zvcss, Dugei], Zqovt) + df.loc[df[c5] == Zqovt] Dataframe Export as CSV with Automatic File Path and Name: rmd | r | pdf | html Export a pandas dataframe to csv, store automatically in user home download folder. File name contains the variable name, use fstring to get variable name as file string. pandas: df2export.to_csv(spn_csv_path, sep=,) pathlib: home() + joinpath() + mkdir(parents=True, exist_ok=True) fstring: f{mt_abc=}.split(=)[0] time: strftime(%Y%m%d-%H%M%S) A.3 Functions links A.3.1 Section 3.1 Function Arguments and Returns links Python Function Data Type Handling: rmd | r | pdf | html Check if parameter is string or integer, conditional execution and exception handling. Check if parameter is string or an integer between some values. py: type + isinstance(abc, str) + isinstance(abc, int) + raise + try except Tuple and Dictionary as Arguments with args and kwargs: rmd | r | pdf | html Update default parameters with dictionary that replaces and appends additional key-value pairs using kwargs. Pass a dictionary for named arguments to a function. Python function None as default for mutable list argument. python: dict3 = {dict1, dict2} + dict1.update(dict2) + func(par1=val1, kwargs) Command Line Argument Parsing Positional and Optional Arguments: rmd | r | pdf | html Parse parameters entered via command line to call a python script. Optional and positional arguments of different data types (int, str, etc.). Default values, allowed list of values. argparse: parser.add_argument() + parser.parse_args() Function value returns: rmd | r | pdf | html Return one or multiple values from function. python: return a, b, c A.3.2 Section 3.2 Exceptions links Python Raise, Try and Catch Exceptions: rmd | r | pdf | html Raise an Exception in a python function, try and catch and print to string. Trace full exception stack. python: raise + try except + ValueError + TypeError traceback: print_exc() A.4 Statistics links A.4.1 Section 4.1 Markov Process links Markov Transition Conditional Probability Check Sum to 1: rmd | r | pdf | html Generate a sample 50 by 50 markov transition matrix. Check row sums for approximate equality to 1. numpy: allclose + reshape + sum A.5 Tables and Graphs links A.5.1 Section 5.1 Matplotlib Base Plots links Mabplotlib Scatter and Line Plots: rmd | r | pdf | html Plot several arrays of data, grid, figure title, and line and point patterns and colors. Plot out random walk and white noise first-order autoregressive processes. matplotlib: subplots() + ax.plot() + ax.legend() + ylabel() + xlabel() + title() + grid() + show() numpy: random.normal() + random.seed() + cumsum() + arange() Mabplotlib Text Plots: rmd | r | pdf | html Print text as figure. matplotlib: ax.text() textwrap: fill() json: dump() A.6 Amazon Web Services links A.6.1 Section 6.1 AWS Setup links AWS Account Set-up and Start Instance: rmd | r | pdf | html Generate keypair on AWS, launch instance, launch security, ssh access, and AWSCLI. ssh: ssh-agent + ssh-keygen + ssh ec2-user@ec2-52-23-218-117.compute-1.amazonaws.com aws: aws ec2 start-instances + aws ec2 stop-instances + systemctl start amazon-ssm-agent Boto3 Client Service Communications: rmd | r | pdf | html Start AWS services, send requests etc via boto3. boto3: boto3.client(service, aws_access_key_id, aws_secret_access_key, region_name) A.6.2 Section 6.2 S3 links AWS S3 Uploading, Downloading and Syncing, Locally, EC2 and in Docker Container: rmd | r | pdf | html From EC2 or local computer upload files to S3 folders. Download sync folders with exclusions between local and S3 folders. Download file from S3 to local computer, an EC2 Linux computer, or into a Docker Container. py: platform.release() boto3: boto3.client(s3) + s3.upload_file() + s3.download_file() os: sep A.6.3 Section 6.3 Batch links AWS Batch, Batch Array: rmd | r | pdf | html Set up python function that uses AWS_BATCH_JOB_ARRAY_INDEX. Register batch task and submit batch array tasks using ECR image, and save results to S3. Batch Array status check until success. yaml: load() boto3: client() + register_job_definition(jobDefinitionName, type, containerProperties, retryStrategy) + aws_batch.submit_job(jobName, jobQueue, arrayProperties={size:10}, jobDefinition) + aws_batch.describe_jobs() A.7 Docker Container links A.7.1 Section 7.1 Docker Setup links Docker Container Set-Up and Run on AWS: rmd | r | pdf | html Install Docker on AWS and build Docker image. Start docker container and run programs inside Docker. aws: ssh + yum update -y + amazon-linux-extras install docker -y docker: service docker start + service docker status + docker build + docker images + docker image prune + docker run -t -i fanconda /bin/bash + python /fanProg/invoke/run.py + docker ps -a + docker system df + docker container ls -a AWS Docker Elastic Container Registery (ECR) Update and Push: rmd | r | pdf | html Update and push to Elastic Container Registry (ECR) with newly built Docker image. Pull from Elastic Container Registry docker image. scp: scp -o StrictHostKeyChecking=accept-new -i aws: aws ecr get-login docker: docker login + docker build + docker tag + docker push + docker pull A.8 Get Data links A.8.1 Section 8.1 Environmental Data links CDS ECMWF Global Enviornmental Data Download: rmd | r | pdf | html Using Python API get get ECMWF ERA5 data. Dynamically modify a python API file, run python inside a Conda virtual environment with R-reticulate. r: file() + writeLines() + unzip() + list.files() + unlink() r-reticulate: use_python() + Sys.setenv(RETICULATE_PYTHON = spth_conda_env) A.9 System and Support links A.9.1 Section 9.1 Command Line links Execute Python from Command Line and Run Command Line in Python: rmd | r | pdf | html Run python functions from command line. Run Matlab Command Line Operations: rmd | r | pdf | html Generate a matlab script and run the script with parameters. subprocess: cmd = Popen(ls_str, stdin=PIPE, stdout=PIPE, stderr=PIPE) + cmd.communicate() decode: decode(utf-8) os: chdir() + getcdw() A.9.2 Section 9.2 File In and Out links Searching for Programs, Reading and Writing to File Examples: rmd | r | pdf | html Check the path to a particular installed program. Get the parent folder of the current file. Reading from file and replace strings in file. Convert text file to latex using pandoc and clean. py: open() + write() + replace() + [c for b in [[1,2],[2,3]] for c in b] subprocess: call() pathlib: Path().rglob() + Path().stem + Path(spn).parents[1] os: remove() + listdir() + path.isfile() + path.splitdrive() + path.splitext() + path.split() shutil: which() Python Directory and Folder Operations: rmd | r | pdf | html Join folder names to form absolute path. Folder path slash conversion from system os.sep to forward slash. Generate new folders and files, with existing folder substrings. Generate subfolder recursively. py: open(srt, w) + write() + close() os: os.sep + os.listdir() + os.path.abspath() + os.path.abspath(os.path.join(os.sep, users, fan)) + os.path.join(/, c: fa, fb) + spn_path.replace(os.sep, /) pathlib: Path(srt).mkdir(parents=True, exist_ok=True) + [Path(spn).stem for spn in Path(srt).rglob(st)] shutil: shutil.copyfile(/fa/fl.txt, /fb/fl.txt) + shutil.copy2(/fa/fl.txt, /fb) + shutil.rmtree(/fb) distutils: dir_util.copy_tree(/fa, /fb) Python Yaml File Parsing: rmd | r | pdf | html Parse and read yaml files. yaml: load(fl_yaml, Loader=yaml.BaseLoader) + dump() pprint: pprint.pprint(ls_dict_yml, width=1) A.9.3 Section 9.3 Install Python links Basic Conda Setup Instructions: rmd | r | pdf | html Conda and git installations bash: where A.9.4 Section 9.4 Documentation links Python Documentation Numpy Doc: rmd | r | pdf | html Numpy documentation examples. Xie, Yihui. 2020. Bookdown: Authoring Books and Technical Documents with r Markdown. https://CRAN.R-project.org/package=bookdown. "]]
